[![English Google Webmaster Central office-hours hangout](https://i.ytimg.com/vi/PBAtvzYIbP8/hqdefault.jpg)](https://www.youtube.com/watch?v=PBAtvzYIbP8)

## English Google Webmaster Central office-hours hangout

Join us for a Google Webmaster Central office hours hangout on May 10, 1pm US-Pacific 

https://www.timeanddate.com/worldclock/fixedtime.html?iso=20190510T22&p1=268



This session is open to anything webmaster related, in particular any of the things we talked about at I/O which you're still curious about: https://webmasters.googleblog.com/2019/05/io-2019-sessions-webmasters-SEOs.html



Add your questions at https://www.youtube.com/user/GoogleWebmasterHelp/community



To join live, watch out for the link here once the event starts, and use a webcam + headset. Feel free to drop by - we welcome webmasters of all levels!



#### [0:00:00](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=0) |  JOHN MUELLER: All right. Welcome, everyone, to

today's Webmaster Central office-hours hangout. My name is John Mueller. I am a webmaster trends analyst at Google. And today I have two guests and maybe more. We'll see. First off, we have Lizzie, who writes a lot of our documentation. So she's the one that makes sure that all of you have especially the structured data information that you need to make sure that that's all aligned  

#### [0:00:30](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=30) |  and that that works really well. And

we have Martin. (ECHOING) She's the one that makes sure that all of you have especially the structured data information-- Echo. Whoops. I don't know. Do you want to add an introduction, like, what do you do at Google? MARTIN: Hi there. I'm Martin. I annoy in Google by coming in and annoying them, whenever I possibly can. I'm currently an SEO consultant but have done seven years of being head of SEO [INAUDIBLE] Expedia, and prior to that, was head of SEO from [INAUDIBLE]..  

#### [0:01:00](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=60) |  So I have some big band experience.

And I'm normally the one complaining about the documentation. JOHN MUELLER: Uh-oh. I'll stay in the middle. Cool. So as always, there were a bunch of questions that were submitted. I set this up fairly short-term because the I/O was happening this week. And so many things were happening, I wasn't sure that I'd be able to get to it to do something like this.  

#### [0:01:30](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=90) |  But I'm glad we have it running

now. So there are some questions submitted. But if any of you who are here live want to ask first questions, feel free to go for it. MARTIN: While we're waiting for any of them to jump in, I will get us started with just a first question. I understand you announced at I/O this week some cool new features that come to search console, specifically around the site speed. I was just wondering if you could talk to that a little bit more when the rest of us  

#### [0:02:00](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=120) |  are likely to get it, and specifically,

what sorts of data is it that you're using in that? JOHN MUELLER: So "when" is always a tricky question. We obviously wanted to kind of open it up at I/O and have it all ready. But there's still some things that we're working out, more we'd like to get more feedback from people, which is why we set up that trusted test [INAUDIBLE].. So I'd sign up there. You're probably the first one to sign up.  

#### [0:02:30](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=150) |  And Barry is probably-- you and Barry

were probably fighting for the first place. I don't know what we've said specifically about the data. My understanding is it's based on a Chrome user experience report's data, so making it a little bit easier to get into there. Yeah. MARTIN: Is there any-- so are there any other cool things from search console that were announced that I may have missed? JOHN MUELLER: That were announced? So--  

#### [0:03:00](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=180) |  LIZZIE: Oh, but how to in FAQ--

JOHN MUELLER: How to in FAQ reports, they're coming to search console. MARTIN: Cool. JOHN MUELLER: So similar to the other enhancements that are in there-- LIZZIE: They're there now. JOHN MUELLER: I think they're here. LIZZIE: They're there. If you have to in FAQ on your-- JOHN MUELLER: Oh, you need to add the markup first. MARTIN: I have seen in another site the FAQ markups, so yes. Yeah. JOHN MUELLER: Cool. That'll be there. Then there are two things that are happening where I don't know exactly when they will come. That we talked about briefly.  

#### [0:03:30](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=210) |  On the one hand, the opt-in for

large images, that's something if you have large images and you want to have them show in Search, then you can do that. And the other thing is for Duplex on the web, the settings for that. So in particular, the aim is-- so Duplex on the web is a way to kind of streamline your checkout flow so that people can go to their Google Assistant and say, like, I want to buy this ticket from Expedia. And it basically goes off and does everything for you.  

#### [0:04:00](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=240) |  So I think that's pretty cool. And

the setting there is mostly a test account so that you can specify test account, username, password, that the machine learning system will use to kind of learn the checkout flow. MARTIN: Cool. JOHN MUELLER: So that's something where-- I think, for both of those, there's still a lot of work that needs to be done. And some of that might change over time. But that's at least what we've announced so far at I/O.  

#### [0:04:30](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=270) |  BARRY: John, I was a little bit

confused by the Duplex being a Google Search console because there's Duplex settings in Google by business also, like, do you want to get the phone calls? Is that going to move also, where you can have settings for both places at both locations? JOHN MUELLER: We specifically have it in Search Console because it's tied to your website. And we-- kind of it's something that could be available directly through Search as well.  

#### [0:05:00](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=300) |  So that's why you put it in

in Search Console and not Google My Business where Google My Business is more tied to like a physical business. So for that, it makes sense to have the phone call setting there. But the Duplex on the web is really tied to your website, which might or might not have a phone number that you can also call. So-- BARRY: Right. I was thinking about like, making a reservation, ordering food online from a local restaurant, does it use their online form? Or does it make a phone call or something else to make that reservation?  

#### [0:05:30](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=330) |  JOHN MUELLER: So based on what we

showed it at I/O, it uses, essentially, your web checkout flow, which is what we're-- like, the machine learning systems are trying to learn and trying to kind of do it in a way that is almost a higher level autocomplete, and that it goes through multiple steps. MARTIN: Outside of the kind of standard accessibility guidelines and the rank guidelines, specifically  

#### [0:06:00](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=360) |  for forms that you want to include

it in this, or will they be coming? Is that-- or it that a matter of wait and see? JOHN MUELLER: So the team wants to be able to work with websites as they are. So that's the general goal. I think we-- we obviously have various accessibility guidelines for forms to make it easier to autocomplete them. Those are things to do in any case. But specifically for this feature,  

#### [0:06:30](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=390) |  we want to work with websites how

they are and not require that they make any specific changes. All right. Any other questions from any of you who are joining here live? BARRY: Could We talk about Googlebot a little bit? JOHN MUELLER: Googlebot, OK. BARRY: So it went live technically two days ago, the new Googlebot, the new evergreen Googlebot. JOHN MUELLER: Oh, we've been testing it for a while.  

#### [0:07:00](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=420) |  BARRY: Fully. JOHN MUELLER: So it's hard

to say, like, it went live because there's always this kind of transition period. BARRY: So when did it go 100% live? Or is it still transitioning? JOHN MUELLER: I don't know. I'd need to have the other Martin here. But my understanding is it's 100% live. The only things that are not live yet are the testing tools. So in particular-- what is it? The URL inspection tool and the--  

#### [0:07:30](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=450) |  BARRY: Mobile-friendly structure data. JOHN MUELLER: Mobile-friendly

test, yeah. It's a bit weird that those aren't ready yet. But we need to make sure that the normal crawling and indexing works first, and then we switch those over too. So I expect that won't be too long. But I can't make promises for them. BARRY: SEOs could expect a little bit fluctuations in the search results just because you're able to index  

#### [0:08:00](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=480) |  a little bit deeper than you were

ever beforehand? JOHN MUELLER: No. I think websites that we could index before, they shouldn't see any change at all. This is really just for websites that are using or focusing on kind of these modern features in browsers that have content which we would otherwise have missed with the older version of Chrome. BARRY: That's the point, meaning now you're able to get to other websites or other content that you weren't able to. So maybe those websites are now, potentially, ranking a little bit higher and then pushing down some other websites.  

#### [0:08:30](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=510) |  So they may have an effect then,

maybe or maybe not. You've obviously done tests on this. JOHN MUELLER: Yeah, I doubt you would see a big effect on that. So that's something where a lot of the websites that are already kind of in competitive areas, they already try to make their content so that it works in Search anyway. So I could imagine there are some websites that are a bit-- I don't know-- focusing more on modern technologies. And obviously those areas, perhaps, things  

#### [0:09:00](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=540) |  shuffle around a little bit. But for

the most part, I don't see that changing anything in any way that people would notice. MARTIN: I think this was an answer to I/O during part of the announcement, but is it now using HTTP/2 exclusively? JOHN MUELLER: No, no. MARTIN: Any thoughts on when that may or may not happen? JOHN MUELLER: So HTTP/2 makes a lot of sense, in particular for browsers, where you have kind of this, like, multiple streams coming in at the same time.  

#### [0:09:30](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=570) |  And for crawling and indexing, we don't

really need it so much, because we catch a lot of the content anyway. So it's not the case that we need to kind of, like, do one quick fetch and render of the page with all of its embedded content right away. It's something that we could do independently and keep that content and kind of splice it together when we need it. MARTIN: That's [INAUDIBLE]. JOHN MUELLER: Yeah, so it's something we do bring up with the team because everyone's like, I don't know. But you're saying I should move to HTTP/2 or support it,  

#### [0:10:00](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=600) |  but you don't support it. Like, what's

up? It's all backwards compatible anyway, so that shouldn't be any problem. BARRY: And before-- I'm going to stop after this last question on Googlebot. A lot of people are asking, I see, at least on Twitter, about two waves of crawling for some JavaScript web apps, and that's not changing. Could you explain that so, like, people who aren't so technical can understand what that means? JOHN MUELLER: People who aren't that technical to explain  

#### [0:10:30](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=630) |  how JavaScript indexing works-- I think that'll

be tricky, yeah. BARRY: Martin's there, so ask Martin to explain it. MARTIN: It sounds like [INAUDIBLE] here. JOHN MUELLER: Is someone coming? We have one more person joining us. Anyway, with JavaScript indexing, one of the tricky parts is we pick up the HTML content initially, and we can index that right away.  

#### [0:11:00](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=660) |  And rendering sometimes takes a little bit

longer. So sometimes that's a matter of, I don't know. Depending on the site, depending on what all is happening, it can take-- I don't know-- minutes, hours, a few days, something like that with this kind of delay there. So in particular for news websites, I'd still recommend that you have some kind of static content because we need to be able to index status quickly as possible. But for any website that's more stable than kind  

#### [0:11:30](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=690) |  of this delay of a day or

two, that won't change much. BARRY: I've previously heard it was much longer than a day or two. So that's-- JOHN MUELLER: It really depends. And it's something where the team is working on reducing that to make it as fast as possible, obviously. But it's not the case that you have to wait a month until your content is indexed. It's really kind of more a matter of, like, somewhere between a few minutes to maybe a couple of days.  

#### [0:12:00](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=720) |  BARRY: All right, thank you. JOHN MUELLER:

All right. Let me just take a look at some of the questions that were submitted. Oh, big question about thin content-- "We have a clothing e-commerce site." Let's see, "with," I guess, "different products that are very similar. And some of these are crawled but not indexed.  

#### [0:12:30](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=750) |  It wouldn't be a good idea to

exclude," I guess, "the different variations from crawling and indexing." So in general, especially for e-commerce sites, what we recommend is that you try to focus on making the product pages stand on their own and being really unique products, unique things that people are actually searching for. So if you have different variations that could be something like sizes or different colors,  

![](https://i.ytimg.com/vi/PBAtvzYIbP8/hq1.jpg)



#### [0:13:00](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=780) |  then I would kind of fold those,

all of those, into the same product page, so that we tend to have fewer pages to crawl. They can be more visible in Search because it's more concentrated. And then you don't have to worry about the situation, like, is my greeting page also being indexed or not? You just have one product page, and it has different variations, different attributes that can apply to that. MARTIN: Specific to that answer in diagnosing it [INAUDIBLE] the process of fixing it, have you  

#### [0:13:30](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=810) |  got any plans to put the items

that are in the coverage portion search console into an API, where we can check this on a page-level basis, independently of the frontend? And as a follow-on to that, there's only ever 1,000 lines given in that, when there's a couple 100,000 pages excluded or crawled but not indexed. It would be really helpful to get more than that one [INAUDIBLE]. JOHN MUELLER: Plans-- I don't know about plans. We do get that question a lot. So that's something where I would  

#### [0:14:00](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=840) |  love to see more features in the

API. I think that helps a lot, especially the larger sites that can pull that data out, and you work through it. I think that would be really useful. But I don't know what the exact plans there would be. I don't know. Do you know? LIZZIE: Me neither, no. JOHN MUELLER: No? LIZZIE: No, haven't heard anything. JOHN MUELLER: Good. Then I'm not missing out.  

#### [0:14:30](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=870) |  "My site's dropped for most of the

queries that it ran for. For some of the queries, non-branded remain strong." Let's see, "Will Google ever look at demoted content that was improved, in the meantime, to see if it fulfills the user needs better for previously ranking queries?" Yes, definitely. So-- here comes another Martin.  

#### [0:15:00](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=900) |  So definitely. If something changed on your

website, and we crawled and reindexed it, then we will take that into account. It's not that we're going to stop crawling just because we kind of stopped showing something invisibly. So you don't need to noindex it. You don't need to block it by robots.txt. The general idea is if you have content  

#### [0:15:30](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=930) |  that you do know you need to

improve, then I would just improve it, ideally. Or if you really can't improve it, because it's a lot of content that you're left saying, well, I don't know what to do with this content, then maybe just removing it is fine. But it's not the case that we would not update the website or update the content when we see it as being bad ones. MARTIN: If the user wants to speed up that process, would effectively render help for pages [INAUDIBLE]??  

#### [0:16:00](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=960) |  JOHN MUELLER: Yeah, yeah. So in the

URL inspection tool, you can submit for recrawling or reindexing. That definitely helps, but that's on a per-page basis. So segment file would probably help more if it's a broader change. SPEAKER 1: Hi, John. JOHN MUELLER: Hi. SPEAKER 1: Regarding content, since we're on that topic, I do have a couple of questions. And the first one I'm hoping is a lot more straightforward. So for all intents and purposes, for the sake of cleaning up or removing thin or low-quality content  

#### [0:16:30](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=990) |  pages from a website, is noindexing that

content basically as effective as just taking the entire page down? JOHN MUELLER: Yes. For the [INAUDIBLE] index, it's effectively down. It's still on your website. So in particular, if it's something that you say you want to keep it on your site because you think users on your site might want to find it when they kind of navigate within your site, then fine.  

#### [0:17:00](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=1020) |  It removes it from the Google index.

So we don't show it in the search results. And from there, we don't really care about what is actually on those pages. SPEAKER 1: Oh, great, great. And a second one-- let me put my tinfoil hat on here because I haven't really heard of it being spoken of before. But it's the idea of content dilution. So for example, I have a service that I use Copyscape basically to check for copies of my content across the web.  

#### [0:17:30](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=1050) |  And I've seen many cases where we'll

get absolutely crazy garbage domains. Really, they look really sketchy, PDF files stuffed full of spun versions of my content, many versions of PDF files, many versions of garbage landing pages that are actually cloaked and will redirect to something sketchy, like online drug sales. Anyways, point being is, would it be-- is it a possible thing that certain content gets spun so much in so many instances of garbage spam  

#### [0:18:00](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=1080) |  that the original content gets mistakenly identified

as part of that too, if that makes any sense? JOHN MUELLER: I don't see that happening. So that's something-- we've seen that situation over and over again. I think pretty much every popular site is used as a seed for, like, a lot of these spammy sites that basically just scrape and spin content. So I don't see that causing any problems.  

#### [0:18:30](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=1110) |  SPEAKER 1: So there is a way

to differentiate the fact that the source content is legitimate. And it's not part of the fact that you see it 200 other times in other sketchy or spammy ways. JOHN MUELLER: Yeah, I don't see that being a problem. Yeah. We look at the website overall as well, when it comes to quality. So if overall the website is good, then we should be able to treat that content appropriately. If overall the website is low-quality,  

#### [0:19:00](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=1140) |  like these spammy scraper sites, then we

should just treat that as spam and handle it like that. SPEAKER 1: That's good to know. Thank you, because that's certainly a factor out of everyone's-- every web masters control. JOHN MUELLER: Yeah. SPEAKER 1: Great. Thank you. JOHN MUELLER: I think that same thing happens with links as well. Like, a lot of the spammers will basically take links to popular sites and put them on their sites and say, like, look, I'm linking to CNN. Therefore, my content must be legitimate.  

#### [0:19:30](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=1170) |  And that doesn't change anything. So if

you see random scraper sites linking to your site, that's not really something you need to worry about. SPEAKER 1: That's a relief. Great. Thank you. JOHN MUELLER: All right. Whoa. Here's one for Martin, just in time. "Does the change for Chrome 74 impact Google's ability to trigger infinite scroll on pages?" MARTIN SPLITT: To a certain degree, yes. Basically, there's not a fundamental change  

#### [0:20:00](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=1200) |  in how we're doing it. But as

we now support a bunch of features that you might use, such as the Intersection Observer, for instance, yes, you can now use that without a polyfill in Googlebot. However, that being said, make sure to test this. I know the testing tools haven't been updated yet. But make sure that the content you care about is indexed as being indexed. And honestly, if I were you, I would just keep the polyfill for a couple of more-- I don't know how long.  

#### [0:20:30](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=1230) |  We don't have a timeline. But keep

the polyfill around. There might still be benefits for having it until you can definitely test our testing tools, so yeah. JOHN MUELLER: There was also a question earlier, I think from Barry. MARTIN SPLITT: Hi, Barry. JOHN MUELLER: "Did we switch to the new version of Chrome completely for crawling and indexing?" MARTIN SPLITT: Yes! LIZZIE: And when was it? MARTIN SPLITT: Yes! [LAUGHING] So the thing that we do is, as you  

#### [0:21:00](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=1260) |  know, we keep experimenting on new stuff

with Googlebot, on very, very small sets of URLs, basically, very small samples, sometimes just like, basically, a couple of URLs, really. But we continuously improve or increase the amount of the sites that we will be crawling with Googlebot over the last couple of months, very carefully monitoring what was happening. The things-- the issue that we confirmed that happened a couple of months back  

#### [0:21:30](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=1290) |  has nothing to do with rendering. But

yes, so we have been continuously increasing the sample size of the URLs that we were crawling with the new Googlebot and have ramped it up to 100% already. I don't know the exact day when we did, to be honest. I don't have it on top of my head, because it just went smoothly and-- BARRY: Was it from like, 10% to like 100%? Or was it like-- MARTIN SPLITT: No, no, no. It was less than 1%, 1%, 10%, 20%, 30%, 40%, 50%, 75%, 100%,  

#### [0:22:00](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=1320) |  I think, were the steps that I

have observed. BARRY: So if you could send me an email with exact dates and percentages-- MARTIN SPLITT: Sorry? BARRY: If you could send me an email with exact dates and percentages, that would be useful-- I'm just joking. MARTIN SPLITT: I would have, but I don't know if we have that much-- BARRY: I'm joking. I'm joking. MARTIN SPLITT: --the previous crawls, but basically, it was a pretty rolling thing.  

#### [0:22:30](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=1350) |  I just sampled it at random points

of time and checked in with the rendering team. Zoey is in the rendering team, the person that was yesterday with me on stage for that visit to this specific session. And I was as excited about it as everyone else was, so I was like, so Zoey, how [INAUDIBLE]?? So I have observed these things, but I don't think I know the dates specifically. BARRY: But the whole process started a few months ago, or a year ago, or-- in terms of the 1% testing? MARTIN SPLITT: Did we say that? JOHN MUELLER: I have no idea. MARTIN SPLITT: I don't know.  

#### [0:23:00](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=1380) |  So I remember I talked to Zoey

in December last year. And I think that was by-- no, it was in November. November, we were at 10%. BARRY: Interesting. Very nice. And the indexing bugs have nothing at all to do with this at all? MARTIN SPLITT: We're talking indexing, not rendering. BARRY: I know, but who knows? [LAUGHING] They're all connected in some way. MARTIN SPLITT: Fair question, but no. BARRY: Awesome. All right, and the caching has nothing  

#### [0:23:30](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=1410) |  to do-- the cache date has nothing

to do with this either? JOHN MUELLER: No. MARTIN SPLITT: I'm still quite surprised how many people can't ask about cache. Cache is like a nice convenient feature that we offer, but it is not related to what-- BARRY: I get-- I'm sure you get it a lot. But I get like 5 to 10 emails a day, saying, why is the cache date a Google log? Like, a month ago, like, from a month ago, I'm like, I don't know. JOHN MUELLER: So you're saying the cache date is related to the emails that you get? BARRY: Yes, direct correlation.  

#### [0:24:00](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=1440) |  MARTIN SPLITT: Those are your emails based

on the cache date? MARTIN: You can stop. MARTIN SPLITT: [INAUDIBLE]. MARTIN: You can stop, Martin. JOHN MUELLER: But yeah, OK. Totally different question-- "We're selling variations of Mexican flags." MARTIN: Cool. JOHN MUELLER: "The variations are linked with Mexican tables-- Mexico table flag, Mexico hand waving flag, et cetera.  

#### [0:24:30](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=1470) |  Our preferred page in Search is cross-linked

from the variations with Mexico. Is this anchor text OK, or should we use a Mexico flag for our preferred flag? I think you can link either way. We do use the anchor text from links as a way to understand the context of the page a little bit better. But if your whole website is about flags, you don't need to mention flags of every city in every country that you have there. MARTIN: Wouldn't it be the flag type  

#### [0:25:00](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=1500) |  that would be probably your preferred anchor

texting in that example? Table flag-- JOHN MUELLER: Sure, yeah. Yeah, yeah. Yeah, it depends on how you have it set up. If you have one page for Mexican flags, and from there, you linked to the different variations, then sure. "The indexing issue," or "an indexing issue is that stories seem not to be surfacing  

#### [0:25:30](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=1530) |  in a realistically timely manner, particular for

keywords, individuals for whom we have very solid ranks. Stories are popping up a day or two later or not at all." "We're seeing fairly good outlets surfacing. Some, the results are several days old or even weeks old in favor of other outlets with more newsy content. Is there some other indexing issue with newsy content?" I'm not aware of any issue. Do you guys know?  

#### [0:26:00](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=1560) |  No? MARTIN: I can-- so this is

one of the things I work on every day. And there are occasional issues, but nothing like that. JOHN MUELLER: It's good that you're here. It's good. And it is always good to have kind of a neutral confirmation. MARTIN: Yeah, and to be fair, it's an extension to that question, though. There is still the outstanding bug of Google picking up incorrect dates on news items. And I'm interested whether or not the new renderings will make any difference to that because my suppositions is picking up incorrect dates  

![](https://i.ytimg.com/vi/PBAtvzYIbP8/hq2.jpg)



#### [0:26:30](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=1590) |  from app containers, where it is rendering

the contents of them. It may or may not be related to what this question asker is asking. But certainly, I have seen examples where a news [INAUDIBLE] something, the wrong date picked up. And that news piece, [INAUDIBLE].. So that may be something that [INAUDIBLE] should look at, is what Google's perceiving the [INAUDIBLE].. JOHN MUELLER: Howdy, Michael. MICHAEL: Hi!  

#### [0:27:00](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=1620) |  Thank you for answering my question. It's

just, I think, in the last 48 to 72 hours, like, no complaints about sort of the sketchy outlets in my sector surfacing, because sometimes you wonder, like, where is this coming from? They're are all legitimate outlets, but definitely seeing stories where there is kind of news in our sector. But there's stuff from a week ago.  

#### [0:27:30](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=1650) |  And then as you keep sort of

scrolling down, it's like a week, two weeks, a month ago. And you're like, scratching your head, saying, there is some new stuff going on. And then it does pop up sort of a day later, sometimes not at all though. Yeah. JOHN MUELLER: Yeah. I don't know. Sometimes we do have weird fluctuations that happen. So it might be something that's just something temporarily out of sync. With the dates question, one thing I heard from someone at I/O, which  

#### [0:28:00](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=1680) |  I don't know is still the case,

is sometimes there is a mismatch between the top story state and the normal search results state. That's something that I thought we had fixed, but I need to look into that because that's still an issue. "Great to see how to roll out to the web. I know there's a search appearance filter and search console for how-to snippets that show in search results.  

#### [0:28:30](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=1710) |  But what about when it rolls out

to smart displays?" "Will there be a way to measure that in Search Console? If so, will the voice query show up? And will the recording show you how many steps the user got through?" I have no idea. Anyone? Any takers? I have no idea. A lot of these things we're still very early stages.  

#### [0:29:00](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=1740) |  So we'll have to see how that

works out. I'm curious to see how that ends up working with especially the smart displays. I can see that being pretty useful. But I don't know how that will show up in Search Console. We'll see. "Is crawl budget more a matter of crawl depth or of a volume of pages?" So for us, crawl budget is essentially how many URLs we would fetch from a website on a date.  

#### [0:29:30](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=1770) |  So that's kind of the, I guess,

the volume of requests that we'd be able to get. For most websites, that's not an issue because we can get as much as we want. And for really large websites, it is more of a problem because we feel we're more limited by the server resources. And we don't want to cause problems by trying to get all of their fresh content as quickly as possible. And usually, the hard part there is not so much  

#### [0:30:00](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=1800) |  finding that limit but balancing the needs

of what we would crawl, during that time. So on the one hand, we want to get all of the fresh stuff. So we'd have to look at the homepages regularly, the more higher-level category pages regularly, because from there, the content is linked. Then we need to get that freshly linked content. But we also need to update the existing content over time and kind of make sure that we're not missing anything that otherwise isn't directly linked on the page.  

#### [0:30:30](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=1830) |  And that also includes all of the

embedded resources that we pulled in from JavaScript. CSS, Images, all of that comes into play there too. So it's not crawl depth. Essentially, it's more that the depth we try to pick up by scheduling the different pages. It's really just purely a matter of number of requests that we make to the server so that we try to stay below a number that ends up causing problems for the website.  

#### [0:31:00](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=1860) |  MARTIN: Can we specify something about that

answer? JOHN MUELLER: Sure. MARTIN: You started it by saying, we look at this certain number of URLs for each one-- for each site that will crawl. And you mentioned you were also a couple of times through that. Is that tied to a hard number of URLs or a token transfer [INAUDIBLE]? It is much that if I reduced a page's website, a website's pages, from 10 megs to 300k, with that dramatically increase the number of pages that could crawl? JOHN MUELLER: I don't think that would change anything. MARTIN: So it's a pure URL limit?  

#### [0:31:30](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=1890) |  MARTIN SPLITT: It's a request. It's not--

JOHN MUELLER: Yeah, what happens-- so what sometimes happens is if you have a large response, then it just takes longer for us to get that. And with that, we'll probably crawl less because we're trying to avoid having too many simultaneous connections to a server. So if you have a smaller response size-- and obviously we can get more simultaneous requests, and we could theoretically get a little bit more-- but it's not the case that if you  

#### [0:32:00](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=1920) |  reduce the size of your pages and

suddenly, it will start crawling. MARTIN SPLITT: So it's also that when the response takes a long time, it's not just the size of the response. It's also the response time. Servers tend to respond slower when they're overloaded or about to be overloaded. So that's also a signal that we're picking up, like, ooh, this takes a really long time to [INAUDIBLE] data on the server. Maybe we should look into the crawl limits, the whole scope of this particular server so that we're not talking the server over. MARTIN: But that also counted for resource on the page  

#### [0:32:30](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=1950) |  that we serve, potentially, by a third

party was being slow to respond. MARTIN SPLITT: Oh, third party. JOHN MUELLER: No. We look at it on a per server level. So if you have contact from a CDN or from other networks, other places, then that would apply to their [INAUDIBLE].. MARTIN: Cool. JOHN MUELLER: Essentially, because how slow an embedded resource is doesn't really affect the rest of the crawling on this site.  

#### [0:33:00](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=1980) |  MARTIN: Thank you. JOHN MUELLER: Sure. "We're

trying to clear our sites from being banned on SafeSearch. Some of our pages are not available under SafeSearch in Europe but not available in the USA. Is geography a part of the factor that determines what is adult content and what isn't?" I have no idea. MARTIN: SafeSearch is special. JOHN MUELLER: My understanding was that SafeSearch is SafeSearch, and it's not different across different locations.  

#### [0:33:30](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=2010) |  But it sounds like you're seeking something

different, so it's hard to say. I don't know. I can ask the team to see if we can figure something out for the next one. "Is the ability to pull all search console data into Data Studio anywhere on the road map, especially PageSpeed and errors?" So we don't even have PageSpeed in the UI yet. So that would be a little bit early. But I think in general, I'd be a fan  

#### [0:34:00](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=2040) |  of having all data available for DPI.

But it takes a lot of work to get that there and to maintain all of that. So I don't know. MARTIN: There is a Community Connector for Lighthouse at least, for Data Studio. But the Lighthouse team at Google probably could do a better job of integrating that as well. JOHN MUELLER: You know anyone from Lighthouse? MARTIN SPLITT: I do. LIZZIE: Yes. MARTIN SPLITT: You should tell him I have to know that [INAUDIBLE].  

#### [0:34:30](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=2070) |  JOHN MUELLER: Cool. MARTIN SPLITT: Oh, I'll

ping them. JOHN MUELLER: Oh, he's doing it right now. [LAUGHING] MARTIN: If you could just CC me on there, Martin. MARTIN SPLITT: No, because I'm going to use Instant Message [INAUDIBLE]. JOHN MUELLER: Let me just see some questions here, live. "I've been noticing that content hidden under Tabs on the mobile site is not showing the same way in the search results, as was promised."  

#### [0:35:00](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=2100) |  What gives, Google? So what generally happens

with content that is hidden behind a tab is we will use it for indexing. We'll use it for ranking. So that's something from, especially with the mobile first indexing, when we index the mobile version of the page, that's not a problem. So it shouldn't affect ranking. But what will happen is we won't show it in the snippet.  

#### [0:35:30](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=2130) |  A particular-- the snippet, we try to

separate that out because if we show something the snippet, it feels like we're really promising the user that they'll see this when they visit that page. So if we know that this is kind of hidden by default, then we won't show it in a snippet. But from a ranking point of view, it'll rank normally. So that should be fine. "I have 300 URLs and robots.txt file with disallowed URL parameter. They also have noindex, nofollow tag.  

#### [0:36:00](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=2160) |  But in Search Console, they're still shown

as indexed. What's up?" So you're doing almost too much to make that happen. In particular, if it's blocked by robots.txt, we don't know if there is a noindex tag there. So what will happen is we will index the URL without its content. And that's probably what you're seeing in Search Console, as the index count there.  

#### [0:36:30](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=2190) |  So what you need to do to

prevent those from being indexed at all is to allow crawling and, instead, to only use the noindex meta tag on the page. And then as we recrawl those pages, we'll see noindex, and we can drop them completely out of the index. And again, just to be clear, it's not that we're indexing the content on those pages that are disallowed from crawling. It's really just we're indexing the URL. And we're picking it up based on links to that page.  

#### [0:37:00](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=2220) |  Maybe we're showing the anchor text as

a title for that URL. But the snippet should be, like, we can't show you anything, and it links to the homepage on robots.txt. "The Search Console showed different menus to different websites. For example, I have one with a Products category, an e-commerce site, and not in another one." Yes. So we try to show you the categories where you have data  

#### [0:37:30](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=2250) |  for. So if you don't have specific

structured data types, then that doesn't make sense to show you that report, because there's nothing to show. So some sites will have things like products if they have product structured data that we picked up, or how to, if you have how-to information marked up. But other sites won't have that in Search Console. "Why doesn't Adobe Reader rank for Click Here?" I don't know. I do not-- what are you trying to find when  

#### [0:38:00](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=2280) |  you search for "Click Here"? That seems

like a very weird query to search for. MARTIN: It's a historical reference to this. BARRY: I should elaborate? No. I was just referencing your comment about anchor text and links and stuff. JOHN MUELLER: I don't know. I have no idea. What should we show for "Click Here"? It seems like one of those queries where you can argue what it should be showing.  

#### [0:38:30](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=2310) |  It's so ambiguous. BARRY: Yes. MARTIN: You

should [INAUDIBLE],, which seems an appropriate answer. JOHN MUELLER: Oh, yeah, I would, someplace to click, I guess, yeah. "Info operator, it's gone now. Can you confirm that in the site move or page move, URL Inspection tool, we can expect the new URL to be canonical, specifically when the site colon queries  

#### [0:39:00](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=2340) |  [INAUDIBLE]?" I'm not completely sure what you're

asking. But yes, the info colon query operator is gone. I think that's been gone for a while now. We recommend using the URL Inspection tool to look up the canonical if you're using that. Look at the canonical. The site colon operator doesn't show you the canonical. So with the site colon, especially  

#### [0:39:30](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=2370) |  if you've done a site move, and

we'll try to be helpful and say, like, if you're searching for the old domain, then we'll show you the old domain, even though we've processed that site move already. So that's sometimes a little bit confusing. So with a site colon operator, you tend not to see the canonical. Sometimes if you look at the cache page, you'll see that we cache the new URL instead, which is also a sign that the site move has gone through.  

![](https://i.ytimg.com/vi/PBAtvzYIbP8/hq3.jpg)



#### [0:40:00](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=2400) |  "That was a great section at I/O

with Martin." Ooh. LIZZIE: Nice. MARTIN: Yeah, that one. JOHN MUELLER: Oh! MARTIN: That one. [LAUGHING] JOHN MUELLER: Yeah, I really love that session. "When testing a landing page URL, in the Structured Data Testing tool, it reports error in breadcrumbs, but pasting the source code at the same page if it doesn't show those errors anymore. I checked through the code and can't find what the problem is." I don't know. MARTIN SPLITT: It sounds like a bug on our side. JOHN MUELLER: That sounds like a bug.  

#### [0:40:30](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=2430) |  MARTIN SPLITT: You can-- yeah, I'll do

that in a second. What you can do is you can post the-- if you feel like it, you can post the URL here. JOHN MUELLER: They have the URL. MARTIN SPLITT: It has it? [TONGUE CLICK] Perfect. I'll take a look at the URL and see if I can spot the problem. And if it's a bug in Structured Data Testing tool, I'll be happy filing it accordingly. JOHN MUELLER: Cool. And thanks for the feedback on the session.  

#### [0:41:00](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=2460) |  "Google is not showing any lazy loaded

image alt text. What am I doing wrong? I followed Google's advice on lazy loading and added Data Alt and no script to my code. Rendering is fine." And there's a link to a screenshot. That sounds like you want to look at it, I guess. MARTIN SPLITT: Yes. Huzzah!  

#### [0:41:30](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=2490) |  "Sorry, the page does not exist." Hm.

So generally speaking, I am surprised. So if I understand correctly, your lazy loading the images, which means you have the images in the original source code. And that should include the alt text as well. You don't really lazy load alt text, normally. You should have that in the regular HTML. If you have a noscript fallback, then that should also just show up.  

#### [0:42:00](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=2520) |  And I'm not exactly sure what's happening.

But if you mean like your infinite-- like, an infinite scroll kind of thing and load the entire content dynamically, then that can happen. There is only so much that we do in terms of infinite scrolling. We need to improve our guidelines for that one. I agree. We will do that, I guess, now that you sit next to me and nod. That probably means I have more now. LIZZIE: Sounds good to me.  

#### [0:42:30](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=2550) |  MARTIN SPLITT: Lizzy to Martin-- so yeah,

if it's lazy loading, then that's something that can sometimes go wrong a little bit, especially because we can't just, like-- obviously, we can't infinite scroll. Surprisingly, you can't just take and set a time to do that. But I don't have good guidance on that right now for you here. Impromptu, we will have to look at this in more detail. That's what we planned on doing after I/O. JOHN MUELLER: Cool. All right.  

#### [0:43:00](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=2580) |  "John, can you tell me when Google

is going to fix the cache error? Not a single web page is cached [INAUDIBLE] 10th of April. And it's affecting our ratings as well." So there's a bit more here. So Martin says web pages are being cached. So I've seen this on Twitter a few times. And I looked at some of the sites that do update fairly frequently, and they seem to be cached fairly fine.  

#### [0:43:30](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=2610) |  So I think that this-- what you

might be seeing is just some side effect of some of the indexing issues that we've had in the past. And maybe it's just taking a little bit more time for the cache to update. But in general, the Cache page is not reflective of the Index page. So that would not be affecting any ranking. So if you're seeing issues with the rankings, then that would not be from the Cache page. "We're a news website, and we disappeared  

#### [0:44:00](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=2640) |  from the top stories. We think Google

is confusing our site with the forum, since we have structured data. What can we do?" I guess the structured data is news article structured data. So that will be fine. LIZZIE: Wouldn't it perform like it's [INAUDIBLE] page? JOHN MUELLER: I don't know. So in general, I think the important part to know is we don't show whole pages in the Top Stories section.  

#### [0:44:30](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=2670) |  It's an organic search feature. And sometimes

we show these pages there. Sometimes we don't show them there. It's not that there's anything manual on our side where we'd say, these sites would not be shown in the top stories just because they also happen to have a forum or some kind of discussion on those pages or in the site somewhere, as well. So that's something that would be totally unrelated. I think we've had a question from you a few times  

#### [0:45:00](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=2700) |  about the Top Story section. It's just

really-- it's an organic search feature. It's not that there is something manual that's blocking your site, in particular, from appearing there. MARTIN: Oh, cached pages. JOHN MUELLER: Oh, no! Your [INAUDIBLE] cached page, error 404. MARTIN: Yeah. JOHN MUELLER: I think-- MARTIN: I'm not saying that would have any effect on ranking whatsoever. I am just agreeing that I am certain 404 [INAUDIBLE]..  

#### [0:45:30](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=2730) |  MARTIN SPLITT: The thing that I would

like to call out is this question had two parts. MARTIN: Yes. MARTIN SPLITT: And it's like, it's not caching websites. And that's, like, hurting my rankings. And those two are not related. MARTIN: Completely disconnected, as far as I'm concerned as well, yes. JOHN MUELLER: So there we have some links. We have seen this from a few people with the Cache page. So I know there are people at Google looking into this to see what is happening there, specifically. But like I mentioned, the Cache page  

#### [0:46:00](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=2760) |  is not reflective of what we have

indexed. A pretty direct way to see that is all of the JavaScript-based websites we cache the HTML version of the page. We don't cache the regular version of the page. So those are completely different pieces of content there. We do try to keep the cache more or less up to date so that we can show it to users when they need to look at the Cache page. But for the most part, it's really separate from the rest of crawling, indexing,  

#### [0:46:30](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=2790) |  and ranking. Cool. I think we made

it through all of the questions that were submitted. Anything else from any of your sides, any of you? MARTIN: From my side, multiple people have asked it, and I asked it last time I was sat here as well. It is just, basically, I want everything else that's in Search Console, built on an API, or at the very least, pushed across the Data Studio. That's, yeah.  

#### [0:47:00](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=2820) |  JOHN MUELLER: Can you ping someone on

that, Martin? MARTIN SPLITT: It just pinged. MARTIN: Again, CC me. MARTIN SPLITT: Absolutely. No, I think we're talking with the Search Console people quite a lot. And we'll move forward from there. JOHN MUELLER: We hear from a lot of people that they want more stuff in the API. So we always push for that. It's always tricky because there are a limited number of people. So on the one hand, add more features to Search Console. Move some of the old features from Search Console  

#### [0:47:30](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=2850) |  to a new one. Or should they

do more on the API? It's hard to find a balance there. MARTIN: I do have a better question than that though. You did an [INAUDIBLE] a couple of months ago, or a month or two ago, with the indexing API for jobs on something else. MARTIN SPLITT: Last June. LIZZIE: Last June. MARTIN: Thank you. The API Jobs is the only what I cared about, so that was I remembered it. And any plans to roll that out any further? JOHN MUELLER: I don't know. I don't know. I think, since it's still fairly new, it's  

#### [0:48:00](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=2880) |  something where I expect the team will

be collecting feedback over time, to see how it works out, how people are able to implement it or not, and also to see, does this really change the way that we can crawl an index content? Or is it just like another contacts feature that people have to implement that doesn't actually change things in a way that it affects them? So that's something where I expect to--  

#### [0:48:30](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=2910) |  for us to kind of collect feedback

over a while, and then at some point, to figure out, can we expand this to other kind of structure data types, where it makes sense to get this kind of content fresher? Could we expand it to the general web as well? I don't know. It's really hard to say. How's it working for Jobs? MARTIN: The concept of it is fantastic. I wouldn't comment as to how well it works or doesn't work, because I haven't looked at that. But it would answer a lot of other problems, not specifically the general one, but rapid indexation  

#### [0:49:00](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=2940) |  of new stories or something that any

site that's dedicated to that struggles with. I think we all try and give you guys as many signals as possible to come and index something. But then these sites all have tens of millions of pages as well. And I understand the crawl budget on them is a finite resource. So if we had a way of just saying, hey, listen, these are the 1,100 news articles that we've published today, that would be hugely beneficial because it would save us spending inordinate amounts of time,  

#### [0:49:30](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=2970) |  experimenting with things like [INAUDIBLE] and historically,

[INAUDIBLE],, and so on, so forth. JOHN MUELLER: So it's specifically for news sites, news content. MARTIN: Yeah, I don't want to restrict it just to that. But I think anywhere where it's important to have the up-to-date and immediate information so outside of the news, that might be possible. But for me, I'm thinking, yeah. JOHN MUELLER: Cool. I don't know, Barry. What do you think? Does your content need to be indexed faster? BARRY: No, absolutely not.  

#### [0:50:00](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=3000) |  The second I post it, it's literally

indexed within a few seconds. It's amazing. MARTIN: I know, but despite-- Barry produces-- BARRY: Yeah, five pieces of content a day. MARTIN: [INAUDIBLE] pieces of content a day, which is phenomenal. But when you extrapolate like that, add to 1,000 or 1,500, some of them get missed. BARRY: I'm not a content spammer, so-- MARTIN SPLITT: Don't think that as a challenge, Barry. BARRY: I have a question for all of you. You were all at I/O, right, all of you? JOHN MUELLER: Yeah. BARRY: Or no? Could you tell us, each one of you tell us  

#### [0:50:30](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=3030) |  what was the most important or most--

what announcement was the most exciting for you guys, individually? MARTIN SPLITT: I have a very clear opinion on that, but I'll shut up. LIZZIE: No, go. MARTIN SPLITT: Oh, the Googlebot-- LIZZIE: For me it was the live-captioning videos. JOHN MUELLER: Oh, yeah, the live captioning. MARTIN SPLITT: So it was pretty cool. LIZZIE: He said, "personally." It didn't have to be search-related. MARTIN SPLITT: Fair enough. Then live captioning, definitely live captioning. JOHN MUELLER: Yeah, that was pretty cool. Like, if we had that now, we wouldn't  

#### [0:51:00](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=3060) |  have to have people captioning these Hangouts,

right? Sorry. I mean, I love that people are-- [LAUGHING] --transcribing these Hangouts. I think that's fantastic. MARTIN: Ooh! JOHN MUELLER: I think that [INAUDIBLE].. MARTIN: Someone's going to write that at some point in the next 24 hours to get published. JOHN MUELLER: Wow. BARRY: Doesn't YouTube transcribe them automatically? JOHN MUELLER: I think it's really cool, especially  

#### [0:51:30](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=3090) |  kind of a combination of that with

translations. I think that would be really cool. MARTIN: Sounds like a spammers delight. JOHN MUELLER: I don't know. MARTIN SPLITT: Now that I think about it, I think the most useful was live captioning. And the coolest, I think, was the AR from Search. JOHN MUELLER: Oh, the AR. LIZZIE: The shark? MARTIN SPLITT: The shark. LIZZIE: The shark? JOHN MUELLER: That was amazing. BARRY: You think that was cool? Interesting. I would have gone with the podcast [INAUDIBLE].. MARTIN SPLITT: Yeah, I find that cool. [LAUGHING]  

#### [0:52:00](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=3120) |  BARRY: Sharks are cool. Yeah, definitely, sharks

are cool. MARTIN SPLITT: What? BARRY: Sharks are definitely cool. MARTIN SPLITT: Sharks are cool, but also the fact that they use the 3D graphics format that I have been advocating for a couple years back. So that's pretty cool. BARRY: There you go. I would think the pod for me was probably the podcast, "Audio Searching in Audio Files," which obviously has to be good with transcribing automatically. So that was pretty cool. JOHN MUELLER: Yeah, I think the podcast was also really neat.  

#### [0:52:30](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=3150) |  Yeah. I don't know. I think there's

lots of cool stuff. MARTIN SPLITT: It's so hard to pick. JOHN MUELLER: What's always, I find, a little bit frustrating with I/O is that we all try to get as much stuff launched by I/O as possible. And we do manage to get a lot of stuff launched there. But sometimes, like, it's almost ready. And we want to kind of get people excited about it, but it's not ready yet. And I think the worst ones are the ones, like, oh, it's live! And you can have it if you're in the US.  

#### [0:53:00](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=3180) |  MARTIN: Or take a photo of this

QR codes for this wonderful access. JOHN MUELLER: I didn't [INAUDIBLE].. QR codes are cool too. Cool. So I think with that, we're pretty much out of time. If more questions come up, feel free to drop them into the next Hangout. I probably have some set up for next week or the week after that. Otherwise, feel free to jump by the Webmaster Help Forum and post there, or try to reach us  

#### [0:53:30](https://www.youtube.com/watch?v=PBAtvzYIbP8&t=3210) |  on Twitter, where we're all hanging out

as well. Thanks, everyone. MARTIN SPLITT: Bye! SPEAKER 3: Safe flights home. Bye. JOHN MUELLER: Thanks.  