[![English Google Webmaster Central office-hours hangout](https://i.ytimg.com/vi/x0qLJRivdmY/maxresdefault.jpg)](https://www.youtube.com/watch?v=x0qLJRivdmY)

## English Google Webmaster Central office-hours hangout

Join us for a Google Webmaster Central office hours hangout on Jun 14, 9am CET 

https://www.timeanddate.com/worldclock/fixedtime.html?iso=20190614T09&p1=268



This session is open to anything webmaster related like crawling, indexing, mobile sites, internationalization, duplicate content, Sitemaps, Search Console, pagination, duplicate content, multi-lingual/multi-regional sites, etc. Add your questions at https://www.youtube.com/user/GoogleWebmasterHelp/community



To join live, watch out for the link here once the event starts, and use a webcam + headset. Feel free to drop by - we welcome webmasters of all levels!



Subscribe to Google Search Central â†’ https://goo.gle/SearchCentral



#### [0:00:00](https://www.youtube.com/watch?v=x0qLJRivdmY&t=0) |  JOHN MUELLER: OK, welcome, everyone, to today's

Webmaster Central office-hours hang out. My name is John Mueller. I'm a Webmaster Trends Analyst here at Google in Switzerland. And part of what we do are these office-hours hangouts where webmasters and publishers can jump in and ask any kind of web sites, web search related question that maybe is ideally connected to web search.  

#### [0:00:30](https://www.youtube.com/watch?v=x0qLJRivdmY&t=30) |  As always, a bunch of things were

submitted ahead of time, which is great. But if any of you want to get started with the first question, you're welcome to jump in. RICCARDO: OK, jumping in. JOHN MUELLER: OK. RICCARDO: I found yesterday that somehow power links from our website that are not included in the top link [INAUDIBLE] internet paging Google search console. We are sending this link through the site map.  

#### [0:01:00](https://www.youtube.com/watch?v=x0qLJRivdmY&t=60) |  But I think that Google is not

able to find it crawling on our website. And this could be something bad for our website or not. Because these are generally faceted [INAUDIBLE] into our website. So maybe it's not so important. But sometimes it could be. JOHN MUELLER: I generally wouldn't worry about that too much if the website itself is still  

#### [0:01:30](https://www.youtube.com/watch?v=x0qLJRivdmY&t=90) |  crawable and indexible. So if you're seeing

that your new pages are findable in search fairly quickly, then I think that's OK. I don't think you need to do anything specific there. If you notice that individual pages don't show up at all in search, and you think they should be linked within your website, then I would double check that. On the one hand, you can check manually per page.  

#### [0:02:00](https://www.youtube.com/watch?v=x0qLJRivdmY&t=120) |  On the other hand, there are a

lot of really neat website crawling tools out there that you can use to crawl your website to double check is all of the content properly linked within the website. RICCARDO: OK, because for the user, the link is available. And-- but for Google I think is mostly difficult because they usually have to click before [INAUDIBLE].. And so there are a lot of fields that are [INAUDIBLE] so Google  

#### [0:02:30](https://www.youtube.com/watch?v=x0qLJRivdmY&t=150) |  cannot access this content and because Google

cannot click on this website. And so maybe it will be better to have this link ready for Google and not just to send it by [INAUDIBLE]. JOHN MUELLER: Yeah, so a sitemap file helps us to find new and updated pages. But ideally, these pages should also be linked within your website. So I wouldn't say you should only use the sitemap file.  

#### [0:03:00](https://www.youtube.com/watch?v=x0qLJRivdmY&t=180) |  You should really-- ideally, you should have

the sitemap file to help you. But you should primarily use the internal links within the website to allow crawling. RICCARDO: OK, thank you. JOHN MUELLER: Sure. RAMESH: Hi, John. Can I ask a question? JOHN MUELLER: Sure. RAMESH: Thanks. So I have a question regarding this bad perspective [INAUDIBLE]. So usually I have one presents in India, which is very popular. So we are thinking of going out in foreign countries.  

#### [0:03:30](https://www.youtube.com/watch?v=x0qLJRivdmY&t=210) |  So targeting US as a first. And

we're thinking of changing our brand name there, like, for instance, [INAUDIBLE] India we're known as [INAUDIBLE] but in US we might want to be targeted as [INAUDIBLE]. And we already have a knowledge panel for [INAUDIBLE].. So will it effect us domain-wise in the US market? People might be looking for us for something else, and maybe we end up something else, now.  

#### [0:04:00](https://www.youtube.com/watch?v=x0qLJRivdmY&t=240) |  So what do we do-- strategy toward

that predicament? How we can resolve that so when somebody is looking for [INAUDIBLE] or [INAUDIBLE] they can be considered as one? JOHN MUELLER: I think that's always a bit tricky, because you're doing a brand name change which takes a lot of work and takes a lot of time. The approach of having two brands in different locations-- I think that's also an idea that you could use.  

#### [0:04:30](https://www.youtube.com/watch?v=x0qLJRivdmY&t=270) |  If you use something like hreflang between

those different language or country pages, you can also have it for different brands, essentially. So you could be called one company name here, maybe in Switzerland, and a different name in the UK and with the hreflang you can still connect that. So that if someone is searching for the Swiss name in the UK, we will show the UK name. So that kind of helps a little bit.  

#### [0:05:00](https://www.youtube.com/watch?v=x0qLJRivdmY&t=300) |  But I think any time you separate

things out into multiple brands, which is actually the same thing, it's always a lot harder from the tracking and from the search side as well. So I would think carefully about that. Sometimes you have to do what you have to do. It's not you that makes these decisions. Sometimes you just have to deal with it. But it's always a bit tricky if you  

#### [0:05:30](https://www.youtube.com/watch?v=x0qLJRivdmY&t=330) |  have the same thing with different brand

names associated with it RAMESH: Sure. Thanks, John. So on that, I think-- now when you say to having a separate entity itself-- so is it possible to have a different knowledge panel for that [INAUDIBLE] for a different brand name? And again, when you say the hreflang, I mean, most [INAUDIBLE] only to a few pages that are going to have a relationship with my other-- website-wise, like let's say home page only.  

#### [0:06:00](https://www.youtube.com/watch?v=x0qLJRivdmY&t=360) |  I cannot link my actual plan to

my other internal pages-- [INAUDIBLE] those pages? So mostly you have to be selective towards the actual plan. It's like this should be linked from my homepage only, or the common pages across all the countries. JOHN MUELLER: Yeah. Yeah. I mean hreflang is on a per page basis. You can use it for the pages where you want. I would really recommend using it in the area where you see problems. So that's probably, maybe the brand name, especially if it's a different name and different locations.  

#### [0:06:30](https://www.youtube.com/watch?v=x0qLJRivdmY&t=390) |  Then people in the wrong location might

be searching for the other brand name. So with the hreflang you can kind of work that out. But that's something that you can do for the homepages or for the about us pages or whatever pages where you notice that people are going to the wrong version. RAMESH: All right. Thanks, John. JOHN MUELLER: Sure.  

#### [0:07:00](https://www.youtube.com/watch?v=x0qLJRivdmY&t=420) |  All right, let's jump into some of

the questions that were submitted-- a whole bunch of stuff. We followed the guidelines and updated the favicons for Google Mobile Search in our multi country website. You can see the new favicon in Google Mobile Search for most of our domains after submitting the new homepage and search console. However, a few of them still show the old one even after waiting more than seven days.  

#### [0:07:30](https://www.youtube.com/watch?v=x0qLJRivdmY&t=450) |  Two domains that were showing the updated

favicon two days ago have changed back to the old one. So in general, these kind of things can sometimes take a little bit of time to settle down. So especially if you're talking about a period of seven days, then I would still give it a little bit more time to clearly settle down. And I would make sure that when you're using it across a domain that you don't just update the homepage-- that you also  

#### [0:08:00](https://www.youtube.com/watch?v=x0qLJRivdmY&t=480) |  make sure the other pages associated with

the rest of the site are also updated so that when we crawl and index those pages, then we see a kind of a clear signal saying for this domain, this tab icon is the one that you want. So I wouldn't see it more as a technical thing with regards to how do I link the icon that I want, but more a matter of you need to make sure that it's consistent across the site.  

#### [0:08:30](https://www.youtube.com/watch?v=x0qLJRivdmY&t=510) |  And sometimes it takes a bit of

time to clearly settle down properly. I've seen cases where it gets updated within a day or two. I've also seen cases where it takes a little bit longer. SVG images question-- inline SVG versus image tag SVG-- as a front end developer, we prefer inline SVG because it loads faster and doesn't require us to host images, however the problem  

#### [0:09:00](https://www.youtube.com/watch?v=x0qLJRivdmY&t=540) |  is that inline SVGs and their attributes

are not indexed by Google and Google Images. Are there any plans for that to change? I am not aware of any plans with regards to that changing that we've talked about externally. So I can't really say much there. In general, what I would be careful with, though, is kind of the perception every image that you have needs to be found in Google Images.  

#### [0:09:30](https://www.youtube.com/watch?v=x0qLJRivdmY&t=570) |  I think it's great to have a

lot of images in Google Images. But for a website, it's also worthwhile to think about what you want out of Google Images-- how you see users visually searching for your content. And with that in mind it's often not the case that every single icon on a home page, on a website, needs to be indexed and Google Images, because people are not going to search visually for all of these different icons.  

#### [0:10:00](https://www.youtube.com/watch?v=x0qLJRivdmY&t=600) |  So if you're using an SVG as

a user interface element or if you're using an SVG as a decorative element on a page, then that's probably not something that people will be using explicitly to try to visually find content on your website. I mean it's theoretically possible that they would do that, but I'd really think about how might someone search visually with Google images  

#### [0:10:30](https://www.youtube.com/watch?v=x0qLJRivdmY&t=630) |  and reach your website. And then think

back from there how can I present myself in the right way at the right place at the right time for these users so that they do come to mind content. So that's kind of the angle I will take rather than just purely I need to get every graphical element into Google Images. Duplicate content question. Why are there so many lyrics websites out there?  

#### [0:11:00](https://www.youtube.com/watch?v=x0qLJRivdmY&t=660) |  I think it kind of goes into,

like, all of these lyrics are the same because they're the same songs. Why is its content even indexed? I don't know why so many lyrics websites exist. I imagine people like searching for lyrics and like browsing around. So that's probably why they exist. From a search point of view, what happens here with this kind of duplicate content is we'll recognize that the block of text  

#### [0:11:30](https://www.youtube.com/watch?v=x0qLJRivdmY&t=690) |  there is duplicate, but we'll also recognize

that the rest of the page all around it is not duplicate across all of these different sites. People do really cool stuff with lyrics sometimes-- give a lot more context rather than just purely this is a song title and here are the lyrics. And because of that, we do try to index all of these pages and we try to double them up in the right place in the search  

#### [0:12:00](https://www.youtube.com/watch?v=x0qLJRivdmY&t=720) |  results. So what usually happens is if

you search for something that's within a copied chunk of text across multiple sites, we'll pick one of those sites to show and we'll essentially filter out most of the other ones. Whereas if we can tell that someone is searching explicitly for something that's kind of unique on that site, so maybe a chunk of text from the lyrics as well as additional information that's not directly  

#### [0:12:30](https://www.youtube.com/watch?v=x0qLJRivdmY&t=750) |  in the lyrics or maybe even someone

knows your website and is explicitly searching for the lyrics and then your website name, then obviously makes sense for us to try to pick the most relevant one to show there. So that's something where the text itself is duplicate content, but the rest of the page isn't duplicate content, therefore it makes sense for us to index that. And when someone is searching generally for that duplicated piece of text, we'll try to pick one of those pages and filter out most of the other ones.  

#### [0:13:00](https://www.youtube.com/watch?v=x0qLJRivdmY&t=780) |  But oftentimes people search explicitly in a

way that makes one of these versions the most relevant one. Can you speak to the necessity of E-A-T and author biography pages linked from an article? Should we have an author's credentials on the article itself or is linking to the author's bio from their byline good enough? We have an issue where the author bio  

#### [0:13:30](https://www.youtube.com/watch?v=x0qLJRivdmY&t=810) |  pages are meta no index. Does this

stop Googlebot or the quality writers is from accessing this page? So I think we talked about this question in the last English Hangout a little bit, especially about the quality writers and how they don't rate your website, they help us to rate our algorithms. So that's not something that you'd need to explicitly worry about. With regards to how you link the author's credentials,  

#### [0:14:00](https://www.youtube.com/watch?v=x0qLJRivdmY&t=840) |  that's something where we don't have explicit

guidelines from a search point of view, but where you can work on this yourself and think about how might users expect to find this information and how can you provide it in a way that really highlights the value of your website, of the content that you're providing there. I have a multilingual website that I'm working on. Each language has around 100,000 pages. There are six different languages,  

#### [0:14:30](https://www.youtube.com/watch?v=x0qLJRivdmY&t=870) |  but only three of them are translated.

For the others, the ones that are not translated, is English. OK and then it kind of goes into how do I deal with the non translated versions? They're looking at two options. First, remove the hreflang for all pages and canonicalize. Or second, fix the hreflang problem and use  

#### [0:15:00](https://www.youtube.com/watch?v=x0qLJRivdmY&t=900) |  self referencing canonical tags to those non

translated versions. So ultimately both of those options could work. You could aim to have these pages indexed separately, especially since you mentioned for the non translated versions, there's still a difference with the currency that you show on these pages. So these are kind of unique pages,  

#### [0:15:30](https://www.youtube.com/watch?v=x0qLJRivdmY&t=930) |  and we might index them individually. On

the other hand, if there's not that much value in the uniqueness across these versions, then that might make sense to canonicalize. In general, my recommendation is to tend towards having fewer URLs rather than having more URLs, just because having fewer URLs makes it easier from a technical point of view on the one hand.  

#### [0:16:00](https://www.youtube.com/watch?v=x0qLJRivdmY&t=960) |  But it also makes it a lot

easier for us to concentrate the value of your website, of the content that you have there, in fewer pages. Because if we have to spread it out across these different language versions, which are kind of the same and they're kind of competing with each other, then both of these or a multiple of these different versions-- they're essentially not as strong as they would be if they were combined into one individual page. So that's generally the direction I would tend towards, is try to find a way to have fewer pages rather than more.  

#### [0:16:30](https://www.youtube.com/watch?v=x0qLJRivdmY&t=990) |  So if you know that you have

different country versions where the content is actually the same, maybe there's a way to concentrate those into one version rather than having separate versions. If you do want to make separate versions, maybe you have to do that for policy or for legal reasons, that's fine as well. Using the hreflang between those versions is an option. What can sometimes happen, though, is that our systems recognize that the content is essentially  

![](https://i.ytimg.com/vi/x0qLJRivdmY/maxres1.jpg)



#### [0:17:00](https://www.youtube.com/watch?v=x0qLJRivdmY&t=1020) |  the same. We will pick one of

those versions and use that as a canonical internally. We'll use the hreflang to still split out the different URLs, though. So in your case where you have the English and the Germany content both in English, we might pick up the general English page as a canonical. We Will index that one. We won't index the Germany page that's in English as well. But when a user in Germany searches,  

#### [0:17:30](https://www.youtube.com/watch?v=x0qLJRivdmY&t=1050) |  we'll know because of the hreflang between

those different URLs, we can show the Germany URL for users in Germany. So it makes it a lot trickier to track. It makes a lot trickier to monitor in search console because we fold it together in one canonical version, and then we split it out when we show it to users. But that's an option as well. So it is really hard for me to say what you should be doing there.  

#### [0:18:00](https://www.youtube.com/watch?v=x0qLJRivdmY&t=1080) |  My general approach is if you're unsure,

then I would try to just have fewer URLs and work from there. If you really absolutely need to have separate URLs, then you have to have separate URLs. It's kind of the situation. And in an ideal world, if you do have separate URLs then I recommend trying to get localized content as well. If you're already going down the harder route, you might as well make it easier for you.  

#### [0:18:30](https://www.youtube.com/watch?v=x0qLJRivdmY&t=1110) |  Google is now including mobile devices an

image for some websites in the search results. The images is usually a square and often, but not always Google uses an image specified by the Open Graph [INAUDIBLE]. Is this feature documented anywhere? Do you have a first look for the schema item prop image? Like how can I tell Google, which image I want to use?  

#### [0:19:00](https://www.youtube.com/watch?v=x0qLJRivdmY&t=1140) |  I don't think we have that documented

anywhere. My guess is that this is one of the many experiments that we run, and we're trying to see how it works out. And my guess is that if we start doing this at a broader scale, then we'll have some structure data for you that can help you to help us to pick the right image to show for these individual snippets. I'll definitely check in with the team though,  

#### [0:19:30](https://www.youtube.com/watch?v=x0qLJRivdmY&t=1170) |  to see if there's something that we

can provide there in the meantime, so that you can specify images there as well. Yeah, I have some guesses on how we pick these images, but I don't think that's very useful for me to go through my guesses and then everyone goes off and implements it and then maybe I guessed wrong. But I'll check with the team. Is it still good to build a quality website with a good amount of traffic, guess posts in a medical niche?  

#### [0:20:00](https://www.youtube.com/watch?v=x0qLJRivdmY&t=1200) |  One of my clients is looking for

quality guest posts in the medical niche, or is it good to take links from one quality website? So I'm not quite sure what you're asking. It sounds like you're trying to build links using guest posts.  

#### [0:20:30](https://www.youtube.com/watch?v=x0qLJRivdmY&t=1230) |  If you're talking about where do I

place my guest posts or where do I have other people place guest posts for me. And that's something I generally avoid doing. It's like just going off and creating guest posts and using them to drop links to a website. There are ways that you can collaborate in a reasonable way with other websites, and sometimes you can do that in a strategic way. But in general I wouldn't just say  

#### [0:21:00](https://www.youtube.com/watch?v=x0qLJRivdmY&t=1260) |  you should create guest posts and drop

them on websites and then make sure that they get x amount of traffic per day. That, from our point of view, would probably be seen as unnatural link building. And that could on the one hand, be ignored by our algorithms. It could be picked up by our algorithms if it's done in a really big scale and seen as something that you shouldn't have been doing. It could also be picked up by the web spam team manually,  

#### [0:21:30](https://www.youtube.com/watch?v=x0qLJRivdmY&t=1290) |  and they might apply a manual action

for this kind of thing. So that's something where I'd avoid just blindly throwing out I'm going to drop so many guest posts with links to our website on these five web sites because they get x amount of traffic. Now that Googlebot is using the latest version of Chrome, has a Google smartphone user agent changed? Webmaster help still lists Chrome 41  

#### [0:22:00](https://www.youtube.com/watch?v=x0qLJRivdmY&t=1320) |  in the smartphone user agent. I'm still

seeing Chrome 41 in our logs. Also, when Googlebot is crawling and rendering pages, is Googlebot always the user agent? So the last one is definitely the case. When we crawl in index pages, Googlebot will always be in the user agent. I think that makes sense. We'll probably have to rethink how we want to set up the user agent in general now that everything is moved to a more modern Googlebot  

#### [0:22:30](https://www.youtube.com/watch?v=x0qLJRivdmY&t=1350) |  infrastructure for rendering. So I would definitely

expect that we announce some changes there at some point in the future. I don't know what the timing there will be. We've been waiting a little bit to make sure that everything is working well and experimenting a little bit with the different settings. But I would assume that at some point, we'll have a user agent that matches more what we actually  

#### [0:23:00](https://www.youtube.com/watch?v=x0qLJRivdmY&t=1380) |  use for rendering. So on the one

hand for smartphones that's a little bit easier, because we already kind of have a browser like user agent. On the other hand, for desktop I don't know how we change that there. That's one thing that's always been a bit on my mind as well. In that the current desktop Googlebot user agent is not like a browser at all. And maybe it should look like a browser. I don't know. The difficulty with the desktop user agent  

#### [0:23:30](https://www.youtube.com/watch?v=x0qLJRivdmY&t=1410) |  is of course that lots of sites

have this kind of hardcoded, because that desktop user agent hasn't changed at all since, I don't know, last decade or whenever we implemented that. So that's kind of a tricky balance to do that. But I'd expect at some point that we would talk about the new user agent names that we'd use going forward. We just didn't want to do everything at once, because that tends to confuse more than it actually  

#### [0:24:00](https://www.youtube.com/watch?v=x0qLJRivdmY&t=1440) |  helps. RAMESH: John, any update on when--

with the new Googlebot, can we expect this Googlebot can visit us apart from the US? Or we can have more regional based Googlebots that can be visited from any county apart from just the US bot? JOHN MUELLER: I don't expect to see a lot of changes there. So we do crawl from some individual countries. So there is a handful of countries  

#### [0:24:30](https://www.youtube.com/watch?v=x0qLJRivdmY&t=1470) |  where we know that it's hard to

crawl from the US, so we crawl from local IP addresses. But I don't expect to see that changing in the sense that we'll crawl from every country. Because that's just not efficient. RAMESH: All right. Thanks. JOHN MUELLER: Sure. Oh my gosh, there's a long question in the chat. Let me take a look at that. We're a news publisher. Or if you're here and you have a microphone, feel free to jump in. I don't know if you're still here, maybe not.  

#### [0:25:00](https://www.youtube.com/watch?v=x0qLJRivdmY&t=1500) |  We're a news publisher website primarily focusing

on business finance vertical. We probably have been impacted by the June core update, as we've seen a traffic drop from the June 1st week. Agreed that the update specifies there are no fixes, no major changes, that need to be made to lower the impact. But for a publisher whose core area is content news, doesn't it signal that it's probably the content, the quality or the quantity,  

#### [0:25:30](https://www.youtube.com/watch?v=x0qLJRivdmY&t=1530) |  which triggered Google's algorithm to lower down

the quality signal of the content being put up on the website which could have led to a drop of traffic. We're aware that many publisher sites have been impacted in such a scenario. It would really help if Google could come out and share some advice to webmasters and websites not site specific, but category or vertical specific. At least, on how to take corrective measures and actions  

#### [0:26:00](https://www.youtube.com/watch?v=x0qLJRivdmY&t=1560) |  to mitigate the impact of core updates.

It would go a long way in helping websites who are now clueless as to what impacted them. I have heard this a few times. I think it's a bit tricky because we're not focusing on something very specific where we'd say-- for example, when we rolled out the speed update that was something where we could talk about specifically this  

#### [0:26:30](https://www.youtube.com/watch?v=x0qLJRivdmY&t=1590) |  is how we're using mobile speed and

this is how it affects your website, therefore, you should focus on speed as well. With a lot of the relevant updates-- a lot of the kind of quality updates, the core updates that we make, there is no specific thing where we'd be able to say you did this and you should have done that. And therefore we're showing things differently. Sometimes the web just evolves. Sometimes what users expect evolves. And similarly sometimes our algorithms are--  

#### [0:27:00](https://www.youtube.com/watch?v=x0qLJRivdmY&t=1620) |  the way that we try to determine

relevance, they evolve as well. And with that, like you mentioned, you've probably seen the tweets from search liaison, there's often nothing explicit that you can do to change that. What we do have is an older blog post from [INAUDIBLE] which covers a lot of questions that you can ask yourself about the quality of your website. That's something I'd always recommend going through that's something that I would also go through  

#### [0:27:30](https://www.youtube.com/watch?v=x0qLJRivdmY&t=1650) |  with people who are not associated with

your website. So often you as the site owner, you have an intimate relationship with your website. You know exactly that it's perfect. But someone who is not associated with your website, they might look at your website and compare it to other websites and say, well, I don't know if I could really trust your website because it looks outdated or because I don't know who these people are who are writing about things.  

#### [0:28:00](https://www.youtube.com/watch?v=x0qLJRivdmY&t=1680) |  All of these things play a small

role. And it's not so much that there's any technical thing that you can change in your line of HTML or server setting. It's more about the overall picture where users nowadays would look at it and saying, well, I don't know if this is as relevant as it used to be because these vague things that I might be thinking about. So that's where I'd really try to get people who are unassociated with your website to give you feedback on that.  

#### [0:28:30](https://www.youtube.com/watch?v=x0qLJRivdmY&t=1710) |  Sometimes you can also do that through

the webmaster help forums, either the ones from us or there are lots of communities out there with other webmasters where you can talk with other people who've seen a lot of websites and who can look at your websites and say well I don't know, the layout looks outdated or the authors are people that nobody knows or you have stock photo images instead of author photos. Like why do you have that? All of these things are not explicit elements  

#### [0:29:00](https://www.youtube.com/watch?v=x0qLJRivdmY&t=1740) |  that our algorithms would be trying to

pinpoint, but rather things that combine to create a bigger picture. So that's kind of the direction I take there. I know a lot of people have been asking for more advice and more specific advice so maybe there is something that we can put together. We'll see what we can do internally to put out a newer version of a blog post or provide some more general information about some of the changes that we've been thinking about there.  

#### [0:29:30](https://www.youtube.com/watch?v=x0qLJRivdmY&t=1770) |  Well let's see, another question from the

chat. During the month of April I decided to change the URL structure of one of my websites, and ever since we've seen a significant drop in organic traffic in Search Console. However, Google Analytics shows a lot more organic clicks. Where could this discrepancy be coming from? Is it possible that the change of URLs messed up the way that Search Console tracks clicks and impressions?  

#### [0:30:00](https://www.youtube.com/watch?v=x0qLJRivdmY&t=1800) |  So Search Console's clicks and impressions are

based on the search results that were actually shown. So that's not something that would get confused if you make a change within your website. What can happen if you change the URL structure of your website is that it takes us a bit of time in search, in general, to understand that better. So offhand my suspicion is if you're seeing a significant discrepancy between Search Console  

#### [0:30:30](https://www.youtube.com/watch?v=x0qLJRivdmY&t=1830) |  and Google Analytics with regards to organic

traffic, that perhaps you're tracking Google Analytics somewhere incorrectly. Because with Google Analytics, depending on how you have that set up, you might be tracking things twice when a user opens a page. You might be tracking other things in different ways. You might be tracking other kinds of traffic as organic when it shouldn't be or when it splits across different sessions.  

#### [0:31:00](https://www.youtube.com/watch?v=x0qLJRivdmY&t=1860) |  So that's kind of the direction I

would take there. My suspicion is that if Search Console is showing you that things have dropped after you've made a significant restructuring of your website, then that would be in line with what I would expect when you make a significant restructuring of your website. And these kind of restructurings, especially within a website, they do take a bit of time to settle down again. So my guess is when search settles down  

#### [0:31:30](https://www.youtube.com/watch?v=x0qLJRivdmY&t=1890) |  and things are in a stable area

when it comes to search, then you should be able to compare the search console and the analytics-- numbers that you're seeing, and they should be roughly the same. They won't be exactly the same, because they track things in very different ways. But they should be roughly similar. Another thing that might also be playing a role here is traffic from the Discover feed, which is a bit tricky to track in Google Analytics  

#### [0:32:00](https://www.youtube.com/watch?v=x0qLJRivdmY&t=1920) |  and I think we showed it separately

in Search Console now. So that might be something to also look at. Maybe you're seeing a lot of clicks or impressions from there, and you don't see those in the performance report because they're tracked separately in Search Console. ALEXANDER: John could I ask a questions? JOHN MUELLER: Sure. ALEXANDER: As well, thanks for your time. So from what I've read, Google can handle text based information within accordions completely,  

#### [0:32:30](https://www.youtube.com/watch?v=x0qLJRivdmY&t=1950) |  but a client of ours within the

streaming business, when they have their seasons behind accordions, when just searching for the show, they're number one. But when searching for the show and the season, they're nowhere to be found. So could you clarify things here for me? JOHN MUELLER: It's hard to say how you might have set that up. So there are different ways that you  

#### [0:33:00](https://www.youtube.com/watch?v=x0qLJRivdmY&t=1980) |  can implement these kind of accordions on

a site. If it's done in a way that you're using just CSS to hide something that's already loaded, then we would be able to index that because we crawl and render the page and then the content is there, It's just not visible. Then we would be able to index that. That would rank essentially the same as normal visible content. What might happen there is that we wouldn't show it in the snippet directly. But it would still rank.  

#### [0:33:30](https://www.youtube.com/watch?v=x0qLJRivdmY&t=2010) |  On the other hand, if it's an

accordion where you click on the top level and then it does a quick server side request and pulls in the content and then shows that, that's not something that we would know about at all. Because Googlebot wouldn't click on different elements to see what else gets loaded on the page. So that's kind of from a technical implementation side, I double check that. Especially if you're saying that they don't rank at all. If they were ranking a little bit lower then we'd know about the content. It's more a matter of, well, they're  

#### [0:34:00](https://www.youtube.com/watch?v=x0qLJRivdmY&t=2040) |  just not ranking as well for that

specific phrase. But if they're not ranking at all, then that sounds almost like a technical thing that we can't recognize the content at all. ALEXANDER: I see. Thank you so much. JOHN MUELLER: Sure. ANATOLI: You mentioned the guest question, and I mean to just say that of course I understand [INAUDIBLE] just technique. But for example, we are going to provide an English version  

![](https://i.ytimg.com/vi/x0qLJRivdmY/maxres2.jpg)



#### [0:34:30](https://www.youtube.com/watch?v=x0qLJRivdmY&t=2070) |  of website about [INAUDIBLE],, and nobody knows

us because it will be a new website and there are a lot of recommendations that you can write-- I mean, like guest posts to other websites, but high quality. For example, I create content for my website and I can create the same level of content, high quality content, to other websites just to make brand awareness  

#### [0:35:00](https://www.youtube.com/watch?v=x0qLJRivdmY&t=2100) |  and of course to get links on

my website. Do you think it's not a good idea just to use other outreach techniques now, or for example, if I create high quality content, what do you think? It helps or not or Google ignores this link? JOHN MUELLER: I would be really careful. So in the past we have said you should not use guest posts for link building. So that's something where, kind of as a starting point  

#### [0:35:30](https://www.youtube.com/watch?v=x0qLJRivdmY&t=2130) |  our guidelines are pretty clear in saying

you should not be, essentially, publishing content on other people's websites and including links to your website back. Because then you're putting that link on other people's website. It's not that the other website is organically recommending you. It's you going out and putting that link on the other person's website. So that's kind of our starting point there.  

#### [0:36:00](https://www.youtube.com/watch?v=x0qLJRivdmY&t=2160) |  If you're talking about brand awareness, then

obviously that's not a problem. You can just use nofollow for those links. Then people will recognize that you're an expert on this topic, and they'll see like, oh this is a new brand or new website that I don't know about. They'll click on those links. They'll go to your website. They'll learn more about you there. That's perfectly fine. If these links are nofollow, then you're going around all of these difficult discussions around is this person dropping links on other people's websites.  

#### [0:36:30](https://www.youtube.com/watch?v=x0qLJRivdmY&t=2190) |  So that's the ideal situation for growing

awareness of your content of your website. I suspect when it comes to SEO sites in general, it'll be hard because there's so many people who are saying, well, I am an SEO expert and I have all of this content and trust me. So that'll probably be hard. The other thing to think about when you're  

#### [0:37:00](https://www.youtube.com/watch?v=x0qLJRivdmY&t=2220) |  doing guest posts like this is maybe

there are ways that you can do it. you can do a guest post on other people's sites. You have those links with a nofollow there. But at the same time, these other sites are saying, well, look at this awesome content that this person wrote and they do organically link to you because they've seen the content that you've written for them directly. So from my point of view, I wouldn't say that if you're doing guest posts  

#### [0:37:30](https://www.youtube.com/watch?v=x0qLJRivdmY&t=2250) |  then you will be penalized and our

algorithms will never see you favorably again. But it does it does make a lot harder. And in particular, if we look at a website and see all of the links for this website our guest posts, then that's an obvious situation where anyone from the manual [INAUDIBLE] team looking at that will say well, none of these links are actual recommendations for the website. Therefore we should really be careful with how  

#### [0:38:00](https://www.youtube.com/watch?v=x0qLJRivdmY&t=2280) |  we see those links in general. On

the other hand, if we see that there is lots of normal organic links pointing to this website, and there are occasional guest posts where you spread some additional knowledge on other people's web sites, then that's usually something where, from a manual [INAUDIBLE] point of view, they'll look at that and say well, I can see they're trying to do some things, but overall they're are good guys and they're watching out to do the right thing. And then we don't really need to do anything.  

#### [0:38:30](https://www.youtube.com/watch?v=x0qLJRivdmY&t=2310) |  So yeah. I mean, I don't want

people to go off and say well, John says you should do guest posts because that's definitely not what I'm saying. And going out and just dropping links on other people's sites is not the way to build links. And it will result, over time, in the web [INAUDIBLE] noticing that our algorithms picking that up and saying, wow, all of the links to this blogs over here are basically terrible weird guest posts.  

#### [0:39:00](https://www.youtube.com/watch?v=x0qLJRivdmY&t=2340) |  We should ignore all links to this

blog, because that's also not what you want. But I primarily see it as a way of building brand awareness. And if you have those links nofollowed, that doesn't matter for brand awareness. And over time that builds up your reputation, too. ANATOLI: OK. Additional question about redirectings. One time I read that you replied to one guy  

#### [0:39:30](https://www.youtube.com/watch?v=x0qLJRivdmY&t=2370) |  that Google doesn't count regular links and

especially if you bought some other expired domains and tried to manipulate the results. But I need you to see, for example, I have a URL structure and I want to change this URL structure in my website. For example, I have old content and I  

#### [0:40:00](https://www.youtube.com/watch?v=x0qLJRivdmY&t=2400) |  want to refresh this content to other

pages. It means Google doesn't count these links to old pages or so [INAUDIBLE] or not? JOHN MUELLER: Redirects within your website are perfectly fine. I think perhaps the thread that you're thinking about is about people buying expired domains and then just redirecting them to their website. That's something that's a really old school tech technique,  

#### [0:40:30](https://www.youtube.com/watch?v=x0qLJRivdmY&t=2430) |  and that's something that we work really

hard on recognizing and ignoring. But if you're redirecting within your website, if you're restructuring, if you're moving from one domain to another domain that's where redirects come into play. That's how they should be used. That's kind of what we do. ANATOLI: OK. Thank you. JOHN MUELLER: All right. Let me run through some of the submitted questions. So much the left.  

#### [0:41:00](https://www.youtube.com/watch?v=x0qLJRivdmY&t=2460) |  Working with a client, a food blogger,

who has some AMP pages created but still has the original non AMP version of the same recipe available as well. Is this counted as duplicate content or not? So if the AMP page is connected to the non AMP page with the link rel alternate-- link rel AMP HTML. I think it's called, and the canonical back to the web page, then that is not duplicate content. Then those are essentially connected AMP pages.  

#### [0:41:30](https://www.youtube.com/watch?v=x0qLJRivdmY&t=2490) |  We would primarily index the HTML version

and then swap out the AMP version as needed for mobile users when we show that search results. So that's seen as one page. On the other hand, you can have separate AMP pages as well. You can make pages AMP only and then those would be indexed individually. And in that case, if you have one HTML page that shows a recipe and one AMP only page that  

#### [0:42:00](https://www.youtube.com/watch?v=x0qLJRivdmY&t=2520) |  shows the same recipe, then that would

be considered duplicate content. We wouldn't demote your website because of that. We wouldn't say that your website is bad because of that. Sometimes this just happens for technical reasons. But you're kind of competing with yourself in a situation like that, because you have two different pages that are targeting the same keywords-- that are targeting the same user. So my recommendation there would be if you recognize that you have multiple pages  

#### [0:42:30](https://www.youtube.com/watch?v=x0qLJRivdmY&t=2550) |  with the same content or with mostly

the same content, pick one and focus on that one. Fewer pages make things easier from a technical point of view and they help us to concentrate the value in those pages so that they rank better as well. AMP is a great way to make web pages. So maybe that's a good approach there. On the other hand, maybe you're saying that my non AMP version is also really fast and awesome and I prefer using my non AMP version  

#### [0:43:00](https://www.youtube.com/watch?v=x0qLJRivdmY&t=2580) |  because it's easier to create or for

whatever other reason, that's fine too. Just switching to AMP itself is not a ranking factor. So you don't need to artificially say Google is saying I should do everything on AMP, therefore I will delete my HTML pages. Maybe the HTML version is the one that you want to continue using, maybe it's the AMP version. XML site map errors. It's unclear what effect an XML site map  

#### [0:43:30](https://www.youtube.com/watch?v=x0qLJRivdmY&t=2610) |  error has if an individual URL has

an error. Is the entire site map ignored, any content after that URL ignored, or is it just that specific URL? It's just that specific URL. So if we can parse the XML file properly and it's just one of those elements that is broken internally within that element, then we can skip that element and we can parse the rest of the XML file. On the other hand, if that element is broken in a way  

#### [0:44:00](https://www.youtube.com/watch?v=x0qLJRivdmY&t=2640) |  that the rest of the XML file

can't be parsed at all, so maybe you have an open bracket and you forget to close that for example, then the rest of the XML file is unreadable. And in that case, of course, the rest of the XML would not be usable as a site map. But if it's more like a logical error that you have within one of these URL elements, then that's within that element-- that doesn't affect anything else on the site map file.  

#### [0:44:30](https://www.youtube.com/watch?v=x0qLJRivdmY&t=2670) |  Does Google use rel="me" for crawling, indexing,

and ranking? I don't think we'll use that at all. So it might be that that comes into play with some kinds of structured data when we try to understand the entities in a more specific way. But in general, I don't think you would see that affecting crawling, indexing or ranking. In the future, will access to the old Webmaster Tools  

#### [0:45:00](https://www.youtube.com/watch?v=x0qLJRivdmY&t=2700) |  be removed or not? Will the search

appearance section be moved to the new version? At some point we're going to have to turn off the old Webmaster Tools, yes. So that will happen. I don't know one when that time will be. I am vaguely guessing that towards end of the year, we'll probably have to make that cut.  

#### [0:45:30](https://www.youtube.com/watch?v=x0qLJRivdmY&t=2730) |  However we are trying to move as

much as possible to the new search console. So that's hopefully happening. All of the features that we see people still using are trying to be moved over. What might happen, though, is that-- what ideally would happen even, is that we rethink a lot of these features and we don't just blindly move them one to one, but rather we think about what are people actually trying to do with this feature and how can we help  

#### [0:46:00](https://www.youtube.com/watch?v=x0qLJRivdmY&t=2760) |  them to do it more efficiently. So

that's something that will affect some of these features in the sense that they won't be moved one to one exactly as they are. But rather we'll try to rethink them and consider what can we change within our features and make it easier for people to use. There might even be features where we say, well people really love this feature, but it has absolutely no effect on most websites, therefore maybe we shouldn't be moving it over. Maybe we should be dropping it.  

#### [0:46:30](https://www.youtube.com/watch?v=x0qLJRivdmY&t=2790) |  And kind of giving people a clear

signal to let them know that actually, they don't need to spend time on this specific feature. I don't have anything in particular in mind there with regards to things that we won't be moving over, but that's certainly a possibility. If there is something explicitly that you're missing in the new search console, and you're saying I really want this or I really want you to prioritize moving over this feature because I hate switching over  

#### [0:47:00](https://www.youtube.com/watch?v=x0qLJRivdmY&t=2820) |  to the old version, then use a

feedback link in Search Console and let us know about that. And ideally, don't just go in there and say I want this feature, but rather go in there and say I want this feature because I need to do xyz, and this feature lets me do that in an efficient way. Because that helps us to figure out what part of the feature is really critical and which parts we have to really take care to make sure that the new version is as fantastic as it can get.  

#### [0:47:30](https://www.youtube.com/watch?v=x0qLJRivdmY&t=2850) |  In the near future, will the disavow

tool be able to process and execute all disavowed domains in a few minutes? I don't see that happening. I think the disavow tool is one of those things that so few websites need to use, that we'll probably just be moving that over as it is. And we probably won't be setting that up in a way that prioritizes recrawling of all websites that were linked to that website.  

#### [0:48:00](https://www.youtube.com/watch?v=x0qLJRivdmY&t=2880) |  I don't see that happening. Is there

any chance to rank a 90%, 95% identical service website under one domain locally at x locations without getting into a canonical issue? So like different vendors that have the same services, I think, is kind of the direction that you're going into there.  

#### [0:48:30](https://www.youtube.com/watch?v=x0qLJRivdmY&t=2910) |  I mean sure, we index this if

these are different websites or different versions of the same content, but you will, as I mentioned with some of the other questions, you will run into the situation that you're competing with yourself. And if you end up competing with yourself across x different locations, which might be, I don't know 100 or 1,000 different locations, then you're really diluting the value of your content across all of these different versions, which  

#### [0:49:00](https://www.youtube.com/watch?v=x0qLJRivdmY&t=2940) |  makes it a lot harder for any

of these versions to rank in the overall competitive landscape. So from that point of view, you can do this. Nothing will stop you from doing this. And these pages will probably be indexed in some way. But will they really do what you want them to do for your business? I doubt that. So that's another case where I'd say fewer URLs probably  

#### [0:49:30](https://www.youtube.com/watch?v=x0qLJRivdmY&t=2970) |  would work better than just duplicating things

across a ton of different URLs. Does a dofollow link to a noindex page lose page rank? By lose, I mean the page rank that flows to the other links in the page is smaller when it is [INAUDIBLE] by more links? The same question for nofollow page. So a dofollow link is just a link  

#### [0:50:00](https://www.youtube.com/watch?v=x0qLJRivdmY&t=3000) |  that doesn't have a nofollow. from a

practical point of view, we see these links as links, as they are. When we calculate page rank, I'm sure our systems take into account some of that-- how that gets distributed further from there. But I don't think from a practical point of view, it makes any sense to focus on this specifically. So from that point of view, I don't  

#### [0:50:30](https://www.youtube.com/watch?v=x0qLJRivdmY&t=3030) |  think it really makes sense to worry

about whether or not a link to a noindex page is worse or better than a link to an indexable page. If people are linking to pages that are not findable in search on your website, then that might be a sign that perhaps these pages should be indexed. Otherwise people wouldn't be recommending them. But that's more of a tactical thing from SEO point of view.  

#### [0:51:00](https://www.youtube.com/watch?v=x0qLJRivdmY&t=3060) |  Like, are you providing the right content

for indexing? Or are you blocking things that you could be making indexable? How often are the links updated in Search Console? I don't know. I assume it's something like once or twice a week. As far as I know, most of the data in Search Console is updated about that frequently.  

#### [0:51:30](https://www.youtube.com/watch?v=x0qLJRivdmY&t=3090) |  I don't know if anything in particular

is different with regards to links. Is it better to use WordPress instead of having our own website software, not regarding special tags, but regarding to the HTML structure for Googlebot? No. You can use whatever platform you want HTML pages are HTML pages. You can take the output of WordPress and copy that into a text editor and save that as an HTML file  

![](https://i.ytimg.com/vi/x0qLJRivdmY/maxres3.jpg)



#### [0:52:00](https://www.youtube.com/watch?v=x0qLJRivdmY&t=3120) |  and it'll be the same from our

point of view. WordPress is definitely a way to make websites in an easy way, in a way that by default just works well for a search. But there are lots of different ways that you can make websites. And that includes making them with your own website software. I think one of the advantages of using a CMS like WordPress or using any of the hosting platforms is that you have a lot fewer things  

#### [0:52:30](https://www.youtube.com/watch?v=x0qLJRivdmY&t=3150) |  to worry about in the sense of

you don't have to worry about providing the way the HTML is served, you don't have to think about security as much because you can focus on the existing mechanisms that are well known for the CMSs-- especially if you're using a hosted platform then security is a lot less of an issue, scaling is a lot less of an issue. So that's the advantages. They are more from a practical point of view that you have to do less to get your content out there.  

#### [0:53:00](https://www.youtube.com/watch?v=x0qLJRivdmY&t=3180) |  Sometimes it still makes sense to roll

your own website software. Especially if you're doing it out of a hobby, then it's a lot of fun to roll run a run your own server, but you don't necessarily need to do that. There is no [? SEO ?] advantage of using WordPress over any other CMS over doing it yourself. Now we're running out of time and still so many questions.  

#### [0:53:30](https://www.youtube.com/watch?v=x0qLJRivdmY&t=3210) |  OK. Let me see if I can

run through some of these a little bit quicker, and then maybe we will have a little bit of time for more questions from you all. And of course, the first one is a really long question about international websites. I will skip that, because we're kind of out of time. But for longer questions like this, I'd recommend checking in with the Webmaster Help Forums  

#### [0:54:00](https://www.youtube.com/watch?v=x0qLJRivdmY&t=3240) |  because they can look at some of

the examples that you have there and give you a little bit more specific advice. Does Google prioritize above the fold content over the rest of the page content when ranking a page? Not necessarily, no. Another FAQ mark up question. Should FAQ pages have the answers expanded, or can we use an accordion style where the answers expand when clicked o? Yes, you can use an accordion style. The important part there is that the question  

#### [0:54:30](https://www.youtube.com/watch?v=x0qLJRivdmY&t=3270) |  is at least visible by default. One

of our websites got hit by unnatural links penalty. We removed many links. We created an Excel file and disavowed and removed. Still our reconsideration requests failed a few times. I feel like even if we disavow all of our links, it'll be denied and nobody is actually looking at it. What's up with this? So people do manually look at these links. And they do look at whether or not  

#### [0:55:00](https://www.youtube.com/watch?v=x0qLJRivdmY&t=3300) |  you're really significantly covering the links that

you should be focusing on. So it sounds to me like you're seeing some links there and you're cleaning those up. But maybe you're missing out on some other things that you should also be focusing on. Oftentimes when reconsideration requests fail they'll give you some sample URLs to think about as well. So I'd double check for that. If you're really unsure, I would recommend  

#### [0:55:30](https://www.youtube.com/watch?v=x0qLJRivdmY&t=3330) |  posting in one of the Webmaster Help

Forums so that people can take a look at things that you've disavowed and point you in a direction of some other things that you weren't thinking about. A spammy title tag including just keywords works better for our rankings rather than a natural title. What should we do? You can do it either way. It's not that we're saying your website will be penalized for having a spammy title tag.  

#### [0:56:00](https://www.youtube.com/watch?v=x0qLJRivdmY&t=3360) |  However, a title is a really obvious

thing in the search results. So just because you have a spammy title tag that ranks well, assuming that that's actually the case here, it doesn't mean that more people will be clicking on your link because maybe they don't understand what this page is about or maybe they go like, oh, this guy is just trying to spam. I'll click on the number 2 result instead. So I would primarily see the title  

#### [0:56:30](https://www.youtube.com/watch?v=x0qLJRivdmY&t=3390) |  as a way of encouraging people to

click on your pages and saying, well, this is the content that I have. And this is why it's relevant to your specific interests at the moment. So I'd use the title more in that direction rather than purely as a ranking element, because there are lots of ways that you can improve your rank. We experienced a big drop in traffic across two sites simultaneously in April.  

#### [0:57:00](https://www.youtube.com/watch?v=x0qLJRivdmY&t=3420) |  Have not been able to resolve that.

It was around that de-indexing bug. Are there any factors that could cause such a big drop outside of a major update? It's hard to know where to start looking. I don't know which sites these are. So that's-- JAMES: Hi, John. This is my question. JOHN MUELLER: Oh, OK. Fantastic. Someone's here. Cool. So that's hard to say.  

#### [0:57:30](https://www.youtube.com/watch?v=x0qLJRivdmY&t=3450) |  So offhand, the de-indexing bug that we

had there in April, that wouldn't be affecting it because that's something that is completely resolved. So that sounds more like a general change in ranking overall. JAMES: Yes. When you have something where two sites have dropped in the same hour on the same day, you-- should you be looking at some sort of commonality between the two?  

#### [0:58:00](https://www.youtube.com/watch?v=x0qLJRivdmY&t=3480) |  Is it also a the chance of

that being content related? There's obviously content improvements you can always make, but when it's two-- they are using the same code base, but two completely different subject matters, two completely different areas, where do you start-- where would you start looking, really? JOHN MUELLER: I guess what I would try to figure out is get rid of the most obvious things and narrow things down a little bit from there.  

#### [0:58:30](https://www.youtube.com/watch?v=x0qLJRivdmY&t=3510) |  So double check the manual actions. I

assume you take that. Double check for technical issues. So in particular, find pages on your website- are they index, are they not index, is the canonical correct, or are they being duplicate eliminated one against the other? Especially when you're saying they're on the same code base, then sometimes that can happen that pages on one website happened to be indexed as a canonical on the other website, and the other website says actually  

#### [0:59:00](https://www.youtube.com/watch?v=x0qLJRivdmY&t=3540) |  these pages are noindex. And then we

pick a canonical that is noindex. So narrow things down as much as you can to get rid of the obvious technical questions. Because if it's a technical issue then that's a lot easier to fix. It's a lot easier for you to test. And in the end if you figure out it's not a manual action, it's not a technical thing, then it's really something where the overall website doesn't really  

#### [0:59:30](https://www.youtube.com/watch?v=x0qLJRivdmY&t=3570) |  match what our algorithms are expecting anymore.

So that's the point where it gets hard. That for sure. But where you might need to take a step back and rethink how can we provide our website in a way that works well for the modern web user, . What kind of things might people be missing on our website? What ways are we, perhaps, presenting ourselves in a way that is detrimental to the way  

#### [1:00:00](https://www.youtube.com/watch?v=x0qLJRivdmY&t=3600) |  that users might look at these pages?

So for example, if these pages have a ton of ads on them, then that might be something where users, when they go to these pages, are like oh where's the content. And that could be reflected in our algorithms over time. But yeah, narrowing that down is really tricky. JAMES: Are there any rolling algorithm that, sort of from a security perspective, could trip on a certain day  

#### [1:00:30](https://www.youtube.com/watch?v=x0qLJRivdmY&t=3630) |  like that? JOHN MUELLER: It can happen

that the algorithms that we roll out have such an immediate effect across a number of sites. That can certainly happen. If you want, you can also drop a link to your forum thread, maybe here in the chat-- JAMES: Uh, yeah, I made a comment, actually. JOHN MUELLER: Oh cool, OK. JAMES: I think.  

#### [1:01:00](https://www.youtube.com/watch?v=x0qLJRivdmY&t=3660) |  Yeah. JOHN MUELLER: Cool OK. Yeah. Oh,

you have two questions. JAMES: Yes, one took ages to come up because I have the link in. JOHN MUELLER: All right, cool. JAMES: Thank you. JOHN MUELLER: I'll take a look at that afterwards. We had a manual review two months ago. We use a bad WordPress plugin. We fixed the problem. Google remove the manual action. The traffic came back. But after one week we lost all of our rankings. In Search Console there's no manual action. We asked the forum. Didn't get any advice. Will we have a high score on the PageSpeed insights.  

#### [1:01:30](https://www.youtube.com/watch?v=x0qLJRivdmY&t=3690) |  This site has about 80 posts of

original content. We removed all outgoing. Links we disavowed all backlinks. We removed all schema markup. Nothing changed. So on the one hand, it sounds like you're doing some pretty drastic changes. Probably a lot more than you need to do. On the other hand, some of these changes seem very technical in nature, and might not be related to the overall view of your website.  

#### [1:02:00](https://www.youtube.com/watch?v=x0qLJRivdmY&t=3720) |  So I would assume that this isn't

really related to the WordPress plugin. It's not related to the manual action. Because if that's resolved, then that's resolved. It's not that our algorithms would hold a grudge on that. It sounds like from a speed point of view you're doing OK. But speed doesn't mean that a website will rank automatically. It still has to be relevant. It has to match what our algorithms expect there.  

#### [1:02:30](https://www.youtube.com/watch?v=x0qLJRivdmY&t=3750) |  Removing all outgoing links, I think that's

probably too much. I don't see that helping a website ever. I would recommend making sure that you do have your outgoing links there to make it easier for people to find more context about the information that you provide. Disavowing all backlinks is also an extreme step, because if you're disavowing all links then none of those links are helping your site at all which  

#### [1:03:00](https://www.youtube.com/watch?v=x0qLJRivdmY&t=3780) |  makes it even harder for us to

rank your pages. So my recommendation there would be to step back from some of these extreme changes that you've made like removing the outlining and disavowing all backlinks, and instead to focus more on the website overall. And think about where might there be quality changes that you could work on. What might be some directions that you could take the website overall to help improve its quality overall? If you're talking about 80 posts of original content,  

#### [1:03:30](https://www.youtube.com/watch?v=x0qLJRivdmY&t=3810) |  then that's kind of a limited scope

of things that you'd have to look through. I would also keep in mind that when you're looking at the quality of a website, it's not just a textual content of these posts that matters. It's really the whole website overall that is-- that affects how users perceive your website. So it's trying to take a look at the bigger picture.  

#### [1:04:00](https://www.youtube.com/watch?v=x0qLJRivdmY&t=3840) |  Let's see. Structured [AUDIO OUT] Structured markup

question with the new how to markup. How does this interact with recipes? If you have a Pan Galactic Gargle Blaster page, should we use both? Or do recipe and how to target different types of searches? Also is it worth adding speakable about markup to the steps?  

#### [1:04:30](https://www.youtube.com/watch?v=x0qLJRivdmY&t=3870) |  I think you can probably do all

of that. I don't think we would show all of these at the same time. But we would probably pick one of those and show it depending on how people search. Also speakable markup, of course, is specific to a voice device. So that wouldn't be affecting how it's shown in the visible search results. Well, let me see.  

#### [1:05:00](https://www.youtube.com/watch?v=x0qLJRivdmY&t=3900) |  Can we do SEO using Blogger? If

so, how? Yes, you can you do SEO using Blogger. Lots of websites use Blogger and they work well in search. So that should be fine. Similar to WordPress, it's a way of making web pages, and you can make web pages and lots of different ways. I bet if I refresh this page there will be a ton more questions, but we're kind of over time already. So maybe I'll just open up to any of you. If there's anything still on your mind  

#### [1:05:30](https://www.youtube.com/watch?v=x0qLJRivdmY&t=3930) |  that maybe I can help with? Nothing?

RAGHUVEER: Hello, John. JOHN MUELLER: Hi RAGHUVEER: Yeah, I have one question. I have one website. JOHN MUELLER: Named? RAGHUVEER: https://www.example.com. Then I have moved my old container in https example.com.  

#### [1:06:00](https://www.youtube.com/watch?v=x0qLJRivdmY&t=3960) |  Then in that case, do I have

to create a webmaster or do I have to go with the existing webmaster? JOHN MUELLER: So I think you mean the Search Console account? RAGHUVEER: Yes, Search Console account. JOHN MUELLER: Yeah. So there are two ways now that you can do that in Search Console. On the one hand, it's per hostname. That's the traditional way to do it with a Meta Tag or something. And for that, HTTP and WWW, in the beginning  

#### [1:06:30](https://www.youtube.com/watch?v=x0qLJRivdmY&t=3990) |  they do play a role. So you

have to pick the right version. You can also do both of them if you want, if you're unsure where the data is. RAGHUVEER: In that case, do I have to do a redirection from WW to non WW? JOHN MUELLER: If you want, sure. You can pick one of those. That's a best practice. We recommend doing that. By setting up the redirect from one version to the other, you can help us to focus more on the version that you pick.  

#### [1:07:00](https://www.youtube.com/watch?v=x0qLJRivdmY&t=4020) |  That makes it easier for you. It

makes it easier to track. That's usually what we recommend. The other thing you can do in Search Console is if you verify with the DNS, with a domain name, then you can verify the whole domain. And that includes all of the version with HTPPS and not HTPPS and WW and non WWW. It's all included in the same account.  

#### [1:07:30](https://www.youtube.com/watch?v=x0qLJRivdmY&t=4050) |  So those are the two ways that

you can do that RAGHUVEER: OK, thank you. JOHN MUELLER: Sure. RICCARDO: And last question, John? JOHN MUELLER: OK. RICCARDO: I would like to know if you have any news about the question why some 404 on Google Search Console are 404 [INAUDIBLE] and how this is on crawl anomaly? JOHN MUELLER: I asked the team, and they didn't  

#### [1:08:00](https://www.youtube.com/watch?v=x0qLJRivdmY&t=4080) |  have an answer for me offhand. So

you found a tricky question. I think the crawl anomaly report is generally one that seems to confuse people, because there are a few things that come together there. So maybe we can make that a little bit clearer in the future. But I am still pushing for an answer for that particular part. Because I looked at my websites and I recently removed an AMP plug-in from my blog and half of these old AMP pages are as 404  

#### [1:08:30](https://www.youtube.com/watch?v=x0qLJRivdmY&t=4110) |  and half of them are as crawl

anomaly. Ad I'm like why are the same kinds of pages listed in different ways? But hopefully we can get that figured out. I switched to a pure AMP setup for my blogs to try things out. So that's why these old AMP pages show up is 404. But we'll see. RICCARDO: OK. Thank you. Cool JOHN MUELLER: OK. With that, let's take a break here.  

#### [1:09:00](https://www.youtube.com/watch?v=x0qLJRivdmY&t=4140) |  Thank you all for coming. Thanks for

submitting so many questions. I'll set up the next batch of Hangouts probably later today. So if there is anything on your mind that you still want to have covered, feel free to add that there. Or as always, feel free to drop by our Webmaster Help Forum where tons of people who have worked on similar issues are often able to help out as well. And finally on Twitter, we're doing a thing called #AskGoogleWebmasters,  

#### [1:09:30](https://www.youtube.com/watch?v=x0qLJRivdmY&t=4170) |  where if you include that hashtag we'll

try to include that and one of the future short videos, if there is something not site specific that you'd like to ask. All right, great. So thanks again and I wish you all a fantastic weekend. Bye everyone.  