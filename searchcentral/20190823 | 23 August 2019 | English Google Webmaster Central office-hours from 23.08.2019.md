[![English Google Webmaster Central office-hours from 23.08.2019](https://i.ytimg.com/vi/acr3i9UCCZ0/maxresdefault.jpg)](https://www.youtube.com/watch?v=acr3i9UCCZ0)

## English Google Webmaster Central office-hours from 23.08.2019

This is a recording of the Google Webmaster Central office-hours hangout from 23.08.2019. These sessions are open to anything webmaster related like crawling, indexing, mobile sites, internationalization, duplicate content, Sitemaps, Search Console, pagination, duplicate content, multi-lingual/multi-regional sites, etc. 



Watch out for new sessions, and add your questions at https://www.youtube.com/user/GoogleWebmasterHelp/community



Feel free to join us - we welcome webmasters of all levels!



Subscribe to Google Search Central â†’ https://goo.gle/SearchCentral



#### [0:00:00](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=0) |  MARTIN SPLITT: The infinite spinner. JOHN MUELLER:

Some people-- or are we on? OK. Welcome, everyone, to today's Webmaster Central office-hours Hangouts. My name is John Mueller. And with us is Martin Splitt. We're webmaster trends analysts at Google here in Switzerland. And part of what we do are these office-hours hangouts. We have a slightly different setup this time, which is more like a meeting room,  

#### [0:00:30](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=30) |  because we're expecting one more person to

join. So that'll be pretty cool. I have all of your questions here, so we can go through those. Or if any of you want, you're welcome to jump in with the first question from your side. KONSTANTIN ZOBOV: Hi, guys. JOHN MUELLER: Hi. MARTIN SPLITT: Hey. KONSTANTIN ZOBOV: I asked a question about the ranking of one of the biggest domains, amazon.com,  

#### [0:01:00](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=60) |  and their product pages, which lack the

content part but get the high SERP positions. Can please give some information how this works? Or is there a secret why they're getting all those top ranked without even having proper content on the web pages? JOHN MUELLER: There's not really a secret. So I looked at those pages that-- so you mentioned a query there, and I looked at that. And from my point of view, there is content on there.  

#### [0:01:30](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=90) |  There are reviews on there. It feels

like there is stuff on there that would make sense to show in the search results. So I don't see anything specifically problematic with those pages, where there would need to be some kind of a secret Amazon bonus or anything like that. Sometimes really large sites do have pages that aren't really perfect, but the rest of the site is really good. So sometimes it can happen that we rank pages that individually  

#### [0:02:00](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=120) |  might not be fantastic, but are otherwise

on a reasonable website. So that might be happening to some of those pages that you're seeing, but even for the query that you mentioned, that content looks reasonable. You can buy the product there. It has the technical details. From my point of view, that-- KONSTANTIN ZOBOV: Well, that's basically the case.  

#### [0:02:30](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=150) |  Sorry if I interrupted you. So technically,

there is no technical information. They're like five sentences. And they're short, two-word sentences, and there are five of them. Basically, it's 15 words of description of the product, and everything else is completely links to other PDPs. And in terms of review, there was just one review. That's why we get kind of concerned. Because we started working on the platform, then we close our products. But this kind of weird PDP just simply appear from nowhere. And there is no useful kind, because I work in this field  

#### [0:03:00](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=180) |  currently, for these specific products, and got

really surprised when I saw just, really, 10 to 15 words. And it's not even looks to be a proper description of the product. That's why I asked this question. JOHN MUELLER: Maybe I saw a different page, or maybe they serve different pages to different users. But from my point of view, looking at the query and looking at the product-- MARTIN SPLITT: Yeah, it looks really good. JOHN MUELLER: --it looks OK. I think, in general, it's always possible to find  

#### [0:03:30](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=210) |  pages that are kind of suboptimal on

larger websites. And when you're competing with a really large competitor like that, it's always going to be hard. So that's something where I wouldn't purely focus on the number of words or the amount of technical information that you have there. If you're competing one-to-one with a really big website that does a lot of stuff really well, then that's going to be really hard. So my usual recommendation would be  

#### [0:04:00](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=240) |  to try to find angles that are

unique, that you can cover, that they're not interested in even trying to cover. MARTIN SPLITT: Also I wouldn't fall for the, oh, it's only 17 words. As John said, we might see a different page. But the page that I'm seeing, if I would be a user and wanting to buy this camera, it tells me the video resolution, it tells me the frame rate, it tells me the interface, the measurements, the price, the shipping information. It has reviews.  

#### [0:04:30](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=270) |  It has answered questions. It has all

the manufacturer data. It's not the length of a product detail page. It's the content. And as far as I'm aware, the content page that I'm being served looks pretty decent. KONSTANTIN ZOBOV: OK. JOHN MUELLER: I think what you might also want to keep in mind is that we generally crawl from the US. So if, for example, they serve an empty page to users outside of the US but they serve the full content  

#### [0:05:00](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=300) |  to users in the US, then we

would still be able to index that full content page. And that sometimes throws those things off for our side because nobody likes to do things for Switzerland, so we always see empty stuff or you can't buy it. But we would still index that in Google and show it worldwide because we only see the US version because, technically, that's where our data centers are that do the crawling. MARTIN SPLITT: And at least in my search results,  

#### [0:05:30](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=330) |  it's on position 7 for that query,

so there's a bunch of other pages that are ranking higher, at least for me right now. KONSTANTIN ZOBOV: Something changed during the last week, honestly. Amazon started dropping down. I don't know if it's a coincidence or something else. Was surprising to me, but yes. And you see top two results is our pages basically. That's a good news, but also bad news. So I was real curious if there is a small secret way, just because they have a large volume of pages and links everywhere.  

#### [0:06:00](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=360) |  They have a very high rank for

the overall domain. OK. Good to know. Thank you very much. JOHN MUELLER: Sure. All right. Any other questions from you all before we jump in? ANDREW SYCHEV: Hello, John. Hello, Martin. MARTIN SPLITT: Hi. ANDREW SYCHEV: So I have a client. And it is a federal medical center. And all content obviously goes through the doctors before it publishes on the website.  

#### [0:06:30](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=390) |  So do you think it is a

good idea to let users know that the information was checked by doctors and also put relevant structure data? What I mean, it's a medical center, after all, and it is a logical assume that you can trust the information. So, for example, the page which provides information about a surgery, where you can read about the surgery, check prices, and make an appointment. And the content of such pages also  

#### [0:07:00](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=420) |  checks by doctors because it contains medical

facts. So do I need to put information about this particular doctor who checked the page there? JOHN MUELLER: I think you don't need to do any of that. But if you're doing something good for your users, then I would highlight that and tell people what it is that you're doing, and highlight the value that is behind your content.  

#### [0:07:30](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=450) |  I think, in general, if you're spending

time and money to make things better, then don't hide that. Don't be shy with that. I realize with all of the E-A-T things, people would want to do that especially, but I think, just generally, from purely a user point of view, if you're doing something good and it's not  

#### [0:08:00](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=480) |  directly visible on your pages, then you

just might not realize that you're actually doing that. ANDREW SYCHEV: OK. OK, I get it. Thank you. JOHN MUELLER: Sure. OK. Let me run through some of the submitted questions so we don't lose track of them completely. Let me just refresh the list so that we get the newer ones. "When I select a domain property in Search Console, the property has no disavow tool."  

#### [0:08:30](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=510) |  Yes, that's true. Some of the tools

in Search Console are only available in the older version of Search Console. We're working on moving everything over, but as some things are still in the old one, you still need to use the traditional properties. Usually verification is pretty easy, so that should be less of an issue. "With the desktop version, I have structured data but no AMP version.  

#### [0:09:00](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=540) |  So does it violate Google's policy because

of two different versions?" It doesn't violate our policies, but we really, really want you to have the AMP version be equivalent to the normal version of your website. So structured data is usually less of a problem. But especially content-wise, navigation-wise, internal linking, all of that should be equivalent on AMP so that when users go to your AMP page, they're not served a stripped down page that doesn't serve their needs.  

#### [0:09:30](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=570) |  I know that's something that the AMP

team is always kind of struggling with because people think, well, I'm just make a really fast page, and to make a fast page I will show no information. But for users, that's a terrible experience. And in the long run, that's not going to be good for your site. "When the 90 days is up after you use the URL removal tool, does Google try to recall the URL directly?  

#### [0:10:00](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=600) |  If so, does it see the robots.txt

file or is it only when it spiders the site?" So the URL removal tool only hides a search result in the search results page. It doesn't change anything with crawling and indexing. So usually what happens is we hide it in the search results, and we will continue to crawl the page. And if that page is blocked from indexing, if it has a noindex, or if it's blocked by robots.txt or it's a 404,  

#### [0:10:30](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=630) |  then we'll drop it from our index,

and we won't have to crawl it as much anymore. So it's not after the 90 days. It's more that, during this time, we'll work to kind of re-process that page. I think the question kind of goes in the same vein and also covers kind of the quirk about robots.txt and noindex. If you have a noindex on a page and you block it by robots.txt,  

#### [0:11:00](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=660) |  then we don't see the noindex because

we can't crawl it. So I'd recommend doing either/or. If you do both of them, then we just don't see the noindex. Question about JSON schema markup for my handmade, one-of-a-kind products. "I don't have a global identifier, and Search Console gives me a warning for not adding one. I refuse to just make one up."  

#### [0:11:30](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=690) |  So there are two things here. On

the one hand, this is a warning It's not an error that will block everything. It's basically just saying, well, it would really help us to have an ID here so if there were multiple versions of this product, or multiple people selling the same product, we could group them together, potentially. So that's kind of the one thing. It's not that we would not process it at all. It's not an error.  

#### [0:12:00](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=720) |  It's just a warning. You don't have

to fix all warnings. A lot of sites have warnings with structured data, and that's perfectly fine. On the other hand, depending on how many products you're selling, it might make sense to try to get one of these IDs so that you can use that, especially if you're selling something that other people are reselling. Then maybe that makes sense. But ultimately, that part is definitely up to you.  

#### [0:12:30](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=750) |  I certainly wouldn't go out and just

make them up. Apparently you just register your company, and then you can start enumerating your product. So maybe it's not that much of a hassle. I don't really know. But again, it's a warning. It won't break everything. I'm working-- KONSTANTIN ZOBOV: John? JOHN MUELLER: Yeah. KONSTANTIN ZOBOV: I wanted to quickly ask you, since you touched the products in catalog, question  

#### [0:13:00](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=780) |  about the jackpot position. We see that

one of our products that we manufacture basically has the wrong name and descriptions, just because it was launched or submitted to Google a long time ago. And all other distributors use the same wrong name. Is there a way that we can just feed Google the correct product description, its correct GTIN number, or whatever unique identifier so it fixes the overall index, so it fixes  

#### [0:13:30](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=810) |  the major product information? So it doesn't

use the legacy one. JOHN MUELLER: I don't know. That's something you'd probably need to check with the folks from the shopping side. I don't know who would be best to get in touch with that. If you want, you can drop your information in the chat, and I can forward that on to the shopping team.  

#### [0:14:00](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=840) |  Maybe there is something that they could

send back to you. KONSTANTIN ZOBOV: Would be great. Thank you. JOHN MUELLER: Cool. "I'm working on geographical pages for UX. I hired a photographer to capture relevant images of the region. I'm wondering how Google distinguishes between new photography and existing stock photography, and if this can change search results."  

#### [0:14:30](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=870) |  So what would definitely happen is we

would see these as separate images, and we would index them as separate images. In Google Images, we would show them individually. They're unique images. Even if it's the same scenery, even if it's a similar view to existing ones, they're new images. The lighting is different. Everything is slightly different. So that's something, from that point of view, we would treat them as individual things  

#### [0:15:00](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=900) |  and rank them individually. From a web

search point of view, we would not really care what you use with regards to the images. So in web search, we focus on the textual content there. We don't have this differentiator where we'd say, well, this image is stock photography. Therefore it's bad. We essentially just say, well, there is an image here. There is an alt attribute. We can index the image for Google Images.  

#### [0:15:30](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=930) |  We can double-check to see if that's

a unique image that we need to index individually. But for normal web search, we wouldn't really need to take that into account. So from a web search point of view, that would probably not change a lot. For Google Images, it would change things. For users, I imagine, it would change things as well.  

![](https://i.ytimg.com/vi/acr3i9UCCZ0/maxres1.jpg)



#### [0:16:00](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=960) |  "With E-A-T, how much value do external

links carry? Surely providing that you're an expert on page is not sufficient. What else matters? Mentions? Or external links from relevant sites?" We don't have any explicit information with regards to what you need to do there. A lot of this comes from the Google rater guidelines, which are not direct search results or search ranking factors. But rather, this is what we give folks  

#### [0:16:30](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=990) |  when they evaluate the quality of our

search results. So from that point of view, it's not that you would need to gain this through links or anything like that. But rather, this is something that normal people look at when they review the quality of the search results and which, perhaps, normal users would kind of think about as well, is can I trust this website. So from that point of view, it's not a matter of you  

#### [0:17:00](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=1020) |  need to put these five words on

your website and then get a link from this other site. That's definitely not the case. But more a matter of really how you present your website overall and how users would perceive that. "My website is still crawling with desktop Googlebot. How much time will it take to change to mobile Googlebot?" So we've switched over a significant part of the web  

#### [0:17:30](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=1050) |  to mobile-first indexing, but we haven't switched

everything over. You don't need to do anything to force that switch over. Our systems use a number of algorithms to try to determine when a website is ready overall. We do that on a per-domain basis. And when we think that it's ready overall, we'll switch things over. So that's kind of the setup that we have there.  

#### [0:18:00](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=1080) |  There's no specific time where we'd say,

well, this [AUDIO OUT]. Oops. So from that point of view, you don't need to do anything specific. ALEXANDROS GEORGAKAKIS: Hi, John. SUJIT DAS: Hi, John. JOHN MUELLER: Hi. ALEXANDROS GEORGAKAKIS: This is Alex from Greece. How are you? JOHN MUELLER: Hi. ALEXANDROS GEORGAKAKIS: Can you hear me? JOHN MUELLER: Yes. ALEXANDROS GEORGAKAKIS: OK. I have a question regarding this crawling issue  

#### [0:18:30](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=1110) |  with the desktop bot. We had the

switch to mobile-first indexed on November of 2018. But a couple of months ago, we have switched back to desktop bot. Do you think that is normal? Is this something that you have seen before? JOHN MUELLER: That usually wouldn't be happening. But I don't know exactly what you're seeing,  

#### [0:19:00](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=1140) |  so it's really hard to say. Would

you able to add the URL maybe in the chat? Then I could take a look at that afterwards. ALEXANDROS GEORGAKAKIS: Yes, of course. I have made a comment with the whole situation. So you might read my question later in the conversation, OK? JOHN MUELLER: I saw your question, but I think you didn't mention the URL. So I don't know which site it is.  

#### [0:19:30](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=1170) |  But I-- ALEXANDROS GEORGAKAKIS: I'm just dropping

it down. I'm dropping it to the chat. Thank you. JOHN MUELLER: Cool. Thanks a lot. FARAZ KHAN: Hi, John. Just a quick question here. JOHN MUELLER: Sure. FARAZ KHAN: This is with regard to unicorn and duplication. We usually understand that duplication is not in the Google guidelines, right? And I think that's a very, very fair point to put across. But we were facing an issue where, if I could put it,  

#### [0:20:00](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=1200) |  our product, a very unique product, was

being offered by multiple brands. And we were creating the pages for those brands. So I think from a content perspective, the technical specifications or the way the product is structured will be the same. The only thing that it will be differentiated is by the brand name that is offering. So how is that content-- will that be treated as duplication? Or how it will be handled? JOHN MUELLER: We treat it on several levels,  

#### [0:20:30](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=1230) |  the duplicate content. On the one hand,

if the whole page is copied, then that's easy-- like the whole HTML page, then we can see that it's a duplicate. On the other hand, if a part of the page is copied, then we can see that that part of the page is duplicate. And what happens when just the part of the page is duplicate is we will index the whole page. We will index all of those versions. And if someone is searching for a specific part that it's only in that duplicated section of the page,  

#### [0:21:00](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=1260) |  then we will try to pick one

of those pages to show. From our point of view, that's kind of normal because we can recognize that the same content is available on different sites. It doesn't make sense to show all of the different versions of the same content. Usually what happens, especially with e-commerce sites, is that there are other things involved that help us to pick the right one. So if someone is searching for something local  

#### [0:21:30](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=1290) |  and we can recognize a store is

local, then we know it's duplicated content, but this is the local version so we'll try to show that one. So those are kind of the things that come up there. In general, when it comes to making sites, oftentimes you don't have time to write product descriptions for everything. So it makes sense to try to add additional value through other parts of the page, maybe through reviews on the page.  

#### [0:22:00](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=1320) |  Maybe you have your own product photos.

Maybe you have something else that you're doing unique to your website, unique to those specific products. And highlighting all of that makes it a lot easier for us to say, well, this is actually a unique version. We need to make sure that we don't just filter it out because it has a small description that's the same across different sites. JASON VERGARA: Same question. JOHN MUELLER: OK. JASON VERGARA: Say if you wanted to change from language region to just region and you redirect that respective URL.  

#### [0:22:30](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=1350) |  Would you lose ranking within that region

because you're no longer region targeting? It just goes to the dot com? JOHN MUELLER: If you're using geotargeting, then that would be kind of a generic page instead of the local page. And for queries where we can tell that a user is looking for something local, then that might have an effect. But if you're not using geotargeting, or if people are not explicitly looking for something local,  

#### [0:23:00](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=1380) |  then that wouldn't change anything. JASON VERGARA:

Sure. Thank you. JOHN MUELLER: Sure. DAN SMULLEN: Hey, John. JOHN MUELLER: Hi. DAN SMULLEN: How you doing? Greetings from Dublin, Ireland. I have a question for you regarding sitemaps. So I wanted to get a couple of pages in a XML sitemap. So I ran a crawl in Screaming Frog and latched them up to the developers to put on our server  

#### [0:23:30](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=1410) |  so that I could submit it in

Google Search Console. But when I got it, it was actually on a subdomain and not on the domain itself. And now it's in the sitemap index. So I was just wondering, will the Googlebot come in, find the sitemap index, find that? Even if it's on a subdomain and the URLs are for the actual main domain, can it find that XML sitemap and will it crawl those URLs, or does it have to be on the domain itself?  

#### [0:24:00](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=1440) |  JOHN MUELLER: If we get the sitemaps

submitted individually, then it has to be within the same path. On the other hand, if it's submitted through Search Console and you have the subdomain also verified in the same account, then that would work. So that's kind of the way that sitemaps works, is for unauthenticated submissions, I guess. If you don't do it in Search Console, then the URLs within the sitemap have  

#### [0:24:30](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=1470) |  to be below the path of that

sitemap file. If you're doing it through Search Console, then the URLs in the sitemap file can be for any valid property within your Search Console account. DAN SMULLEN: OK. Well, thank you. JOHN MUELLER: Sure. All right. More questions from your side? I mean, I have more in this list, so I can continue running through those. But up to you. MARTIN SPLITT: JavaScript questions  

#### [0:25:00](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=1500) |  or specific technical questions? SPEAKER 1: Oh,

you feel that? MARTIN SPLITT: This is what happens. JOHN MUELLER: OK. My site is still being crawled with the desktop crawler. How much time will it take to switch to mobile Googlebot? MARTIN SPLITT: It can take a while. There's another question in there that asked, can I switch to mobile Googlebot. There is no way to opt in or out. We're just progressively changing or moving sites  

#### [0:25:30](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=1530) |  to mobile-first indexing. But there's no way

to tell you, oh, yeah, next week's going to be you. Be patient. It'll happen. It'll be fine. ALEXANDROS GEORGAKAKIS: Hi, again. MARTIN SPLITT: Hi. JOHN MUELLER: Hi. ALEXANDROS GEORGAKAKIS: I have asked this a couple of minutes ago, but I think you weren't in the conversation.  

#### [0:26:00](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=1560) |  Regarding the switch from Google smartphone bot

to the Google desktop one, we have switched to a Google smartphone bot on November 2018. But a couple of months ago, we have switched back to a Google desktop.  

#### [0:26:30](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=1590) |  Do you think that this is something

normal? And why this might have happened? JOHN MUELLER: I don't know. I think you dropped the link-- ALEXANDROS GEORGAKAKIS: I dropped the URL. Yes, yes, yes. JOHN MUELLER: Yeah. I need to check with our team, kind of what the status is there. Did you get a notification in Search Console? ALEXANDROS GEORGAKAKIS: No notification whatsoever. And what-- JOHN MUELLER: After the switch to mobile, did you get one? ALEXANDROS GEORGAKAKIS: We had the notification  

#### [0:27:00](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=1620) |  that we have switched to a smartphone

bot, but never a notification that we have switched back. JOHN MUELLER: OK. I don't think we have notifications that we switch back. But it's something-- in talking with the team, they generally wouldn't switch sites back. MARTIN SPLITT: Yeah. JOHN MUELLER: So that's something where, from discussions with them, if they switch one site over and it turns out the website does a redesign  

#### [0:27:30](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=1650) |  and then doesn't work so well on

mobile anymore, then it's tough luck. We switched over. So I think maybe something weird happened in your case. ALEXANDROS GEORGAKAKIS: What is strange is that we are still top performant at Google Search. We are top performant at Google News. Our AMP pages are at the top performance, 99% accessibility sale rankings, et cetera.  

#### [0:28:00](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=1680) |  And the crawling we see at our

logs from Google smartphone bot is at about 70%, and the Google desktop bot is at about 30%. That's why we are a little skeptical. JOHN MUELLER: That's kind of normal. No, but that's-- ALEXANDROS GEORGAKAKIS: Yeah, yeah, yeah. It's normal, but why is mentioned that's a Google desktop?  

#### [0:28:30](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=1710) |  I can send you the screenshots. JOHN

MUELLER: Yeah, I mean, screenshots would be useful. But in general, when we switch to mobile-first indexing, we still have a split of 80/20 or 70/30 desktop and mobile. So it's not purely mobile, then. And for some kinds of requests, we just use the desktop Googlebot. For example, I think the shopping requests are done with desktop Googlebot.  

#### [0:29:00](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=1740) |  I think for a news site, that

doesn't really matter. But depending on the website, if you look at the overall traffic, then it won't be 100% mobile or even 90% mobile. There will always be 20%, 30%, 40% still with desktop. But I can definitely take a look at that with the team. ALEXANDROS GEORGAKAKIS: OK. Thank you. Thank you very much. JOHN MUELLER: Sure. You also, I think, asked about the Chrome--  

#### [0:29:30](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=1770) |  or was it the new-- ALEXANDROS GEORGAKAKIS:

Google Chrome suggestions, yeah. Yeah. JOHN MUELLER: I have no information on that, how that comes together. Because in the Discover feed, that's something where we do use the normal crawling and indexing. And it's kind of separated out. But I don't know how the Chrome suggestions works there, or how you would rank there. I suspect it wouldn't be a matter of a technical issue,  

#### [0:30:00](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=1800) |  but rather that-- I don't know-- some

fancy Chrome ranking factor, which apparently is now a thing. Yeah. Cool. I will double-check with that, too, with the team, though. ALEXANDROS GEORGAKAKIS: Thanks a lot. Thanks a lot. JOHN MUELLER: Sure. All right. We're kind of running low on time, but if any of you want to ask more questions, it's like we have a bunch of you here, so.  

#### [0:30:30](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=1830) |  ALEXANDROS GEORGAKAKIS: I have another question. JOHN

MUELLER: OK. Go for it. ALEXANDROS GEORGAKAKIS: You mentioned before that the version of the desktop should be exactly the same as the mobile one. In regards of content, or markup-wise as well? Because we don't have the exact same template on desktop and the mobile. We detect the user agent, and we are using a separate desktop  

#### [0:31:00](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=1860) |  template and a separate mobile template to

be more optimal for the user. It's much better performant if you are using less markup, more optimized images, smaller images, et cetera. What is your opinion on that? JOHN MUELLER: That's perfectly fine. ALEXANDROS GEORGAKAKIS: OK. Thank you. JOHN MUELLER: The thing I would watch out  

#### [0:31:30](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=1890) |  for is with mobile-first indexing, when we

do that, we will only use the mobile version for indexing. Like I said, we still crawl with the desktop sometimes. But we use the mobile for indexing. So things like internal linking, we would use the mobile version. So if, on the mobile version, you don't have any of the navigation, then that would be a problem. ALEXANDROS GEORGAKAKIS: OK. JOHN MUELLER: But if the navigation is there and the layout is different, the HTML is different, that's totally fine.  

#### [0:32:00](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=1920) |  ALEXANDROS GEORGAKAKIS: Thank you. SPEAKER 1: One

last JavaScript question. JOHN MUELLER: OK. SPEAKER 1: So I was just wondering. I know you don't-- it's a little bit close to my previous question, but what's the metric that looks, OK, you look at that, OK, this website's going to go into two waves and this one isn't? So we see that quite a lot of JavaScript websites are not within two waves. Maybe there is not enough JavaScript or whatever. Actually, we have quite a lot of reports recently to play with that, because we're investigating that.  

![](https://i.ytimg.com/vi/acr3i9UCCZ0/maxres2.jpg)



#### [0:32:30](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=1950) |  MARTIN SPLITT: Do you want to answer

that or shall I answer that? JOHN MUELLER: I can hand wave. MARTIN SPLITT: You can hand wave. [LAUGHTER] SPEAKER 1: I had a John question. It's the worst question. MARTIN SPLITT: So these days, the two waves of indexing play less and less of a role. So basically, generally speaking, you may see a lot of websites that are not using JavaScript that are still going through, basically, two waves. And you might see a bunch of-- SPEAKER 1: Wait, wait, wait, wait, wait. Explain that. MARTIN SPLITT: Right.  

#### [0:33:00](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=1980) |  OK, so how do I put this?

SPEAKER 1: So is it like heavy CSS or-- MARTIN SPLITT: Pretty much-- no. So here's the thing. Pretty much every website, when we see them for the first time, goes through rendering. So there's no indexing before it hasn't been rendered. And there are certain heuristics that, if we see after a while, oh, this page actually the renderer does not diff as much, or doesn't diff. It looks the way before-- so what happens is we do a crawl, right? SPEAKER 1: So you get a new domain. MARTIN SPLITT: We do a crawl which means-- yeah,  

#### [0:33:30](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=2010) |  let's say you get a new domain.

SPEAKER 1: You learn how much CPU this new domain was-- MARTIN SPLITT: No. SPEAKER 1: --taking. MARTIN SPLITT: No. SPEAKER 1: All right. MARTIN SPLITT: That's not what we do. What we do is we do an HTTP request. We get something back, right? Some HTML. Maybe it's a bare bones HTML and all it does is to load some JavaScript and run the JavaScript. Then this HTML that we got from the original HTTP GET request from the crawl goes into rendering. Rendering goes into JavaScript. Boom, a lot of content happened that wasn't there before. So we're like, a-ha!  

#### [0:34:00](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=2040) |  OK. So this needs to be rendered.

But there is a heuristic that is very rarely-- SPEAKER 1: So you look at the difference between the initial HTML. And then, after rendering, you see extra content. MARTIN SPLITT: Yeah. SPEAKER 1: OK. MARTIN SPLITT: The interesting thing is that-- so what I want to make very, very clear, because I talked to the team and I was surprised about this. I thought this is still a lot more frequently happening, that we are going, oh, all right,  

#### [0:34:30](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=2070) |  we're going to skip rendering. It is

not as frequently happening anymore. So for many, many websites, even if they do not run JavaScript, they might still go through the render phase because it doesn't make a difference as much. JOHN MUELLER: Because it's cheaper. MARTIN SPLITT: It's cheap. It's cheaper than the complexity that we incur. So there's very, very few cases. And the internals of that are very complicated. And I still haven't fully grasped what exactly triggers the heuristics. SPEAKER 1: Because we see that there  

#### [0:35:00](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=2100) |  are quite a lot of JavaScript websites

that never go through two waves. There are some websites that go through two-- again, we don't see the real difference. So one of the factors for you is the difference between the-- MARTIN SPLITT: The initial crawl. SPEAKER 1: The initial HTML whatever, or then the rendered DOM. MARTIN SPLITT: Yeah. SPEAKER 1: OK. MARTIN SPLITT: Crawled DOM and rendered DOM. SPEAKER 1: That's interesting. MARTIN SPLITT: And I wouldn't say that two waves of indexing are dead, but it's definitely something that--  

#### [0:35:30](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=2130) |  SPEAKER 1: Oh, they're not. MARTIN SPLITT:

They're absolutely not, but it's definitely-- I expect eventually rendering, crawling, and indexing will come closer together. We're not there yet, but I know that teams are looking into it. No plans, no deadlines, no roadmaps to be announced yet, but-- SPEAKER 1: You winked twice. You winked. JOHN MUELLER: What about link juice, Martin? How does link juice play into role with rendering?  

#### [0:36:00](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=2160) |  [LAUGHTER] SPEAKER 1: He has to finish

that because I have this concept in my head that JavaScript SEO is dying slowly. It's going to eventually dissolve because you guys are getting better with that. So basically, you are on the path of just killing two waves, eventually completely, right? Can we confirm? JOHN MUELLER: I would say that we're hoping to make it all a little bit better, so that you don't have more things. MARTIN SPLITT: All of it. JOHN MUELLER: But kind of like with normal technical SEO,  

#### [0:36:30](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=2190) |  I don't see JavaScript SEO as dying

because there's just so many things that you can do wrong. And it takes a lot of experience to be able to debug and find out how to improve things. MARTIN SPLITT: And it keeps changing, right? There's new stuff coming in. SPEAKER 1: Totally. JOHN MUELLER: And with every new bit on the web platform, you're like, does this work with Googlebot? SPEAKER 1: So this is interesting. Sorry, John. Sorry about that. I want to follow-up on what you said. So you're saying that even if you guys get so good with JavaScript-- obviously, basically, with resources and I'm guessing some kind of technology that  

#### [0:37:00](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=2220) |  you use to optimize that-- you still

think that JavaScript SEO is going to be-- JOHN MUELLER: I mean, in-- SPEAKER 1: In two years, or three years, you still think it's going to be a thing? Because I had this concept it's going to dissolve. JOHN MUELLER: I mean, it's going to be staying in that we'll be better at it. But there's still-- I mean, there are always technical details that you can get working well, or get working kind of-- MARTIN SPLITT: As well. JOHN MUELLER: --kind of terribly. SPEAKER 1: Oh, yeah. And JavaScript is--  

#### [0:37:30](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=2250) |  JOHN MUELLER: Like with JavaScript, with normal

technical SEO, it's already hard. And it's something that a lot of people struggle with, where it's the internal linking and you have unique URLs and all of these things. And with JavaScript it's all hidden away, so you really have to know how JavaScript works. And when something goes wrong, that's really not going to be trivial to find. And new frameworks, new elements in Chrome, all of these things, they kind of come together. SPEAKER 1: But my logic is that you guys are using-- sorry--  

#### [0:38:00](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=2280) |  the latest version of Chrome. MARTIN SPLITT:

Yes. SPEAKER 1: So with new frameworks, they actually work in the latest version of Chrome. So eventually it's going to be one-to-one. MARTIN SPLITT: There are still-- yes and no. SPEAKER 1: Is it naive thinking here? MARTIN SPLITT: It's a little naive to think that, because the thing is that you are, in the end, still not-- it's not that there's a human being sitting in front of it, looking at your website, going, ah, OK. It is a technical infrastructure. SPEAKER 1: It's not? MARTIN SPLITT: No. I know. There is technical infrastructure-- SPEAKER 1: You lied to me. MARTIN SPLITT: And there are so many interesting implementation  

#### [0:38:30](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=2310) |  details that can interact with the web

platform in interesting ways. To give you a very simple example, what we are doing with web components. I'm writing the guidance right now, so excuse me if I'm not having a very polished answer at this point. You get the raw answer from me. SPEAKER 1: I'll take that. MARTIN SPLITT: Web components work fine in Chrome. We have the latest version of Chrome, Chrome 76, as of a couple of days ago, in Googlebot. That's fine. The thing there is, we have to make a decision what to index.  

#### [0:39:00](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=2340) |  So as the user, depending-- let's say

if I go to a website that has a web component and there's something in the shadow DOM. Then I see the shadow DOM content. If I would run an Internet Explorer 10, I'd see the light DOM content, which gets overwritten. So some people might be like, oh, yeah, so if I have a fallback for crawlers that do not understand JavaScript, or I think I am going to be in the first wave of indexing first, I put my fallback content into the light DOM. But then Googlebot never sees that.  

#### [0:39:30](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=2370) |  That's still something that you need to

know and be aware of. So you might end up with some person coming to you and going, this content is there. It's in the DOM. We don't understand why it's not showing up. And then you have to know, oh, that's because of JavaScript, specifically because of shadow DOM. The shadow DOM overwrites the light DOM. And the way that the Googlebot works is it flattens the shadow DOM into the DOM, overwriting the light DOM in this specific case. To make my point from earlier, JavaScript SEO is not going to go away. It's going to change, right?  

#### [0:40:00](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=2400) |  It used to be-- SPEAKER 1: It's

going to get much more technical. JOHN MUELLER: Oh, yeah. MARTIN SPLITT: That on one hand. And the thing is-- SPEAKER 1: More experiments. MARTIN SPLITT: --today, JavaScript SEO is about finding the pitfalls and the gotchas in today's technology and working around them, or figuring out a better way to do them. And in the future it's going to be more like, this is what can go wrong. It works out of the box, but these are the things that can still go wrong, and these are the things that we need to do to debug them. SPEAKER 1: We got a little bit geeky here, so just to summarize that--  

#### [0:40:30](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=2430) |  MARTIN SPLITT: Yeah. [LAUGHS] SPEAKER 1: I

know you were trying to simplify that. But just to simplify that even further, basically what you're saying-- in the future, JavaScript SEO is going to evolve into making your jobs, or Google's job, a little bit easier and making sure that everything we push out to clients is basically very easy to crawl, index, and understand. JOHN MUELLER: I think that's one thing, but also all of the troubleshooting stuff kind of comes in that.  

#### [0:41:00](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=2460) |  And that's something where we can provide

some tools to help, but things like shadow DOM, light DOM, how are you going to figure that out unless you already know-- MARTIN SPLITT: Know what it is, yeah. JOHN MUELLER: --that is a thing. Or things like you're using Canvas to put content out there. And we think, oh, Canvas is an image, so we index it as an image. MARTIN SPLITT: There's a bunch of consulting. Right now, it's more figuring out what's going wrong probably and helping troubleshooting. And it's going to turn more into,  

#### [0:41:30](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=2490) |  there's 10 ways of doing this in

JavaScript. Nine of them are terrible because. While developers are trying to figure out the right way-- that's one of the reasons why I want developers and SEOs to sit on the same fricking table. Because developers are like, OK, so this is really hard for us. This is making everything slower. And they're not necessarily thinking about can Google index this, or can search engine see this. SPEAKER 1: Because I found out that for-- I know we have to finish. Sorry. JOHN MUELLER: Yeah.  

#### [0:42:00](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=2520) |  SPEAKER 1: I found that, for a

while, a lot of developers in SEO, in JavaScript SEO, is just advising developers to put it in there. I was waking up at night crying when I-- JOHN MUELLER: I think that was a good first step. SPEAKER 1: Because I see exactly what's happening. JOHN MUELLER: I think that that was a good first step. MARTIN SPLITT: Good first step, but. SPEAKER 1: Three years ago, maybe. I'm not a huge fan of [INAUDIBLE].. JOHN MUELLER: I mean, it's also one of those things where, in the first step, you have to know what the limitations are. And when you know the limitations,  

#### [0:42:30](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=2550) |  you can kind of work around them.

And if you have a website and you need to get it indexed, you can say, well, Google will figure it out in a couple of years. That's not a good business model. You have to do what you have to do. SPEAKER 1: I was actually completely looking at how quickly you catch up to technologies, how well you're doing compared to from a year ago. I had this vision in my head, in one or two years JavaScript-- MARTIN SPLITT: That warms my heart, because you're one of the few people who say we quickly catch up to things. SPEAKER 1: Oh, we're going to publish that quickly. MARTIN SPLITT: Oh, no.  

#### [0:43:00](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=2580) |  [LAUGHS] SPEAKER 1: We're going to publish

that soon. The heavy lifting you did with indexing is tremendous because just two years ago you couldn't index six pages of JavaScript when the link was nested in JavaScript. Sorry. So basically you're saying it's going to evolve into being much more complex. I actually-- sorry. JOHN MUELLER: Sorry. [LAUGHS] SPEAKER 1: I get excited. I like that idea. JOHN MUELLER: Cool. MARTIN SPLITT: Fairly technical, yeah. JOHN MUELLER: OK. Let's take a break here. I'll pause the recording before we fill up YouTube. [LAUGHTER]  

#### [0:43:30](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=2610) |  I mean, I think we could go

on forever. And probably there are a million questions from your side, as well, that you want to shove in. But we have to take a break somewhere, so I'll stop here. I'll set up the next sessions. You're welcome to drop the questions there or, of course, ping us on Twitter or post in the Webmaster Help forum. Folks there are really helpful as well. With that, let's take a break, and wish you all a great weekend. MARTIN SPLITT: Thank you very much. Have a great weekend. JOHN MUELLER: Bye.  

#### [0:44:00](https://www.youtube.com/watch?v=acr3i9UCCZ0&t=2640) |  Now if I could find the Stop

button.  