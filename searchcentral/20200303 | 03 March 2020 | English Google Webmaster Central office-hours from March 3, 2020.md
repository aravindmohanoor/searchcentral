[![English Google Webmaster Central office-hours from March 3, 2020](https://i.ytimg.com/vi/H6q-pnFjAHw/maxresdefault.jpg)](https://www.youtube.com/watch?v=H6q-pnFjAHw)

## English Google Webmaster Central office-hours from March 3, 2020

This is a recording of the Google Webmaster Central office-hours hangout from March 3, 2020. These sessions are open to anything webmaster related like crawling, indexing, mobile sites, internationalization, duplicate content, Sitemaps, Search Console, pagination, duplicate content, multi-lingual/multi-regional sites, etc. 



Watch out for new sessions, and add your questions at https://www.youtube.com/user/GoogleWebmasterHelp/community



Feel free to join us - we welcome webmasters of all levels!



#### [0:00:00](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=0) |  JOHN MUELLER: All right. Welcome, everyone, to

today's Webmaster Central Office Hours Hangout. My name is John Mueller. I'm a Webmaster Trends Analyst here at Google in Switzerland. And part of what we do are these Office Hour Hangouts, where webmasters and SEOs and Barry can join in to chat about their websites and Search and interesting topics they've seen along the way. A bunch of stuff is submitted on YouTube already.  

#### [0:00:30](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=30) |  But if any of you want to

get started, jump on in. AUDIENCE: May I? JOHN MUELLER: Go for it. AUDIENCE: Hello. I am working for one of the world's best surgeons in his field. He has many recognized academic publications, countless awards from respected authorities, [INAUDIBLE] and published by respected newspapers, magazines, TV channels in United States. He is actively taking place in many organizations and authoritative institutions like respected universities  

#### [0:01:00](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=60) |  in United States, too. And his website

was performing first page on many related search terms until 12 March, 2019 update. And then it lost 90% of its traffic from Google the next day, dramatic decline. I'm working and researching on it for seven months non-stop now. And we have actually no progress in Search at all. And our performance kept declining. Meanwhile, we manually and very carefully  

#### [0:01:30](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=90) |  reviewed all the bad things we can

reach and, least of all, really spammy ones carefully. Search Console shows no errors but excluded pages that we are totally fine with. We are actively maintaining according to Search Console. We develop mobile and desktop score, 200% of Google [INAUDIBLE] sites. And it has recovered. And the problem that we were able to identify was that this website was serving  

#### [0:02:00](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=120) |  exact text copy of his interviews copied

from those news websites. And actually, 30% of site content was like this. And would that be the problem? Because we were removing all of them. And we applied for a removal on Search Console. Yet it didn't solve the problem for passing one month after we took the action. And another thing we tried was moving to WordPress. But it's accelerated the decline.  

#### [0:02:30](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=150) |  After three weeks of experiments, we decided

to roll back. And what would be your opinion about this case? JOHN MUELLER: It's hard to say without knowing the site. So that's the first part that's a bit tricky. In general, with these kind of things, one thing I would do is make sure to have a forum thread where you have the details, so that people can look at that, and so that when you need to get more eyes on it,  

#### [0:03:00](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=180) |  you can point them at one place

where you have all of the information. So that's kind of what I would try to do there. In general, when you see changes from one day to the next, usually that's not a technical issue, because technical issues would kind of have that normal path of indexing as well associated with that, where you'd have a large amount of changes within a couple of days  

#### [0:03:30](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=210) |  and the rest kind of slowly moving

forward. Whereas if you're saying, it's really from one day to the next, then that sounds more like our algorithms are, for whatever reasons, maybe not as happy with the site as we were in the past or where we think maybe it wasn't as relevant as we initially thought. So assuming that's what you've been able to figure out, that it really happened from one day to the next, and that it's across the board, all of the pages, then I would focus less on technical issues  

#### [0:04:00](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=240) |  and more on overall quality and things

like that. AUDIENCE: And would there be a problem about medical content quality in terms of the citation or references? Should we been doing academic style citation on our medically advising content? JOHN MUELLER: I don't see an issue either way. I think that's essentially up to you.  

#### [0:04:30](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=270) |  But to me, I would try to

take a step back and think about how the website is perceived overall. And try to find maybe some bigger picture issues that are maybe worth focusing on. I don't think it's something like you have the wrong HTML for a citation. That's not something that I would consider to be a problem. AUDIENCE: OK. One last question, John. He really has this recognition in real life but not on Google.  

#### [0:05:00](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=300) |  And we really were searching as a

team, researching, reading any kinds of articles on every respected-- also Google's pages. And would it be possible, if I sent you the case, would you have a look at it for us? JOHN MUELLER: I am happy to take a look. You can post maybe a link in the chat. And I can pick that up afterwards as well. But I can't guarantee that there'll be anything specific that I'd be able to say. AUDIENCE: Yeah, sure. Thank you very much. JOHN MUELLER: Sure.  

#### [0:05:30](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=330) |  All right. Any other questions before we

get started with the submitted ones? AUDIENCE: John, can I jump in and ask some infinite scroll-based questions? JOHN MUELLER: All right. AUDIENCE: Basically, it's an e-commerce site that we're looking at, at the moment. And they're trying to implement infinite scroll. And the question I have mainly centers around  

#### [0:06:00](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=360) |  the idea that the Google-selected canonical URLs

might be different from webmaster initiated canonical URLs. So the behavior that's being displayed from the cart at the moment is that they are referencing the first page in the paginated series on category pages as the canonical URL.  

#### [0:06:30](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=390) |  And I guess the question that I

have is do Google-- do Google drop the outbound seconds on the subsequent pages of a canonical URL specified? JOHN MUELLER: I don't see a big issue with us dropping the second pages like that.  

#### [0:07:00](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=420) |  But it's hard to say exactly what

your setup is. It sounds like when you scroll down, it changes the URL. It's an infinite-- how is the the infinite scroll set up? AUDIENCE: It is terribly implemented at the moment. There's no reference to the other URL. What they almost seem to have done is they've stuck a rel="prev" and next in the heads of the document that references subsequent pages. And you guys pay no attention to that.  

#### [0:07:30](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=450) |  It looks like they're all sort of

soft 404ing subsequent pages, because it looks like Google is guessing the next page in the paginated series to index all the content, from what I can see. Of course, I don't have access to Webmaster Tools on that particular site. It's a demo site, if you like. So I guess the question I'm asking really is if there's five pages within a category, and we're trying to get all the maximum SEO  

#### [0:08:00](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=480) |  value from the-- we're competing with some

bigger players. So we want to squeeze every last drop out of the SEO onsite that we can, so [INAUDIBLE] links, all that kind of stuff. Do we really want to get Google to index all of these category page 2, page 3, if all the products are on there, rather than just dumping in a 20,000-page XML file? There's no signals. There's no-- I don't see any SEO value from that.  

#### [0:08:30](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=510) |  Is it worth the extra effort to

implement, I guess, your solution from 2014 in that process? Does it make sense to do the extra effort? JOHN MUELLER: Yeah, so do you have a category set up at the moment? Or is it just one giant list that leads to the products? AUDIENCE: They will have-- another favorite topic of yours, I think, is they're going to implement a mega-menu, which is not ideal,  

#### [0:09:00](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=540) |  is it, really? But it's the best

they have. JOHN MUELLER: OK. So I think if they have a category-based setup where they have one page that lists all products kind of thing, but they have those products in individual categories as well-- and the lists per category is reasonable-- then I think that should be fine. So the important part from our side  

#### [0:09:30](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=570) |  is that we're able to find all

of the product URLs. So that's something you could check with a local crawler if you have something like Screaming Frog or Deep Crawl, one of those tools, where you can crawl the website yourself. And kind of double check that actually it's possible to reach every one of the product pages, for example. And if we can reach all of those product pages through a category page, then that kind of infinite list of general products that you might also have,  

#### [0:10:00](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=600) |  that's less of an issue. But that's

something where it depends on how you have that set up, like how many items you have per page, and how the infinite scrolling is set up, how many categories you split that across. I think what I would try to do is balance kind of a reasonable hierarchy for your product so that you have a reasonable amount of categories and that you have, within each category, a reasonable amount of individual pages  

#### [0:10:30](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=630) |  that lead to the product pages, so

that it's not too flat but also not just one long listing that's very deep. AUDIENCE: So in an ideal world, would you want Google to be able to land on a category page, scroll through five pages, and pick up the URLs that way? Because there's a hierarchy implemented. There's on-page signals. There's internal links that are going there from the page, those header ones, and title tags. You would want Google to be able to see all of that and those products listed within that hierarchy  

#### [0:11:00](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=660) |  to pass those signals to get maximum

SEO benefit? JOHN MUELLER: I wouldn't look at it for maximum SEO benefit, but just purely from a technical point of view. Is Google even able to find those products? AUDIENCE: Sure. JOHN MUELLER: And then when that baseline of Google is even able to find everything is passed, which is usually pretty hard-- it's not always that trivial-- then that's something where you can think about, which of these products are important?  

#### [0:11:30](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=690) |  And how can I kind of present

them in a way that Googlebot, when it crawls, recognizes that these are important? AUDIENCE: Sure, that's great. I'm just thinking about the PageRank algorithm, really, and the flow of internal-- JOHN MUELLER: Yeah, usually, it's not worth thinking about the PageRank algorithm at that level, because especially with these really large websites, the big issue is really, can it even be found? And if it's findable, and if it's a reasonable structure  

#### [0:12:00](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=720) |  that it's not too deep, not too

flat, then that's something where it should work out. AUDIENCE: Do you have a preference on categorizing in terms of the menu structure? I know you're not a fan of mega-menus. Neither am I. Do you have anything that you could maybe point me to, to have a look at a more optimal setup, perhaps? JOHN MUELLER: I don't think we have anything that I could point at there. What I would do is mostly focus on usability.  

#### [0:12:30](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=750) |  And if, from a crawling point of

view, we can find everything and usability is OK, that users don't bounce, then that's a good point to be. AUDIENCE: Great, OK, thanks. JOHN MUELLER: Sure. AUDIENCE: Yeah, so, John? JOHN MUELLER: Sure, hi. AUDIENCE: Hi. Hello. JOHN MUELLER: Hi. AUDIENCE: Yeah, so, John, I just wanted to know, being SEO, would you recommend SEO people to focus on PageRank  

#### [0:13:00](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=780) |  while optimizing for internal linking? Or no,

they should not do like this? Because I am sure there is some-- not some, but majority of SEOs think for internal links only from PageRank perspective. So what is your solution on this? JOHN MUELLER: I don't think that makes sense. Yeah. So I mean, I think it's interesting to look at the different algorithms that Google uses. But I don't think focusing on things like internal page rank makes a lot of sense.  

![](https://i.ytimg.com/vi/H6q-pnFjAHw/maxres1.jpg)



#### [0:13:30](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=810) |  I would try to look at it

more from a holistic point of view. If there's something important on your website, then make sure that that's really important to everyone. But I don't think it makes sense to calculate the internal page rank and try to optimize things around like that. So one example that we often see is that people try to take their terms of service page and kind of hide that from Google's algorithm  

#### [0:14:00](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=840) |  so that it doesn't collect any page

rank. And usually, that doesn't make any sense, because we understand that websites have a structure like this. And there's no need to hide that, to block it from indexing, to use internal no-follow links, anything like that. So that's something where it's very easy to get lost in the weeds and to do a lot of analysis to try to find the optimal PageRank flow within a website. But most of the time, it's wasted effort. AUDIENCE: And in this case, one example is that when--  

#### [0:14:30](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=870) |  I have seen a lot of people

asking for link in external site, and we should give the internal link to that particular page. And most of the times, in forum, people are asking only thinking that, OK, PageRank, this is why everyone recommends to add an internal linking. JOHN MUELLER: I think you should always have an internal link to a page. If something is important, then make sure it's findable.  

#### [0:15:00](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=900) |  Not from a PageRank rank point of

view, but just general point of view, if you care about the page, then it should be findable for users when they go to your website. AUDIENCE: Mm-hmm. OK, thanks. JOHN MUELLER: Sure. AUDIENCE: Hello, John. JOHN MUELLER: Hi. Let me run through some of the submitted questions first. And I'll get back to all of you that are trying to get some live questions in as well, because lots of these things got submitted over time.  

#### [0:15:30](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=930) |  And it's useful to go through them,

too. So the first one is, "I work for the World Health Organization, and our website is not findable." So there's a long rant there, too. But it would be useful to know which websites you're talking about. So if you can send me the site or post a link, I am happy to take a look at that. "I've been fooling around with some rank trackers out there.  

#### [0:16:00](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=960) |  They tell me that for all of

the keywords in their database, my site ranks position 11 way more often than any other position. I can reproduce this in multiple services and anecdotally as well. Looking at this data on the graph, the distribution is not even close to normal, nothing like my competitors' distributions. It looks really like some kind of penalty or artificial limit that's happening to my site. Can you think of any penalty or something else that would result in disproportionate number of site's results landing in position 11?"  

#### [0:16:30](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=990) |  No, so I'm not aware of anything

specific that would cause something like this. My guess is that it's probably tricky across different rank trackers. So that's something where, instead of using external rank tracking tools, I would look at the search results yourself. And try to think about what is actually going on there, because it's something where we often show a lot of different elements in the search results.  

#### [0:17:00](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=1020) |  And there are lots of ways to

be seen in the search results. So position 11-- just having that number alone-- I don't think that really tells you a lot. So from that point of view, I wouldn't focus on this kind of artificial ranking number that you're seeing there. But really, try to look at what is actually happening in search. "I know there's a lot of talk this week. But do you know if the no-follow change is live for crawling and indexing? I know the original date was March 1.  

#### [0:17:30](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=1050) |  Just wondering if that's live now." So

this is something where we made some changes in our Search algorithms with regards to how we treat no-follow links. I believe the change was split into two parts, one kind of being able to pass signals through no-follow links and the other with using no-follow links for discovering new URLs. And essentially, on our side, the change  

#### [0:18:00](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=1080) |  is that internal systems are now able

to do this. That doesn't mean that internal systems are currently doing it. But at least from a policy point of view, they're able to take this on. And if there are teams within Google that say, I will be able to-- I would want to use this, then that's something that they're open to doing that. So it's possible for them to do it. It's not the case that it's like we're pumping everything full through those links now. It really depends on what teams internally are kind of testing, evaluating, and what makes sense for them.  

#### [0:18:30](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=1110) |  AUDIENCE: Do you know if teams are--

JOHN MUELLER: "We implement organization markup--" AUDIENCE: John, do you know if teams are actually doing anything with that now that they're allowed to? JOHN MUELLER: I don't know. I don't know. AUDIENCE: OK, thank you. JOHN MUELLER: They can. But I don't know. [LAUGHS] Yeah. I also think it's not something where you would see kind of a big invisible change in the search results just because they're suddenly doing this. I imagine the changes would be more subtle.  

#### [0:19:00](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=1140) |  AUDIENCE: A big invisible change that you

could see-- that would be amazing. JOHN MUELLER: Yeah, I don't know. I mean, it's something where we also try to use it as a signal. So it's not like we will just ignore it completely. But we'll try to figure out where it makes sense and where it doesn't make sense. AUDIENCE: So to summarize, the policy change allows anybody in Google to use it for indexing and ranking purposes. But it doesn't mean that you are doing it. And as far as you know, nobody is really doing anything  

#### [0:19:30](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=1170) |  at Google since the change? JOHN MUELLER:

So I haven't looked into whether or not people are actually doing it. But I don't know of anything specific. AUDIENCE: OK, thank you. JOHN MUELLER: "We implemented organization markup from schema.org. There is no postal code on the page. Can we add it only for robots, like--" [AUDIO OUT]..  

#### [0:20:00](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=1200) |  Oops. "Can we implement it only for

robots, like meta postal code and then a content? If not, please list the situations when webmasters can add markup data only for robots." So structure data should be visible in the search-- in the page itself. It should be equivalent to what you're showing to users. So that's something where I would show it to users. So I don't know why, for example, a postal code would not be visible.  

#### [0:20:30](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=1230) |  But essentially, it should be visible for

users if you want us to pick it up. "If a website, for legal reasons, is not allowed to market its products or a subset of them in the US, and the most common approach is to block US IPs, this will, however, lead to not being indexed on Google for any market, since blocking US IPs means blocking Googlebot. Also, only allowing Googlebot but not human visitors from the US seems risky because of Google's policy of handling bots and users the same way.  

#### [0:21:00](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=1260) |  So how should we handle a situation

like this?" So you're right. It's tricky, because our policy does say, you should handle Googlebot the same way as you would handle other users from that same region. So that's something where, if you're not able to show users in the US that content, you should not show Googlebot that content when it's crawling from the US. That's kind of the baseline policy there.  

#### [0:21:30](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=1290) |  It's obviously kind of-- there are subtle

differences between US-based content and other countries' content. Like, if you want to block all users in Switzerland, and Google crawls from the US, then that's perfectly fine. But if you want to block users in the US, and Google crawls from the US, then that's something where you will see a change with regards to indexing. We don't have any provision for saying, this content is only accessible in individual countries. So that's kind of, I think, a tricky situation there.  

#### [0:22:00](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=1320) |  Our general recommendation here is to make

pages that are accessible by users in the US, which might be kind of simplified pages, which might be more like marketing pages rather than the actual content that you're providing, so that you can allow those pages to be indexed in Google because they're accessible in the US, while the actual content that might not be accessible in the US is hosted somewhere else and appropriately blocked from crawling.  

#### [0:22:30](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=1350) |  I know some people say, well, Googlebot

isn't a normal user. And I'll just cloak to Googlebot. But like you mentioned, that's generally a risky approach, because we would probably see that as cloaking. And that would be a violation of our webmaster guidelines. So that's something I'd recommend not doing like that. "We're migrating our radio brand websites into one aggregator brand website. What helps Google to understand individual radio brands  

#### [0:23:00](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=1380) |  under the aggregator brand without losing news

article snippets in Search and Google Discover traffic after the change when everything is under the same domain? Does Google have any best practices for these situations? We might publish the same news article from multiple brands if it fits the radio brand's audience." So in general, this kind of merging of multiple websites into one website is always tricky. So that's something to keep in mind.  

#### [0:23:30](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=1410) |  When you're merging and splitting web sites,

then that takes a lot longer for us to process. And the outcome is not something that is trivially able to determine what will happen in the end. When you're moving from one domain to another, we can essentially take everything from here and just pass it on there. But if you're merging things, the final version is essentially a different website than the individual versions. So that's kind of a new stage and not something  

#### [0:24:00](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=1440) |  that's easily determinable ahead of time. And

that's something where I would expect to see fluctuations, at least in the mid-term until things settle down. And it might be that the final state is very different than the initial state. It might be that the final state is much better than all of these individual ones. It might also be that the final state is a little bit less than the individual ones. So that's something where there is no real kind of trick  

#### [0:24:30](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=1470) |  to handling this, but really where you

have to take it page by page and migrate everything to that new, bigger website. AUDIENCE: If I can? JOHN MUELLER: Sure. AUDIENCE: Would you-- if they have duplicate content, because they have different sites under that one aggregate, would you just pick out one article to be a canonical? Or how would you do that?  

#### [0:25:00](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=1500) |  JOHN MUELLER: I think that's generally the

best approach. So if you can pick one article and set that as a canonical and make sure that that's the best one that you want to have indexed, then I think that's a good approach. In general, we're able to recognize this kind of duplicate content. We'll try to figure out the canonicalization ourselves. But if the webmaster or the owner has preferences with regards to canonicalization, then I would definitely just let us know about that,  

#### [0:25:30](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=1530) |  so that we can do it more

in the way that you want it done. AUDIENCE: OK, thanks. AUDIENCE: John, may I ask another question? JOHN MUELLER: Sure. AUDIENCE: Considering March 2019's update, if a medical website haven't been updating the most competitive content for the passing one year, would that cause a day-to-day dramatic fall right after the 19 March, 2019 update?  

#### [0:26:00](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=1560) |  JOHN MUELLER: So I don't know, offhand,

what happened in March 2019. So that's-- AUDIENCE: [INAUDIBLE] JOHN MUELLER: I don't remember what all happened back then. But usually, if you haven't been updating content for a while, then that's something where, over time, we will see this content as being less relevant. But it's not that we'll say, oh, it's like, 17 pages haven't been updated. That's too much. We will demote the whole website.  

#### [0:26:30](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=1590) |  That's not the case. AUDIENCE: OK, thank

you very much. JOHN MUELLER: "I have seen that apparently Google has some problems to show the right spelling of meta title and description in Persian language. It shows a Persian alphabet from the end to the start. And it wouldn't be possible for readers to read that, as it's meaningless." I'd love to have some examples. So if you're here, or if you can send me some examples separately or send me some screenshots on Twitter,  

#### [0:27:00](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=1620) |  that would be fantastic. It's hard for

me to judge what exactly you're seeing there. Second question-- he's wondering why Google no longer supports pagination with rel="next" and rel previous. "Previously, I've encountered some problems in terms of defining the first page for Google, as it gets my second page instead of the first one. And what's the ideal implementation that Google wants from webmasters in this regards?  

![](https://i.ytimg.com/vi/H6q-pnFjAHw/maxres2.jpg)



#### [0:27:30](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=1650) |  Is just internal links enough?" So internal

links is definitely what we're looking for. So we don't use the rel="next" and rel previous. One of the things that really helps us with regards to pagination is to have kind of a clear hierarchy in the paginated pages. So instead of linking from page 1 to all of the pages of your set, link from page 1 to page 2, and from page 2 to page 3, and appropriately forwards  

#### [0:28:00](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=1680) |  through the paginated set, because then it's

a lot easier for us to understand, this page is embedded within your website in this particular way, because it's linked from here. And it links back to the previous page and to the next page. And then we can determine this next and previous flow ourselves without anyone needing to define that specifically. So that's the recommendation that I'd have there. I've sometimes seen cases where we show maybe page 3 or page 4 in the search results when someone is searching  

#### [0:28:30](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=1710) |  for something generically. And usually, that comes

back to, well, you're linking to page 4 from the beginning already. So it's hard for us to determine why page 1 would be much more relevant than page 4. So that's something where I'd try to just give us a clear pagination through appropriate links on the page. And usually, we can pick that up. "My question is about thin content. The niche I'm working on is gaming.  

#### [0:29:00](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=1740) |  Recently, I built a tool which lets

a user about any-- which tells users about any game specifications. Last month, I launched this service. And almost 1,500 games were added to the database, meaning 1,500 new pages were created for each game. The Google algorithm found these as thin content, which is true. But from a user's point of view, these are perfectly fine. These are sort of question/answer pages. For example, what are the specifics  

#### [0:29:30](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=1770) |  of the 'Fortnite' game? How do I

tell Google about such content? Other sections on my website use the appropriate length content where needed." So in general, so I'm not quite sure how you are able to see that Google sees these as thin content. We don't have kind of like a thin content tool in Search Console. So my guess is we're just trying to figure out how to rank these pages. And if these are multiple pages that you're  

#### [0:30:00](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=1800) |  creating for individual questions about individual games,

then I could see how our algorithms might look at these pages and say, well, we don't know how important this page is overall. So my recommendation there might be to combine some of this information that you have and create really strong pages rather than to dilute your content across tons and tons of different pages. So that's kind of the direction I would head there. It's not so much that you can tell Google,  

#### [0:30:30](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=1830) |  this question is really important, and you

should index this page that only has maybe two sentences on it. But rather, you need to show Google that this content is actually really important and relevant, because you provide a lot of detail there. So that's something where I would go in that direction more, to combine the self-written content that you have about these individual games together with all of this kind of database-generated content that you have and create really high quality  

#### [0:31:00](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=1860) |  and valuable landing pages for the kind

of content that you want to provide. I didn't take a look at your website itself. So maybe you already have something in that direction. But that's generally the direction I would go. And create fewer pages with more, better quality content, than to have lots of pages with small pieces of content. "I have a few questions about breadcrumb markup. I've noticed that Google will drop the final page  

#### [0:31:30](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=1890) |  from the breadcrumb trail displayed in the

search results. For example, the breadcrumb trail might be domain.com, folder instead of domain, folder, and page. My questions are, does Google drop the final page from a breadcrumb trail if the page title is not included in the breadcrumb list that's visible to the users of the page?" I don't think the page title would have anything to do with that, in a case like that. So that's something where usually it  

#### [0:32:00](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=1920) |  doesn't make sense to-- at least, from

my point of view, it doesn't make a lot of sense to show a breadcrumb for the individual page and the page itself, because that's kind of overlapping. And the second question is, "will an excessive character length cause Google to drop the final page title in the breadcrumb trail from displaying in the search results?" I don't know of any specific character length limit there.  

#### [0:32:30](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=1950) |  But there's only so much room in

the search results. Especially on mobile, there is not a ton of room for really long and combined breadcrumb trails. So that's something where we do have to cut things off at some point and have either the dot, dot, dot in the middle or a shortened breadcrumb in general. So that's something to keep in mind when you're creating these breadcrumbs.  

#### [0:33:00](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=1980) |  "Exactly what user agent do I need

to filter our server logs for to check Googlebot crawling our site?" We have a help center page on the user agents. So I would check that out, especially for the mobile user agent. It looks a lot like a normal mobile phone, but there are a bunch of different user agents that are worth looking at. "Can a self-referential canonical with noindex confuse Googlebot?"  

#### [0:33:30](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=2010) |  So I don't think that would confuse

us. But if it has a noindex on it, then we wouldn't index it. And then the canonical link there doesn't really play a role, anyway. So that's something where I don't see it confusing us. But we just wouldn't index that page, because it has a noindex on it. "If page A is non-indexed and canonicalized to another page, say page B, will Google consider page A  

#### [0:34:00](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=2040) |  as noindex or canonicalized?" If it has

a noindex, it's a noindex page. We wouldn't index that particular page. We would potentially index page B. But that's kind of separate from page A in a case like that. AUDIENCE: And it will not also render the page, right? So does it mean, therefore, if Google is finding noindex, it will not even render the canonical? JOHN MUELLER: That's correct. If we-- so I mean, the canonical is separate.  

#### [0:34:30](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=2070) |  But if a page has a noindex

meta tag on it, then we will not render that page. So if your JavaScript changes the noindex into an indexable page, we would not notice that. AUDIENCE: Correct, yeah. Got it. Got it. Thanks. JOHN MUELLER: "Is there still anything like the noodp robots meta tag?" There is no Open Directory Project anymore, at least as far as I know. So there is nothing really to do in either of those cases.  

#### [0:35:00](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=2100) |  In the past, the noodp tag would

tell us not to use the Open Directory Project. But since that's gone, we couldn't use it if we wanted to use it, so not much we can do there. "I would like to know if it's bad to repeat the anchor text in my internal links. For example, say I have an article called Solar System.  

#### [0:35:30](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=2130) |  Can I link it every time with

the anchor text Solar System? Or by contrary, will Google algorithms think that it's spam?" We generally won't think that's spam. I think that it's normal to have multiple internal links to individual pages within your website. Sometimes you have multiple internal links on the same page. And that's completely normal. The thing where it would kind of get spammy is when essentially all of this text on the page  

#### [0:36:00](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=2160) |  looks a lot like keyword stuffing. So

if, for example, you're repeating this link hundreds of times on that page, and it's always solar system, solar system, solar system, at some point, our algorithms would look at this page and say, this page overall looks pretty low quality, because there's just so much repetition in here. It looks like keyword stuffing. And that might be the case if you're looking at something maybe several hundred times  

#### [0:36:30](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=2190) |  on a page. It's definitely not the

case if you're talking about maybe five or six times, the same link on a page. So those are kind of the two extremes there. I think for the most part, websites don't have a problem with this kind of excessive linking internally, because users, when they look at a page like that, they also have trouble navigating that. If everything is like, solar system, solar system, then users have trouble finding the useful content there.  

#### [0:37:00](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=2220) |  AUDIENCE: So in this case, John, in

this case, how Google creates HTML sitemap, then? JOHN MUELLER: An HTML sitemap-- well, it's a link to a lot of pages. AUDIENCE: Because [INAUDIBLE]. Yes. So should we not have this page then? JOHN MUELLER: It depends. I would make it for users. An HTML sitemap, from my point of view, is something that helps users to find the content that they're looking for. It's not something I would rely on for a search engine. So for search engines, I would really  

#### [0:37:30](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=2250) |  make sure the internal navigation works well,

that you have a clean sitemap file. And usually, you don't need an HTML sitemap file additionally. So just from my point of view-- the cases I've looked at, at least-- is if it's a very large website, and you feel you need to have an HTML sitemap, then probably that's a sign that your normal internal navigation is bad already. And you need to fix that. Whereas if it's a smaller website, then we wouldn't need an HTML sitemap anyway.  

#### [0:38:00](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=2280) |  So oftentimes, the decision about whether or

not to make an HTML sitemap is tied to, am I actually doing the right thing otherwhere on my website. And if you're doing the right thing elsewhere, then you generally don't need an HTML sitemap. AUDIENCE: OK. JOHN MUELLER: "For a website with science content-- Evergreen-- should I add the credits image, even if they're a public domain, and a bibliography?  

#### [0:38:30](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=2310) |  Would this help with E-A-T?" I think,

in general, if you have images that you use that have credits that are associated with that, I would specify that on your pages. It seems like the right thing to do, regardless of the kind of website that you have. So that's something where I think that makes sense in any case. With regards to a bibliography, I think that also makes sense in any case.  

#### [0:39:00](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=2340) |  If you have links to more detailed

information where users can kind of dig in and find out more, then provide that to users. I think that's a good service for users. That shows them that you're serious about your content. And that helps our algorithms to figure out as well that, actually, this website might know what it's talking about. "If I have two websites for different countries, like .com and .no, for Norway, and I add the same content  

#### [0:39:30](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=2370) |  in both websites, but I add a

canonical tag in the second website to show the first website--" and "--the content on my second website will get crawled by Google? Or does it count as duplicate content in a website by Google?" So if it's duplicate content, it's duplicate content. So I think that last part is kind of obvious. The important thing here is that duplicate content on its own is not a bad thing.  

#### [0:40:00](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=2400) |  It's not that we will demote your

website and say, it's terrible because there's some duplicate content on it. It just, for us, means that we understand this is a duplicate. And when someone searches for this content, we'll try to show the most appropriate version to show to that user. So it's not the case that we'd say, this is a bad website because there is duplicate content here. But rather, which one of these pages is the right one to show to users? And we'll try to pick the appropriate one. So with that in mind, that might be  

#### [0:40:30](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=2430) |  that a user in Norway, if they're

searching-- we might say, well, this is the local version of the website. And it looks like they're searching for local content. Maybe we'll show that. It might also be that we look at this and say, well, there is a rel canonical telling us the .com is maybe the appropriate canonical. So maybe we'll show that. And these kind of things are sometimes tricky decisions in the sense that, for canonicalization, we use a lot of different factors. That includes the rel canonical.  

![](https://i.ytimg.com/vi/H6q-pnFjAHw/maxres3.jpg)



#### [0:41:00](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=2460) |  It includes redirects. It includes internal and

external links. All kinds of stuff come together. And the clearer we can recognize which one of your pages should be the canonical, the more we'll tend towards that one and use that one. From a ranking point of view, it doesn't matter. So if you have multiple pages-- they have the same content-- we will pick one of these as canonical and rank it like that. If we shift the canonical to another one-- perhaps you have a redirect or a rel canonical set up-- then the ranking will be pretty much exactly the same,  

#### [0:41:30](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=2490) |  just with a different URL shown. So

it's usually not something that is critical for you to fix in Search, but more like if you have a preference, then let us know about that preference, and we'll try to respect that, and less that there is a magic trick that you need to do to rank higher with this kind of a configuration. "The PageSpeed Insight tool flags AMP URL discovered with the option to reanalyze.  

#### [0:42:00](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=2520) |  In terms of mobile page speed as

a ranking factor, which score is used, that of the standard URL or of the AMP URL?" So for speed in general, we use both lab tests as well as field data. So field data is what users would see in Search when they go to these pages. And if users would see the AMP page, then that's something we would use there. So that's the two sides that are involved there,  

#### [0:42:30](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=2550) |  which can come together. So when you're

testing these pages for speed, my recommendation would be to test both of them. Usually, AMP pages are very fast. But you can also make slow AMP pages. So I would really double check both of these versions. And make sure that what users would see is actually the speed that you'd want them to see it. "Does updating old content is determined  

#### [0:43:00](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=2580) |  as creating new content by Google?" Let's

see. It's hard to understand this question. I think it goes in the direction of, do I need to keep updating all of my old content? I have hundreds of articles. And I don't have time to keep updating everything every day. So we don't have any magic algorithm that looks at your content and says, you need to have this updated every week.  

#### [0:43:30](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=2610) |  But rather, we do look at your

website overall. And if overall, we think your website is maybe not as relevant at some point as it used to be, then we'll treat it as being less relevant overall. So it's not the case that you need to go through and keep updating everything. But if you're actively creating new content, then maybe your website will continue to be relevant over time. So it's not that you have to go through all of your news articles and keep updating them with the newest facts.  

#### [0:44:00](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=2640) |  But really make sure that the overall

picture of your website is what you want to have reflected in Search. "I have a quick question. My question is nowadays why Google Webmaster Tools become so rigorous. And considering most of the structured data warnings as errors, are these important to have on a website, for example breadcrumbs and missing fields? Please advise."  

#### [0:44:30](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=2670) |  So I wouldn't necessarily say that Search

Console or Webmaster Tools is more rigorous than in the past. But structured data does evolve over time. And it can happen that things which are fine at some point with regards to structured data become warnings at some point, maybe even errors at some point. So just because you've implemented structured data once doesn't mean it will always remain valid just  

#### [0:45:00](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=2700) |  in that way. In particular, our Search

features evolve. And some of the Search features rely on structured data. And if the new version of a Search feature needs extra information from a website, for example that you don't have in your current version of the structured data setup, then it might be that we would say, well, in order for us to display your website in that Search feature, you need to provide this information. It's not the case that we would say,  

#### [0:45:30](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=2730) |  your website is bad because it doesn't

provide the structured data the way that would match our requirements at the moment. But rather, if you want to take advantage of this Search feature, this fancy way of presenting your website in Search, then you need to make sure that you're fulfilling the requirements for that. So from a ranking point of view, that's less of an issue. But it's really more that, well, there are fancy new ways to show your website in Search. And if you want to work along with that,  

#### [0:46:00](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=2760) |  then make sure that we can work

with your website for that. And we try to minimize the changes in structured data requirements and warnings and recommendations as much as possible. We actively work together with the product teams to really minimize these kind of changes, because they are disruptive. It is something where if you've implemented it once and then suddenly Google changes what it needs to have for a Search feature, then that's frustrating as a webmaster, because maybe you  

#### [0:46:30](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=2790) |  need to do some extra work to

get that done or at the very least update a plug-in to reflect those new changes. It's always a hassle. So we try to minimize that as much as possible. And we try to have as much of a path forward as possible, where we'll say that maybe something becomes a recommendation. And it will be flagged as a warning for a while. And then after some time, we can say, well, we've been telling you that it would  

#### [0:47:00](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=2820) |  be good to have this setup for

a longer time now. Maybe now is the time for you to actually make that change. But yeah, I think it's not so much Search Console but just generally the whole ecosystem around structured data keeps evolving. And that makes it exciting, because there's always new stuff happening. But it also means there's a lot of work sometimes involved in keeping up. OK, we just have a couple minutes left.  

#### [0:47:30](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=2850) |  So maybe we should just switch over

to last questions from you all. AUDIENCE: Hi, John. JOHN MUELLER: Hi. AUDIENCE: I have a question. And I'm not exactly a technical SEO expert. So I hope I'll be able to express the situation as accurately as possible. We have a multi-regional website. And this means that basically, for every page that we create, we have like eight different regional versions. Now, on top of these regional versions, we also have a global version of each page.  

#### [0:48:00](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=2880) |  And from what I understand, this is

to make sure that we are distributing authority evenly throughout the website and not just to one particular region. Is this best practice? Or are we shooting ourselves in the foot with the global pages? JOHN MUELLER: I think that can work well. So what I would try to do in a setup like that is to make sure that the regional versions have  

#### [0:48:30](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=2910) |  a strong reason for existing. So instead

of just taking the same content and saying, well, this is a version for Australia, New Zealand, and the UK, really make it clear that this is a localized version of the content, which in some cases might be that you just have the local addresses and phone numbers on there. But at least really clearly make sure that it's easy for us to recognize when this page is relevant and when we should show that in Search. You can also use the hreflang tags between the pages  

#### [0:49:00](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=2940) |  to tell us what the connection is

between those pages. But in general, that's a very common setup. So I wouldn't necessarily see that as something that you'd want to avoid. AUDIENCE: OK, awesome. Thank you. JOHN MUELLER: Sure. AUDIENCE: Hi, John. JOHN MUELLER: Hi. AUDIENCE: Quick question for you-- I'm using Dialogflow and working on FAQ pages with markup schema properly. But when I plug it into Dialogflow,  

#### [0:49:30](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=2970) |  they have a beta for knowledge. It

doesn't read the markup schema properly. So it wants it to be in plain text. Am I doing it wrong? JOHN MUELLER: I don't know. I haven't tried anything with Dialogflow. So I would check with them. I think that's handled by Firebase, right? AUDIENCE: Mm-hmm, correct. JOHN MUELLER: I would check with the Firebase support folks on that. AUDIENCE: OK, yeah, it seems like counteracting answers.  

#### [0:50:00](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=3000) |  You want it schema, but then you

don't. JOHN MUELLER: Yeah, I think, for the most part, these are probably different use cases, where we want it in schema for Search. But maybe Dialogflow needs to process it differently when it tries to understand the pages. AUDIENCE: Perfect, thank you. JOHN MUELLER: Sure. AUDIENCE: Hi, John. Last question from my site, if you allow. JOHN MUELLER: Sure. AUDIENCE: OK, yeah. So, John, recently I had two pages, two separate pages  

#### [0:50:30](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=3030) |  for one entity. Some was like blog

page. And some was main course page. Blog page was ranking for main course page. And featured snippet was also appearing from blog page. So I just took that particular paragraph from blog page, pasted it in my course page, redirected blog page to course page, right? But what I saw is that now featured snippet is gone. The same content is appearing in other page.  

#### [0:51:00](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=3060) |  But featured snippet is gone, right? In

this case, how to analyze this? Was it really content or other third factors which were playing the role, because we are using the same content? Yeah, please. JOHN MUELLER: Yeah, I don't know. It's hard to say. So the featured snippet is something that is an algorithmic organic search element, from our point of view. And it uses a lot of different signals to understand when to show something  

#### [0:51:30](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=3090) |  as a featured snippet like that. It

might be that if you just take this piece of text and put it on another page, and the page essentially has a lot of other content on it, that we might think, well, maybe this piece of text is not a relevant representation of that page itself. So just taking a piece of text and copying it somewhere else and hoping that that new page will rank in the same way-- I don't think that generally works.  

#### [0:52:00](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=3120) |  And for featured snippets, it probably in

most cases doesn't work that well either. AUDIENCE: And all the page signals are passed with redirection? JOHN MUELLER: Essentially, with a redirect, you're telling us that the new page replaces the old one. AUDIENCE: Yeah. JOHN MUELLER: So the signals that we have, we can pass. That doesn't mean it'll rank the same way, because if the content is different, and you're just redirecting to that different content-- if the layout is different, if the navigation is  

#### [0:52:30](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=3150) |  different-- all of those things can make

it differently relevant for individual queries. AUDIENCE: Yeah, yeah, but it was a very similar page, not a big change. JOHN MUELLER: Yeah. AUDIENCE: I don't know why do we have what happened. JOHN MUELLER: Yeah. AUDIENCE: OK. JOHN MUELLER: I would try things out and see what works well. AUDIENCE: Yeah, yeah. JOHN MUELLER: Especially if you're looking at individual pages, then maybe that's something where you can experiment a little bit and see what works well. AUDIENCE: Yeah, yeah, we are doing. Thanks very much. Yeah, yeah, cool. Thanks. JOHN MUELLER: Cool.  

#### [0:53:00](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=3180) |  All right, maybe one last question from

anyone. AUDIENCE: Hi, John. Could I ask a quick question please? JOHN MUELLER: Sure. AUDIENCE: You talked before about noindex. And obviously, noindex on a meta tag at the top of the page should stop Google from indexing a page. But we're seeing some kind of strange behavior, where we have certain pages that are marked noindex. But we're still seeing them in Search Console showing up as indexed. And we're actually seeing, it says, index bot excluded by robots. And they're now-- I can send you some links if you want to. But it seems like it's the old scenario where a page might  

#### [0:53:30](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=3210) |  have used to have been indexed. Then

it was blocked by robots. Then the noindex was removed. And of course, Google then would never have crawled it to know that the noindex was removed. But it's not that. These are pages that have always been noindexed. And when you go in Inspection Tool, it says that they are marked to be indexed. And there's no kind of typos or code issues or anything on the page. They all validate fine and everything. It's just some very strange behavior. I'm not sure if you're aware of it, or if there's any situations where noindex would be indexed by Google. It's just that it's-- JOHN MUELLER: No. AUDIENCE: --to do with faster navigation. So we don't really want to be seeing duplicate content  

#### [0:54:00](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=3240) |  type of stuff appearing there. JOHN MUELLER:

Yeah, I don't know. So if it has a noindex, and we recognize a noindex, we should treat it as a noindex. AUDIENCE: Yeah. JOHN MUELLER: So we don't use it as a signal, where we'd say, well, maybe we'll index it anyway. So it's pretty clear a sign. But I am happy to take a look if you can send me some examples. AUDIENCE: Yeah, that's how I understood noindex. But I just wasn't sure. I was thinking I'm going a bit crazy. But I'll pop you an email, and I'll stick it in there. JOHN MUELLER: Sure. AUDIENCE: Appreciate it. Thanks very much. Cheers.  

#### [0:54:30](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=3270) |  JOHN MUELLER: Sounds good. Cool. All right,

so let's take a break here. If you have more questions, feel free to drop them in for the Friday Office Hours Hangout. And maybe we'll get to them there. Or if you want, of course, you're always welcome to jump into the Webmaster Help Forum, where there are lots of experts that are able to help out with a lot of these more common situations. All right, so with that, let's take a break here. And hope to see you all in one of the future Hangouts.  

#### [0:55:00](https://www.youtube.com/watch?v=H6q-pnFjAHw&t=3300) |  Bye, everyone. AUDIENCE: Thank you. Bye. AUDIENCE:

Thanks, John.  