[![English Google Webmaster Central office-hours from March 31, 2020](https://i.ytimg.com/vi/L9GN4VX6xww/maxresdefault.jpg)](https://www.youtube.com/watch?v=L9GN4VX6xww)

## English Google Webmaster Central office-hours from March 31, 2020

This is a recording of the Google Webmaster Central office-hours hangout from March 31, 2020. These sessions are open to anything webmaster related like crawling, indexing, mobile sites, internationalization, duplicate content, Sitemaps, Search Console, pagination, duplicate content, multi-lingual/multi-regional sites, etc. 



Watch out for new sessions, and add your questions at https://www.youtube.com/user/GoogleWebmasterHelp/community



Feel free to join us - we welcome webmasters of all levels!



#### [0:00:00](https://www.youtube.com/watch?v=L9GN4VX6xww&t=0) |  JOHN MUELLER: All right, welcome, everyone, to

today's Webmaster Central office-hour Hangouts from home. My name is John Mueller. I'm a webmaster trends analyst at Google in Switzerland. And part of what we do are these office-hour hangouts where folks can join in and ask any question around their website and web search. And we try to come up with an answer for you. A bunch of stuff was already submitted on YouTube. So we can go through some of that.  

#### [0:00:30](https://www.youtube.com/watch?v=L9GN4VX6xww&t=30) |  But we can also go through some

urgent questions for people who are joining here live if anyone has anything I mean, if not, I will just jump into the questions from YouTube. And you can stop me at any time along the way. And-- BARRY: I could always ask a question. JOHN MUELLER: All right, go for it, Barry. BARRY: So I've been obviously tracking how you guys are manually changing the search  

#### [0:01:00](https://www.youtube.com/watch?v=L9GN4VX6xww&t=60) |  result constantly. No, I'm joking. But the

algorithm seems to be-- is it possible that the tools that are tracking the changes to the Google search algorithm rankings, like the 10 listings and so forth, that there's so much change because of how maybe searcher behaviors changing that Google's algorithms are adapting to it, meaning-- I mean, if you look at these tool, like the past couple of weeks it literally feels like there's a Google algorithm update every day in terms of how much fluctuations there  

#### [0:01:30](https://www.youtube.com/watch?v=L9GN4VX6xww&t=90) |  are in the tools that are tracking

it and the web master saying my rankings are changing. So is it possible that search or behavior is influencing the algorithm itself? JOHN MUELLER: I don't know. It's hard-- so I haven't been watching what's happening with these tools. So that's probably something that you see more. But in general, we do try to adapt our algorithms to provide the information that's relevant for users  

#### [0:02:00](https://www.youtube.com/watch?v=L9GN4VX6xww&t=120) |  at the time when they need it.

So that could be something where things are evolving to make sure that people have the right information at the right time. But I imagine that's more specific to certain kinds of searches. I don't think it's like we would just change all of the search results around. So if you're looking for a manual for washing machines, why would you change the search results for that?  

#### [0:02:30](https://www.youtube.com/watch?v=L9GN4VX6xww&t=150) |  Things are essentially still all the same.

But I do know that there are various teams working at Google on improving the search results and particularly around the whole crisis situation where people have higher expectations from search. And they want something that they can trust. And that's probably something where we're trying to provide-- I don't know-- better quality of service or a good quality of service at least for those that are looking for this critical information.  

#### [0:03:00](https://www.youtube.com/watch?v=L9GN4VX6xww&t=180) |  BARRY: So you wouldn't think it's specific

to anything? Like if it's not COVID related searches, you don't think maybe the way people are searching less for, or more for buying toilet paper versus less for going to the movies, that would influence how the algorithm, maybe adjusts? Does that make sense, that question? Like searchers, search trends influencing the Google algorithm and the rankings around that? JOHN MUELLER: Yeah, I don't think that would be happening.  

#### [0:03:30](https://www.youtube.com/watch?v=L9GN4VX6xww&t=210) |  I mean, it's something where we always

see user behavior shift. And sometimes certain topics become really popular. And we try to show the right search results for those kind of things. And this happens all the time. This is one of those things where it probably is a little bit bigger, and it's lasting longer than the Oscars when they come and go. But these kind of shifts are things that are algorithms have to watch out for anyway. So it's not something that I'd say  

#### [0:04:00](https://www.youtube.com/watch?v=L9GN4VX6xww&t=240) |  would be specific to this current situation.

BARRY: Thank you. JOHN MUELLER: Sure. AYMANE SENNOUSSI: I just have a question, John. JOHN MUELLER: OK. AYMANE SENNOUSSI: So today I found out that there is a website that is scrapping the hell out of my content. And I found out that it's ranking very close to my website on Google Search results. This also happens when I look for some technical solutions for my software problems. And I find some Stack Overflow links.  

#### [0:04:30](https://www.youtube.com/watch?v=L9GN4VX6xww&t=270) |  And then it doesn't satisfy my need.

I scroll down a little bit. And I find exactly the same question with the same content. Does Google make any efforts to ban or penalize these scrappers? Or how does it work if I wanted to report this website that is stealing my content? JOHN MUELLER: Well, I think, first of all, if it's your content, and if it's copyrighted content, then maybe the DMCA process is the right approach.  

#### [0:05:00](https://www.youtube.com/watch?v=L9GN4VX6xww&t=300) |  That's something where you need to double

check things from a legal point of view. So I can't give you legal advice. So I can't tell you like you should do this, or you should not do that. AYMANE SENNOUSSI: Well, actually, my website is about legal advice. So I can handle that. JOHN MUELLER: OK, perfect. Yeah, so maybe that would be a process that would work there. That's generally the most direct way to resolve this kind of thing where if the content is taken down, then that's resolved in search.  

#### [0:05:30](https://www.youtube.com/watch?v=L9GN4VX6xww&t=330) |  So that just automatically works out. Otherwise

, the web spam reports are something that you can do. In general, we do look at the web [INAUDIBLE] reports that come in. But we don't take manual action on every single one of them because we try to use them to improve our algorithms overall. So that's one thing where it's useful to get feedback like that. But I wouldn't see it as something where within a couple of days, you will suddenly see that website disappear from search.  

#### [0:06:00](https://www.youtube.com/watch?v=L9GN4VX6xww&t=360) |  So those are generally the main approaches

there. Sometimes it's also tricky in that if we don't have a lot of other good content for that specific query, then we end up showing these kind of things. So oftentimes, if you search for a quote, then someone else will have copied that. And we'll show that in the search. But that's because you are searching for that one specific piece of text. And it's like we have that page index.  

#### [0:06:30](https://www.youtube.com/watch?v=L9GN4VX6xww&t=390) |  Maybe we don't rank it first for

that piece of content. But it's known to us. So we would show it in the search results if you're explicitly looking for that. So that's something where sometimes the perception is also a little bit skewed in that if it's your content, you explicitly search for it. And you see some spammer also ranking. And you're like, that shouldn't be happening. But at the same time, maybe there is nothing else that we would show there. And we happen to know about this page. So at some point, we'll just show it.  

#### [0:07:00](https://www.youtube.com/watch?v=L9GN4VX6xww&t=420) |  AYMANE SENNOUSSI: Yeah, gotcha. Thank you. JOHN

MUELLER: And I think another thing to also keep in mind is that sometimes people have more information to individual pieces of content. So we see that all the time with our blog posts where someone like Barry or someone else will take it and quote parts of the blog posts and add some more information or open things up for comments from other people. And that's, from our point of view, that's a normal part of the web.  

#### [0:07:30](https://www.youtube.com/watch?v=L9GN4VX6xww&t=450) |  Technically speaking, you could look at that

and say, oh, they're copying the content. But actually, they're providing something different. It's a slightly different version of the content. It's maybe a commentary on that piece of content. Maybe it's just other people's comments that are also around that piece of content. And that's something where we would say it's not even about who wrote that first, which one of these should we rank higher. It's a separate piece of content overall  

#### [0:08:00](https://www.youtube.com/watch?v=L9GN4VX6xww&t=480) |  that happens to have quotes that are

the same. But essentially, it's a unique piece of content. AYMANE SENNOUSSI: Thank you. Thank you for the clarification. JOHN MUELLER: Sure. REHAAN: John, could I jump in with a question? JOHN MUELLER: Sure. REHAAN: So in another hangout, you mentioned that the publisher of organization schema doesn't need to be on every single page of the website. If it's on the home page or the contact page, that's good enough. Now, what about if we open an article or a post schema  

#### [0:08:30](https://www.youtube.com/watch?v=L9GN4VX6xww&t=510) |  that's on an article? Does it need

to be on every single paginated page of that article? Or can it just be on the first page of that article? JOHN MUELLER: What are you trying to achieve with the article markup there? I think that's kind of what I would look at there. If there is something that you're trying to achieve with that article markup that's relevant to the whole set of those pages, then put it on all of those pages. If it's something that's just the intro of the article  

#### [0:09:00](https://www.youtube.com/watch?v=L9GN4VX6xww&t=540) |  is relevant enough for that extra piece

of markup, then maybe it's enough to just have it on the first page. REHAAN: That makes sense. Thank you. - Hi, Mr. Mueller. JOHN MUELLER: Hi. VAHAN: Can I ask you a question? JOHN MUELLER: Sure, sure. VAHAN: I'm Vahan, Lead Developer at Search Engine German. So I'm looking at Google Discover specifications. And the rate how to enable the website to use a [INAUDIBLE]  

#### [0:09:30](https://www.youtube.com/watch?v=L9GN4VX6xww&t=570) |  in the discover. And it says one

should use high quality images at least 1,200 pixels wide. I'm sure that Google has a right to display your high quality images to users either by using and/or by filling out the form expressing your interest to opt in program.  

#### [0:10:00](https://www.youtube.com/watch?v=L9GN4VX6xww&t=600) |  So my question is, is it possible

to have large images in the discover still without AMP? JOHN MUELLER: Yes, yes. So I think they want to move away from that form. And another option that you can do-- I don't know if we documented it there or in the other documentation-- is to use the max image preview robots meta tag where you can specify,  

#### [0:10:30](https://www.youtube.com/watch?v=L9GN4VX6xww&t=630) |  I think, large as the large preview

image. That would also apply to Discover. VAHAN: OK, thank you very much because I did notice that CNN web sites sometimes has a large image but doesn't have an end. And I wondered it. [INAUDIBLE] robot image-- could you please repeat? JOHN MUELLER: Let me see. Max image preview I think it's called. Yeah, max image preview.  

#### [0:11:00](https://www.youtube.com/watch?v=L9GN4VX6xww&t=660) |  VAHAN: Method [INAUDIBLE]. OK, thank you very

much. JOHN MUELLER: Sure, yeah. VAHAN: Appreciate it. JOHN MUELLER: OK, let me run through some of the submitted questions. And we can get back to more questions from you all towards the end. And of course, if you have any comments to individual questions or answers, feel free to jump on in. A question for an e-commerce website. From March 21st, we saw that Google removed the indexing  

#### [0:11:30](https://www.youtube.com/watch?v=L9GN4VX6xww&t=690) |  of most of our categories. Suddenly all

of our categories are marked in Search Console as duplicate to unique category. And Google is picking up another canonical or declaring not available. When rendering the pages in search console, I can see that sometimes that none of the images are rendered and sometimes they are. I need to precise that we implement a JavaScript to load the product listing in the category. Do you think that could be the reason? Even if Google is rendering different product names  

#### [0:12:00](https://www.youtube.com/watch?v=L9GN4VX6xww&t=720) |  with different lengths, possibly for Google this

is the same page. It's really hard to say without looking at specific pages. But offhand that sounds like something that would be more of a technical issue with regards to those pages in particular, if you're saying this is a specific type of page on your website. If there is no other reason for things to be dropped from search, then my hunch  

#### [0:12:30](https://www.youtube.com/watch?v=L9GN4VX6xww&t=750) |  is that for one reason or another,

we're seeing the same content for these pages. And if we're seeing the same content, that can either be because on your server, you're doing something unique for Google [INAUDIBLE],, or maybe you're serving a page that shows a server error, or maybe you're showing a page that says it looks like you're a robot. Can you fill out this CAPCHA? It could also be that it's something where you're providing the content in JavaScript in a way that we can't process properly.  

#### [0:13:00](https://www.youtube.com/watch?v=L9GN4VX6xww&t=780) |  So those are the options that would

fall into this situation. And usually, these are things that you can double check with the testing tools where you can work out is this a technical issue in my infrastructure? Or is it something with my JavaScript implementation that I have? And then you can work to fix that. What I would do here is maybe post in the Webmaster Help forum with the specific.  

![](https://i.ytimg.com/vi/L9GN4VX6xww/maxres1.jpg)



#### [0:13:30](https://www.youtube.com/watch?v=L9GN4VX6xww&t=810) |  So some sample urls that you're seeing

this with. Ultimately, if you feel it's really tied to the JavaScript side, we have a JavaScript working group, which is a closed forum that you can just join in. And you can ask questions there as well. So those are probably the two directions I would take there. Can you give us more details about how image indexing and ranking works? We know many things about HTLM, URLs, indexing, and ranking.  

#### [0:14:00](https://www.youtube.com/watch?v=L9GN4VX6xww&t=840) |  But when it comes to images, few

things are really known. For example, how does Google decide to rank an image instead of another? Are backlinks important for an image? Does Google use Cloud Vision technology to rank and index images? How important is a text surrounding images? So many things. OK, I feel this is almost a topic that would deserve a completely separate hang out. So I don't know how much detail I can go into here.  

#### [0:14:30](https://www.youtube.com/watch?v=L9GN4VX6xww&t=870) |  But we do have a fairly comprehensive

help center article on best practices for Google images, which includes a lot of the things that you're asking about here. In general, what I would assume with images is that Google bot doesn't see the contents of the image and instead needs to understand the context of how it's used from your web page. So essentially, we look at the HTML page. We see there's some images embedded there.  

#### [0:15:00](https://www.youtube.com/watch?v=L9GN4VX6xww&t=900) |  There's text on the HTML page. There's

text around the images. There's an ALT attribute associated with the image. All of this is on the web page. But it's about the image. And for us, the combination of the image plus the web page is essentially what we need to use for ranking. So if someone is searching for, I don't know, a beach vacation, then we're not going to look at all images to see where there might be beach on that image. But rather, we'll try to find matching web pages that  

#### [0:15:30](https://www.youtube.com/watch?v=L9GN4VX6xww&t=930) |  have unique and compelling images that we

can show that apply to this situation, this query that someone is looking for. So that's the thing that I would watch out for is really-- like we primarily use a web page to understand the image. And we always need the combination of a web page and the image file when it comes to ranking.  

#### [0:16:00](https://www.youtube.com/watch?v=L9GN4VX6xww&t=960) |  Can general mistakes such as missing a

space between two words, showing 20 products, but heading is showing 10 products, or placing a hyphen incorrectly in schema, hiding tags, et cetera affect SEO? So I guess it depends on where you make those typos. When you're talking about structured data, in particular, since you mentioned schema, that's something where if the structure data is wrong with a typo, for example, then we  

#### [0:16:30](https://www.youtube.com/watch?v=L9GN4VX6xww&t=990) |  might not be able to process that

at all because structure data is something that we process automatically. We need to be able to process that one to one as it comes in. And if there are errors in that structure data in a way that we can't parse it, then we're not going to try to interpret it. However, when it comes to content, if there are typos in your content, if you have extra dashes or periods or spaces or things like that within your content,  

#### [0:17:00](https://www.youtube.com/watch?v=L9GN4VX6xww&t=1020) |  usually that's less of an issue. That's

something that happens on pages. We understand that. And I think the only case where these typos would be problematic is if with those typos, for example, you're making it impossible for us to understand what the primary content is on a page. So for example, if you have a specific product name on your website, and it's mentioned on one page one time,  

#### [0:17:30](https://www.youtube.com/watch?v=L9GN4VX6xww&t=1050) |  and at one time it's mentioned completely

wrong maybe with like missing spaces around the product name that you're describing, then it'll be really hard for us to understand that this is a unique product name that's actually shown in an incorrect way on a page if we can't extract that out as a word, for example. However, if you have this product name multiple times on a page like you normally would do,  

#### [0:18:00](https://www.youtube.com/watch?v=L9GN4VX6xww&t=1080) |  and one of them has a typo,

then that doesn't change anything for us. We can understand that this page is about that product. So that said, it's like [MUTED] That said, so normally things essentially just work out with regards to typos. It's not something where you need to have a 100% perfect page. I don't think any web page is completely perfect anyway.  

#### [0:18:30](https://www.youtube.com/watch?v=L9GN4VX6xww&t=1110) |  So it's usually not a matter of

something where you need to panic if you recognize typos on your pages. Page A is canonicalized to page B. And page B is canonicalized to page C. How does Google treat this? So first of all, I think what you need to figure out in a case like this is what you actually want to have happen. So do you want page A index?  

#### [0:19:00](https://www.youtube.com/watch?v=L9GN4VX6xww&t=1140) |  Do you want it indexed as page

B? Or do you want it indexed as page C? And as soon as you work out what you want to have happen, then you should make it as clear as possible to Google what you want to have happen. So if you're working with the rel canonical link attributes for example, then make sure that you're consistent, but you always point out the version that you do want to have indexed. And then we'll try to follow that. On the other hand, if you're using a rel canonical in inconsistent ways, if your internal linking is inconsistent, your site might file mention things  

#### [0:19:30](https://www.youtube.com/watch?v=L9GN4VX6xww&t=1170) |  in different ways too, then we're going

to have to make a guess. And it's not that you can determine ahead of time what will Google guess. But rather, it might be we guess this way. It might be we guess it a different way later on. It might be that it changes over time as well. So with canonicalization, it's really-- like if you want something to happen, make it really clear to us. The other thing with canonicalization that people forget, I think, every now and then is  

#### [0:20:00](https://www.youtube.com/watch?v=L9GN4VX6xww&t=1200) |  that canonicalization is for us, essentially, a

way of picking a URL to show in search. It's usually not a matter of things ranking in different ways. So if we pick one URL to show in search and canonical, or we pick a different URL, if the content is exactly the same, we would rank it exactly the same. So that decision around canonicalization wouldn't cause your site to jump up or jump down on search.  

#### [0:20:30](https://www.youtube.com/watch?v=L9GN4VX6xww&t=1230) |  It's just well, this URL or that

URL. In the end of February, I bought an expired domain. Afterwards, I set up all things fresh and verified with search console. Then I realized their crawl anomaly and software [INAUDIBLE]. I tried to fix them with the 301s or 410s. But it's still showing errors in Search Console. How can I get that resolved? So in general, if you have a domain that  

#### [0:21:00](https://www.youtube.com/watch?v=L9GN4VX6xww&t=1260) |  was used previously, then we probably have

a bunch of URLs that we know about from a domain. And we'll try to recall them over time. And if we notice that they don't work because the return a 404 or if they return, redirect somewhere else, then we might flag that as a 404 or as a soft 404 in Search Console. And that's perfectly fine. I mean, these URLs are no longer valid on your website.  

#### [0:21:30](https://www.youtube.com/watch?v=L9GN4VX6xww&t=1290) |  So Google sees errors. And we show

them to you. And then you can look at those errors, and say yeah, that's on purpose. I removed all of these URLs. Or I didn't reinstate all of these URLs. And that's perfectly fine. So it's not something that you need to suppress or hide or anything like that from Google. The other thing maybe worth mentioning is that if you're using an expired domain, just because there used to be a website there,  

#### [0:22:00](https://www.youtube.com/watch?v=L9GN4VX6xww&t=1320) |  it doesn't mean that you have any

kind of advantage of using an expired domain. So if the expired domain name is really what you want it as a domain name, then that sounds like a good thing. On the other hand, if you're just picking up that expired domain name in the hope of artificially being featured high in search because that previous website was actually pretty good, then that's not something that I would expect to happen. I want to remove an image in Google search.  

#### [0:22:30](https://www.youtube.com/watch?v=L9GN4VX6xww&t=1350) |  I used a Google outdated content removal

tool. I submitted a request. But the status showed remove content Google. When I visit the image, it's not removed. So it's really hard to understand exactly what you're trying there. I would strongly recommend posting in the Webmaster help forum maybe with a screenshot so that someone can take a look and see what is happening specifically with those pages  

#### [0:23:00](https://www.youtube.com/watch?v=L9GN4VX6xww&t=1380) |  that you're mentioning. One thing to keep

in mind is the outdated content tool I believe just updates the content that we have indexed in search. And if you're using that for images that would be the wrong thing to use there. You'd need to remove that page from search essentially. The other thing to keep in mind is that Google doesn't remove the images on the server. But rather, we can remove them from the search results. So if you're searching for something  

#### [0:23:30](https://www.youtube.com/watch?v=L9GN4VX6xww&t=1410) |  and that image is there, then that's

something you could potentially remove depending on the situation. On the other hand, if you take that URL where the image is hosted and you try it out in your browser, it might still be that it still works because that's not something that we can control. So those are some things to keep in mind. The other thing maybe also worth mentioning is that in particular with images, sometimes the same image is used on multiple pages.  

#### [0:24:00](https://www.youtube.com/watch?v=L9GN4VX6xww&t=1440) |  And if you remove the image once,

it might be that the same image from a different location pops up into the search results afterwards. And essentially, you just need to watch out for that and then also have that other location removed as well. In the view of the recent no-follow changes, what is now the best practice in terms of links to a PDF version of the same page? Previously, we would just add no-follow  

#### [0:24:30](https://www.youtube.com/watch?v=L9GN4VX6xww&t=1470) |  so that the original HTML would appear

in the index. But now PDFs are sitting ducks for indexation. We can't, I guess, add a no-index instruction to the PDF. And we don't want any perceived duplicate content issues. So what can you do? So first of all, you can do a no-index for images. That's essentially the x-robots tag. That's an HTTP header that you can add to the PDF files.  

#### [0:25:00](https://www.youtube.com/watch?v=L9GN4VX6xww&t=1500) |  Well, not to the files, but to

what the server returns for those files. And with the x-robot's tag header, you can use any of the robot's meta tags. And I believe even in an robots.txt documentation, we have examples of specifically how to block PDFs from being indexed for probably both Apache and f So I would double check that. The other thing with regards to no-follow,  

#### [0:25:30](https://www.youtube.com/watch?v=L9GN4VX6xww&t=1530) |  my guess is that this will continue

to work essentially the same way internally within a website in that we just won't treat that link as being as important overall. However, like before, just because you have a no-follow link to that PDF, it doesn't mean that we will never see that PDF. Other people might have other links to that PDF. We might see links from other places in certain periods of time where we see the normal link  

#### [0:26:00](https://www.youtube.com/watch?v=L9GN4VX6xww&t=1560) |  to the PDF file. And we'll go

off and index it. So even previously just having a no-follow link to a page does not mean that that page will never get indexed. My blog is just three months old. And my posts would sometimes keep appearing on the first page and then suddenly disappear after one or two days. Why does this happen? It's really hard to say. But my guess is with a site that new, it's  

#### [0:26:30](https://www.youtube.com/watch?v=L9GN4VX6xww&t=1590) |  just a matter of our systems not

being 100% sure how they should treat the new content that you're providing there. Over time, as we understand the website better, we're a little bit better at understanding how new content on this website fits in with the context of the rest of the web. And we can work out which of these things we should be indexing faster or slower or showing differently in search. But especially if it's a really new website, then sometimes we have to guess.  

#### [0:27:00](https://www.youtube.com/watch?v=L9GN4VX6xww&t=1620) |  And then our algorithms might say, oh,

we'll index this quickly. It looks like something good. And then afterwards, we might be like well, maybe we didn't need to do that. And that's usually something that settles down after maybe a half a year or a year or so. In terms of headings, best practice, and particular headings that currently include internal links, is there a benefit to moving these from the H2's to the body of the text?  

![](https://i.ytimg.com/vi/L9GN4VX6xww/maxres2.jpg)



#### [0:27:30](https://www.youtube.com/watch?v=L9GN4VX6xww&t=1650) |  So I think there is an example

here. I took a quick look. And some of the H2 headings are links to other pieces of content. Some of them are just headings. From my point of view, that's totally up to you. I don't know if there are usability issues that you might need to watch out for with regards to headings that are also links. But in general from Google's point of view, these things don't really matter that much. It's something-- we do use headings to better understand  

#### [0:28:00](https://www.youtube.com/watch?v=L9GN4VX6xww&t=1680) |  the context on a page. But when

you're talking about those links from one page to another page, I don't think that link being in a heading would play any visible role at all with regards to search. We had a situation where one of our keyword website is ranking at position two while against the same keyword, it's on position six for desktop result. Why is that?  

#### [0:28:30](https://www.youtube.com/watch?v=L9GN4VX6xww&t=1710) |  That can happen. So on the one

hand, it's possible for rankings to change fairly quickly. It's also possible for things to be an experiment, essentially, where different people, when they try it out, they might see slightly different results. That's completely normal from our point of view. It's also possible that there are different rankings from mobile and from the desktop search results. That's something that, from our point of view, also makes sense. So in particular, if we recognize that a page is not  

#### [0:29:00](https://www.youtube.com/watch?v=L9GN4VX6xww&t=1740) |  mobile friendly in that when users go

to it, they can't really use it on their mobile device, then that's something well, maybe on mobile search results we would show a little bit lower. So these are the kind of things where sometimes the mobile and the desktop search results are just slightly different. Can excessive div tags in anchor text reduce rendering performance? I have no idea how that would work out.  

#### [0:29:30](https://www.youtube.com/watch?v=L9GN4VX6xww&t=1770) |  Essentially with regards to rendering performance, we

use something that's very similar to normal Chrome. So if you use a normal performance testing tools in Chrome that you have available, the Lighthouse tests, the different other testing tools that essentially build on the Chrome stack, and you see that you can improve the rendering performance of your pages, then that's always a good thing. It's good for users.  

#### [0:30:00](https://www.youtube.com/watch?v=L9GN4VX6xww&t=1800) |  And if Google bot can render pages

a little bit better, then that's also good for our servers as well. But whether or not just having excessive div tags on a page would cause a significant [INAUDIBLE] in rendering performance, I kind of doubt that. But I'm sure you could create a test page that does cause this issue. On our e-commerce and href and menu filters,  

#### [0:30:30](https://www.youtube.com/watch?v=L9GN4VX6xww&t=1830) |  and the same href is used somewhere

in the middle of the primary content, is there any difference? I don't quite understand the question. But I think it's like if you have the same link on the page in multiple places. Is that a good thing or a bad thing? From our point of view, that's perfectly fine. There is nothing special like you need to do. If you have the same link on the page multiple times,  

#### [0:31:00](https://www.youtube.com/watch?v=L9GN4VX6xww&t=1860) |  that's a common scenario that happens with

a lot of sites. So that's not something I would see as something that you'd need to artificially suppress or change. Some infos about the consequences of COVID-19 in search results. How does Google react when such a word appear [INAUDIBLE] what's the impact on search results? I think Barry talked about this in the beginning.  

#### [0:31:30](https://www.youtube.com/watch?v=L9GN4VX6xww&t=1890) |  Essentially, these kind of situations-- I mean,

this is certainly a unique situation. But these kind of changes happen all the time. I believe-- what is it-- maybe a couple of years ago, we mentioned, again, that something like 50% of all searches every day are completely new. And these kind of things happen all the time. Suddenly something completely new comes up and people search for it. And we need to figure out what they're searching for,  

#### [0:32:00](https://www.youtube.com/watch?v=L9GN4VX6xww&t=1920) |  what does that actually mean, and which

pages will be relevant to show there. And we need to do that in an automated way in the sense that we can't manually double check every search results page that we ever show to people because they're just so many different variations. And like I mentioned, like so many new kinds of searches every day. So this is something where our algorithms-- from what I've seen, from just from personally browsing around, it feel like our algorithms  

#### [0:32:30](https://www.youtube.com/watch?v=L9GN4VX6xww&t=1950) |  are able to deal with this fairly

well. And I think that's also a testament to all of the work that the engineers and the ranking teams have been doing over the years to make sure that whenever something completely new comes up, we're able to deal with that appropriately. I have an 8-month-old website that ranks for keywords city plus SEO position 19 in the non-US search results or locations. But when I check my ranking, US, it  

#### [0:33:00](https://www.youtube.com/watch?v=L9GN4VX6xww&t=1980) |  seems I'm ranking very [INAUDIBLE].. Last month,

we temporally reached the first page of Google. And we started slowly losing rankings again. Yeah, I don't know exactly what to say here. But essentially, we do have different [INAUDIBLE] in the sense that if we can tell that someone is trying to find something local, and we can tell that a specific web  

#### [0:33:30](https://www.youtube.com/watch?v=L9GN4VX6xww&t=2010) |  page is matching their intent in a

reasonable way, then we'll flag that in the search results and rank that appropriately. So if you're looking for [INAUDIBLE] from one country, or one keyword in one country and you're looking for the same keyword in a different country, it's usually pretty normal that we would show different results for those kind of things, especially if you're asking about something that's more locally related.  

#### [0:34:00](https://www.youtube.com/watch?v=L9GN4VX6xww&t=2040) |  So if you're looking for, I don't

know, washing machine manual, then probably we don't need to use geo targeting that much to figure out which of these pages we should show. But if you're searching for a washing machine repairman, that's probably something where it makes sense to use geo targeting to figure out this user located, which of the web pages that we have would be best suited for this user at this time. So that kind of locally search results  

#### [0:34:30](https://www.youtube.com/watch?v=L9GN4VX6xww&t=2070) |  and different rankings, that's pretty [INAUDIBLE] depending

on the kind of query. We're a hosting provider. And some of our customers are hosted on subdomains of our domain. Some of these domains are 301 redirected to our own domain, some not. Therefore, we have some valid and many excluded of those subdomains in our search console property. Unfortunately, we can't change anything about how we handle those customers hosting right now.  

#### [0:35:00](https://www.youtube.com/watch?v=L9GN4VX6xww&t=2100) |  So all official guidelines for permanently removing

URLs are not possible. The next idea would be manually removing those subdomains in Search Console with a removal tool every six months. I don't think you need to do that. So essentially, if these are pages that no longer exist or where you get a new page that replaces the previous page, then serving a 404 or serving a redirect for things that have  

#### [0:35:30](https://www.youtube.com/watch?v=L9GN4VX6xww&t=2130) |  moved that's perfectly normal. In Search Console,

we will show those as excluded in the reports. But it's not something that you need to manually fix. You don't need to suppress those errors or that status. That's completely normal. That's something we show that in Search Console. So that if you're not aware of this situation, you can follow up there and see why are these pages excluded and then from there work out was this  

#### [0:36:00](https://www.youtube.com/watch?v=L9GN4VX6xww&t=2160) |  a technical issue on my server, perhaps,

during a certain time? Or is this by design? And if it's by design, if you really remove those pages, if you don't want them serving anymore, if you want them redirecting or whatnot, then that's perfectly normal. It's not that we will rank your website anywhere lower just because you have pages that are currently not valid. From our point of view, it's a sign of a healthy website if you're serving the proper status code. So if things are gone and you tell us they're gone,  

#### [0:36:30](https://www.youtube.com/watch?v=L9GN4VX6xww&t=2190) |  that's perfect. In the mobile first indexing

world, will the hidden tax, hidden content behind tags and accordions still be devalued, for example, because there is a lower chance that it will be seen by a user? No, specifically, when it comes to content on mobile pages, we do take into account anything that's in the HTML. So if there is something there that  

#### [0:37:00](https://www.youtube.com/watch?v=L9GN4VX6xww&t=2220) |  might be visible to users at some

point, we will include that in the indexing. So that's completely normal. If we have a fragment URL and an href, does Google completely ignore that whole link or just the part after the fragment? We essentially, see that link. And we will drop anything after the fragment and just take the earlier part of the URL and assume that's the page that we can fetch from the server,  

#### [0:37:30](https://www.youtube.com/watch?v=L9GN4VX6xww&t=2250) |  and that's the page that we can

index, and that's the page that we will use to forward any signals with regards to links on those pages. I've seen a ranking drop on my domain since the March update and notice in search console that many of the staging links were referencing the live domain. But the website has already been removed from the server and is serving 500 but still in Google cache. I requested to remove the cache from search console.  

#### [0:38:00](https://www.youtube.com/watch?v=L9GN4VX6xww&t=2280) |  Will this have a worse impact on

my rankings? It sounds like there are a lot of things happening there. So it's hard to say what exactly is relevant there. I think maybe, offhand, worth saying that we make ranking changes all the time. And we try to make sure that these ranking changes reflect what we think is relevant and useful for users.  

#### [0:38:30](https://www.youtube.com/watch?v=L9GN4VX6xww&t=2310) |  So it might just be that you're

seeing the results of a normal ranking change that we make all the time. The other aspect with regards to staging site, you removed the staging site, and maybe they're still indexed, that's something where I would make sure that the staging site URLs are just removed properly, so that they return a 404 when someone tries to access them, not a 500. A 500 error is a server error.  

#### [0:39:00](https://www.youtube.com/watch?v=L9GN4VX6xww&t=2340) |  And essentially, when we see that, it

means that our algorithms will see that as a sign that maybe they're causing an error on your server. And usually they'll slow down with crawling. So that's something where serving a 500 on a regular basis is probably not something that you want to do. Is there href links with no-follow attribute and uncrawlable links the same for Google?  

#### [0:39:30](https://www.youtube.com/watch?v=L9GN4VX6xww&t=2370) |  By uncrawlable, I mean something like with

an on-click handler. So we use no follow as a signal in the meantime when it comes to crawling, indexing, and ranking. So that's something where the effect will vary depending on how our algorithms approach that individual link. And things like the on-click handler that you mentioned in the example, that's  

#### [0:40:00](https://www.youtube.com/watch?v=L9GN4VX6xww&t=2400) |  something where usually we would not see

that as a link. So it's not that our JavaScript systems will go through all pages and see where is an on-click handler and what happens when you trigger that. Usually, we would not see that as a link. So if you're making a JavaScript based website, don't use on click handlers for navigation. One thing that might happen in that particular example that you have there, where you have a JavaScript  

#### [0:40:30](https://www.youtube.com/watch?v=L9GN4VX6xww&t=2430) |  snippet in the on-click attribute that mentions

a URL directly, what will probably happen there is we will recognize the URL in the JavaScript that you're mentioning there. And we will try to see if we can just index that page individually if we haven't seen it before. So it'll be something we wouldn't be able to treat as a link. But we'd find a reference to that URL. And we might go off and index that.  

![](https://i.ytimg.com/vi/L9GN4VX6xww/maxres3.jpg)



#### [0:41:00](https://www.youtube.com/watch?v=L9GN4VX6xww&t=2460) |  So lots of edge cases involved there.

But if you're using a JavaScript site, don't use on-click. Use normal href links instead. And if you're using no-follow, then just keep in mind that that's the signal. That's not a directive. It's another way to block indexing of a specific page. You mentioned in Google search news that only index the content that is on the mobile version  

#### [0:41:30](https://www.youtube.com/watch?v=L9GN4VX6xww&t=2490) |  of the page. It doesn't mention hidden

content behind tabs. I think we talked about that just before. My images are ranking good. But my content is not ranking. I have unique content, which is helpful for users. Structure data is good. Unable to figure out the problem. Everything seems good and no technical issues on my website. It's really hard to say what you should be doing differently with regards to a website in general.  

#### [0:42:00](https://www.youtube.com/watch?v=L9GN4VX6xww&t=2520) |  So that's something where I don't know,

almost get a second opinion. And maybe post about that in the WebMaster help forum so that others can take a look at your pages and at the queries that you're trying to rank for and give you some honest, raw advice maybe on your website overall. Sometimes it's useful to just get someone else's opinion on things that you've been working on for a while.  

#### [0:42:30](https://www.youtube.com/watch?v=L9GN4VX6xww&t=2550) |  DARCY BURK: Can I ask a question?

JOHN MUELLER: Sure, go for it. DARCY BURK: Thank you. It's about schema. I'm just wondering, aside from the obvious schema types like faq, or event, or how true that may directly influence like the snippet, do you still recommend using some of the other schema types? Maybe things like local business or maybe more specific to the different types of businesses, or even web  

#### [0:43:00](https://www.youtube.com/watch?v=L9GN4VX6xww&t=2580) |  page? I think you had a tweet

making a joke about if pages are-- what page would you not consider a web page. Would you use those schemas as well? Is there any benefit to it aside from SEO maybe? I don't know. JOHN MUELLER: So the thing I would primarily watch out for with structured data is if there is a specific kind of visible treatment for that [INAUDIBLE] structured data, then that's the direct one-to-one relationship  

#### [0:43:30](https://www.youtube.com/watch?v=L9GN4VX6xww&t=2610) |  that you're aiming for. Everything else apart

from that direct-and-visible treatment, is something where it depends on the pages. And the structured data helps us to a little bit better understand the content on the page. But it's not something where you'll have any visible effect from that directly. So that's-- if you have different cities, and you mark them up as cities and locations, then that helps us to better understand, oh, this is a mention of a city, maybe not a brand, for example.  

#### [0:44:00](https://www.youtube.com/watch?v=L9GN4VX6xww&t=2640) |  But it's not something where there would

be a direct ranking relationship there. DARCY BURK: Right, but you may look at those structured data types to help understand the page just a little bit better? JOHN MUELLER: Yeah, so that's something where usually people are limited by the kind that they have available. Focus on the visible things. And if you can do a little bit more, that's perfectly fine. It's not a bad thing. I just wouldn't go overboard.  

#### [0:44:30](https://www.youtube.com/watch?v=L9GN4VX6xww&t=2670) |  It's like, if you're marking up every

other word on a page, then you're doing a lot of work that doesn't really result in anything useful for search engines. DARCY BURK: OK, wonderful. Thank you. JOHN MUELLER: All right, maybe we can open up for more questions from any of you all. VAHAN: I come back. JOHN MUELLER: OK. VAHAN: So, it turns out that [INAUDIBLE] you mentioned was already in the host plugin  

#### [0:45:00](https://www.youtube.com/watch?v=L9GN4VX6xww&t=2700) |  as we used WordPress. And per hour

tests, like non-AMP and the articles never ever shown the large images. Anything else we can do [INAUDIBLE]?? JOHN MUELLER: I don't know. It's hard to say. I mean, if you can send me some examples or maybe copy them into the chat here, and I can take a look with the team.  

#### [0:45:30](https://www.youtube.com/watch?v=L9GN4VX6xww&t=2730) |  I believe it's also the case that

we just don't show large images all the time, that maybe we show them as a small thumbnail if we think that's good enough. But if you think you're doing everything right, and you're pretty sure that we're never showing the large image, then I'm happy to double check with the team to see if there is something that either we need to document differently or maybe that you specifically are doing in a slightly weird way that I can get back to you on. VAHAN: We have lazy loading. Maybe it affect.  

#### [0:46:00](https://www.youtube.com/watch?v=L9GN4VX6xww&t=2760) |  JOHN MUELLER: It could theoretically. I mean,

it depends on how you mark up the images on the page. I believe-- I imagine you're using the article markup for those pages. VAHAN: Yeah, images in the-- JOHN MUELLER: And the image is probably linked directly in the markup itself. And you probably have the large image linked there. Then probably we would just pick it up from that. However, if you didn't have the article markup,  

#### [0:46:30](https://www.youtube.com/watch?v=L9GN4VX6xww&t=2790) |  and we had to find the image

on the page, then the lazy loading is something where sometimes we see a problem. But it sounds like that's not the case with you. VAHAN: Yeah, OK, I will tweet [INAUDIBLE] a couple of URLs. And [INAUDIBLE]. JOHN MUELLER: OK, cool. VAHAN: Yeah, thank you very much. JOHN MUELLER: Sounds good. All right, more questions from any of you all. What else did we miss? REHAAN: I can ask one more, John.  

#### [0:47:00](https://www.youtube.com/watch?v=L9GN4VX6xww&t=2820) |  JOHN MUELLER: All right. REHAAN: On our

website, our navigation which is site [INAUDIBLE],, has [INAUDIBLE].. And now two of them lead off to an external partner site. And there are no follow links. Is this likely to affect our ranking in any way if those two links were there or not there? JOHN MUELLER: No, I don't think that would change anything. So usually, we would recommend using no-follow for things like ads or if these are placed in user generated  

#### [0:47:30](https://www.youtube.com/watch?v=L9GN4VX6xww&t=2850) |  content on a site. But that's something

which is completely normal. Lots of web sites have ads. So they tend to have the no-follow links. Or if you're using the newer attributes, I believe that would be sponsored or UGC, for example. But that's completely normal. It wouldn't negatively or positively affect your website if you had those there or not. REHAAN: Even if it's in the site navigation? JOHN MUELLER: Even there, yeah.  

#### [0:48:00](https://www.youtube.com/watch?v=L9GN4VX6xww&t=2880) |  I [INAUDIBLE]. Sometimes people buy site wide

ads and using no follow is a proper approach to that. Or using rel equal sponsored is another way to do that. And that's perfectly fine to have these site wide [INAUDIBLE]. REHAAN: That's it. Thank you. JOHN MUELLER: All right, more questions from any of you all?  

#### [0:48:30](https://www.youtube.com/watch?v=L9GN4VX6xww&t=2910) |  No questions [INAUDIBLE]. DARCY BURK: I'll ask

[INAUDIBLE].. JOHN MUELLER: OK, go for it. DARCY BURK: Pedro, go ahead. I've asked one. PEDRO DIAS: I have a question regarding, more regarding how is the flow of reconsideration requests taking on this period of pandemics? Is it like operating at normal scheduled intervals like the regular-- can we expect the usual two, three weeks response time? Or is it longer?  

#### [0:49:00](https://www.youtube.com/watch?v=L9GN4VX6xww&t=2940) |  How is it affecting everything? JOHN MUELLER:

I don't know off hand. But my guess would be that it's slower than usual just because of the way things are set up when we have vendor teams that review these kind of things. Then probably during situations like this, they have to get reorganized first and work from home and get all of the setups working. So my guess is it'll be a bit slower than usual. But I don't have any first hand data on that.  

#### [0:49:30](https://www.youtube.com/watch?v=L9GN4VX6xww&t=2970) |  PEDRO DIAS: Thanks, OK. JOHN MUELLER: Be

patient, Pedro. Your spamming sites will come back. PEDRO DIAS: It's not me. JOHN MUELLER: Sure, sure, that's fine. Your friend. DARCY BURK: I have just a question about videos. Is there any advantage, disadvantage to using a local player versus YouTube and embedding them from an SEO perspective?  

#### [0:50:00](https://www.youtube.com/watch?v=L9GN4VX6xww&t=3000) |  JOHN MUELLER: I think the main difference--

I guess there are two things. On the one hand, we have to be able to recognize the video is there if you want the video to be indexed in video search and with the video snippet. We have to recognize that the video Is there. With a common player format, if that's YouTube or Vimeo or whatever the common formats are, then that's really easy for us to do.  

#### [0:50:30](https://www.youtube.com/watch?v=L9GN4VX6xww&t=3030) |  So if you use your own player

format, and you're using something that you custom made for yourself, then we might have a little bit of trouble understanding that. If you're using something, I don't know, open source scripts, or whatever they're are out there, then probably we'll be able to pick that up. The other thing is, especially if you're using YouTube, the landing page of the YouTube video might rank as well in search. And when you're specifically looking  

#### [0:51:00](https://www.youtube.com/watch?v=L9GN4VX6xww&t=3060) |  at the videos themselves, it might happen

that the YouTube landing page ranks above your content or below your content. It's really hard to say. So that might be something where you say, it doesn't matter for us. I don't care which of these pages is ranking as long as people find the video. It might also be that you say well, my web page is the one that I really need to have ranked. And I'd rather rank a little bit lower than to have a YouTube landing page above mine.  

#### [0:51:30](https://www.youtube.com/watch?v=L9GN4VX6xww&t=3090) |  And that's a call you can make.

DARCY BURK: Got it. Cool, thanks. MIHAI APERGHIS: John, I have a couple of questions, actually one question. So regarding the Google search console API, if I'm guessing given the current situation, there is probably not a lot of work in adding new features to it.  

#### [0:52:00](https://www.youtube.com/watch?v=L9GN4VX6xww&t=3120) |  Just wondering if you heard anything on

adding the fresh data maybe to it or any other developments? JOHN MUELLER: We discussed the fresh data a while ago. I don't know what the status is there with the team. But in particular with the fresh data, the issue we noticed is we can't just start including that by default because that would confuse the way people use  

#### [0:52:30](https://www.youtube.com/watch?v=L9GN4VX6xww&t=3150) |  the data from the API. So we'd

have to add some flag or something like that to it. I don't know what the status of that is at the moment. I believe that something that was not that far away recently. But I don't know how things are different now. MIHAI APERGHIS: OK, and also on the API front, is there any chance there would be a Google trends  

#### [0:53:00](https://www.youtube.com/watch?v=L9GN4VX6xww&t=3180) |  API in the near future given that

especially right now Google trends is a very valuable resource to see how things are moving along day to day? JOHN MUELLER: I don't know. I thought we had an API for Google trends. MIHAI APERGHIS: Well, it's mostly a hack, a work-around. There's a deep export option. So people just use the export URL, [INAUDIBLE] URL by [INAUDIBLE] keyword by keyword and stuff like that. But there is no official API.  

#### [0:53:30](https://www.youtube.com/watch?v=L9GN4VX6xww&t=3210) |  JOHN MUELLER: OK, I don't know. It

sounds like something we should ask for, yeah. I think in general with these kind of things, if you can give us some really good reasons why it makes sense, you can post them on Twitter or anywhere where it's visible, then that's something that's always useful to go to a team and say look, all these people want this. And here's why they want it. You should do it. MIHAI APERGHIS: OK, awesome, cool.  

#### [0:54:00](https://www.youtube.com/watch?v=L9GN4VX6xww&t=3240) |  JOHN MUELLER: Cool. MIHAI APERGHIS: Yeah, they

will help me out, definitely. JOHN MUELLER: All right, OK, so I guess we're overtime. So we can take a break here. I have the next hang out lined up for Friday in English and Thursday in German. I think Martin is doing a JavaScript hang out this week as well, maybe tomorrow or something.  

#### [0:54:30](https://www.youtube.com/watch?v=L9GN4VX6xww&t=3270) |  MARTIN SPLITT: Next Wednesday. JOHN MUELLER: Next

Wednesday. OK, you have hold out until next Wednesday if you care about JavaScript. And I think we just uploaded a whole bunch of YouTube videos from the webmaster conference product summit that we did in Mountain View. So that's another cool set of stuff to look at. In particular, I guess the more advanced people will be keen on listening in to Paul [INAUDIBLE] talk, which I thought was really, really cool to see.  

#### [0:55:00](https://www.youtube.com/watch?v=L9GN4VX6xww&t=3300) |  So stay safe, stay healthy, and hopefully

see you all in one of the next hang out's again. Bye, everyone. MIHAI APERGHIS: Bye, guys. MARTIN SPLITT: Bye.  