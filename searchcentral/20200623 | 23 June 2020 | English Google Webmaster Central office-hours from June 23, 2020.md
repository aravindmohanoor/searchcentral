[![English Google Webmaster Central office-hours from June 23, 2020](https://i.ytimg.com/vi/rO6wTSL6joE/maxresdefault.jpg)](https://www.youtube.com/watch?v=rO6wTSL6joE)

## English Google Webmaster Central office-hours from June 23, 2020

This is a recording of the Google Webmaster Central office-hours hangout from June 23, 2020. These sessions are open to anything webmaster related like crawling, indexing, mobile sites, internationalization, duplicate content, Sitemaps, Search Console, pagination, duplicate content, multi-lingual/multi-regional sites, etc. 



Watch out for new sessions, and add your questions at https://www.youtube.com/user/GoogleWebmasterHelp/community



Feel free to join us - we welcome webmasters of all levels!



#### [0:00:00](https://www.youtube.com/watch?v=rO6wTSL6joE&t=0) |  JOHN MUELLER: All right. Welcome, everyone, to

today's Webmaster Central Office Hour Hangouts. My name is John Mueller. I am a webmaster trends analyst at Google in Switzerland. And part of what we do are these office hour hangouts, where people can jump in and ask their questions around the website and web search. Looks like a bunch of questions were submitted already. But as always, if any of you want to get started with a question of your own, feel free to jump on it.  

#### [0:00:30](https://www.youtube.com/watch?v=rO6wTSL6joE&t=30) |  Or not; that's fine too. Maybe something

will come up along the way, SANJIT CHAKRABORTTY: Hey John, how are you? JOHN MUELLER: Hi. HASIT RUPAREL: Go for it. SANJIT CHAKRABORTTY: OK, so John, actually, I have a question. So I am seeing that still, my site primary [INAUDIBLE]..  

#### [0:01:00](https://www.youtube.com/watch?v=rO6wTSL6joE&t=60) |  So it's still not changeable. We have

a huge number of pages, around 20 million traffic. So it's a bit [INAUDIBLE] me, so how to solve that? JOHN MUELLER: And what is the problem that you're seeing? SANJIT CHAKRABORTTY: In my primary [INAUDIBLE] desktop. JOHN MUELLER: Index as desktop? SANJIT CHAKRABORTTY: Yes. JOHN MUELLER: Yeah. So I mean, from a practical point of view, that doesn't mean that there is anything broken.  

#### [0:01:30](https://www.youtube.com/watch?v=rO6wTSL6joE&t=90) |  We're indexing the site as it is.

I think what I would really look into is whether or not the mobile and the desktop pages are really the same with regards to the content and that the embedded content that you have on those pages is similar. So some of the things we have sometimes seen when people check for the text. If the text is OK, if the structured data is OK, then sometimes, there is still an issue  

#### [0:02:00](https://www.youtube.com/watch?v=rO6wTSL6joE&t=120) |  that maybe the headings are not actually

visible on mobile. If you don't have any headings on mobile, if they're just marked up to be more visible text but not using the heading tags, that might be something that we notice. Another thing that's really common is if you have thumbnails that you use as links to related items on your pages. If you have a larger number of thumbnails on your desktop pages than on your mobile pages, then our systems might think that you're  

#### [0:02:30](https://www.youtube.com/watch?v=rO6wTSL6joE&t=150) |  missing some important images. Probably those thumbnails

don't matter so much, but it's something where our systems might say, well, there are 20 images on desktop, and there are only 10 on mobile. Maybe there is something that the site owner would want to take care of first. So those are, I guess, the more tricky topics that are kind of hard to spot automatically.  

#### [0:03:00](https://www.youtube.com/watch?v=rO6wTSL6joE&t=180) |  There's also the issue of sometimes, if

we think that a page should be a landing page for an image or a video, and on mobile, that image in the video is not so prominent, then we might think that actually, this is not such a good video or image landing page anymore. And that's also something that our mobile-first indexing systems will look at and say, well, it looks like this would be problematic for image search or problematic for video search.  

#### [0:03:30](https://www.youtube.com/watch?v=rO6wTSL6joE&t=210) |  Therefore, we want to be a bit

more cautious here. So those are the things I would take a look at. I don't think it's the case that you urgently need to move or that you will have any kind of a ranking or search advantage if you move or you get your site moved to a mobile-first indexing. But it's good to take care of these things. HASIT RUPAREL: OK, sure. Thank you. JOHN MUELLER: Sure. HASIT RUPAREL: Hey. My question is regarding--  

#### [0:04:00](https://www.youtube.com/watch?v=rO6wTSL6joE&t=240) |  so I know there is no magic

formula for ranking. However, should we be concerned about the search consoles area and be obsessed with it, or still focus on the user experience or the content on the site as one of the factors? JOHN MUELLER: So how do you mean, focus on the search console area? HASIT RUPAREL: So we are going through a major redesign  

#### [0:04:30](https://www.youtube.com/watch?v=rO6wTSL6joE&t=270) |  on the site, and we probably have

3,000 pages or so discontinued. And we are running through a full list of 404 errors and all. And then, there is also core [INAUDIBLE] showing up a little bit where that is a serious issue and stuff like that. So should we be obsessed with it? Or it's like, yeah, eventually, it's going to flesh out, and hope that things will settle in terms of ranking?  

#### [0:05:00](https://www.youtube.com/watch?v=rO6wTSL6joE&t=300) |  JOHN MUELLER: It's really hard to say

offhand, because there are so many different kinds of issues that can be reported on in Search Console, and not all of them are immediately critical issues that you need to take care of right away. So for example, if we can't reach your site, if we can't index your pages, that's pretty critical.  

#### [0:05:30](https://www.youtube.com/watch?v=rO6wTSL6joE&t=330) |  However, if it's a matter of, well,

your page is not as fast as it could be, then that's something we're it's like, it's OK. It's good to take care of these things because they are things that users might see. But it's not the same level of criticalness as, we can't index your pages at all. So with regards to that, it's something where you almost, I guess, need to be able to take a step back and think about, what is the effect of this issue that I'm seeing reported?  

#### [0:06:00](https://www.youtube.com/watch?v=rO6wTSL6joE&t=360) |  And is that effect something that is

critical for my web presence at the moment? Or is that a nice-to-have? Or is that something that's maybe worthwhile, cleaning up when you have a bit of downtime and you don't need to worry about urgent issues anymore? So that's the way that I would look at it. I don't think there is, by definition, any automatic way to recognize which of these issues  

#### [0:06:30](https://www.youtube.com/watch?v=rO6wTSL6joE&t=390) |  are the most critical ones. We try

to bubble up the things that we think are critical, but there are so many different things that can go wrong. So it's kind of hard to say what the most critical thing is you should take care of first. HASIT RUPAREL: OK, thanks. JOHN MUELLER: let me look at some of the questions that were submitted. And as always, if any of you have questions  

#### [0:07:00](https://www.youtube.com/watch?v=rO6wTSL6joE&t=420) |  along the way, or comments, or anything

to add, feel free to jump on in. The first one is, "Let's say I have two strong URLs about cheese in my website. One is an e-commerce page where you can buy cheese. The other is a complete guide about cheese. So two different pages talking about the same topic, but both really relevant. What's the best practice for internal linking? Is it OK to link both pages using the same anchor text, "cheese," or should one be linked differently?  

#### [0:07:30](https://www.youtube.com/watch?v=rO6wTSL6joE&t=450) |  What are some suggestions?" So essentially, internal

linking helps, us on the one hand, to find pages. So that's really important. It also helps us to get a bit of context about that specific page. And we get some of that through the anchor text from the internal linking, and some, of course, from understanding where these pages are linked within your website. So with regards to that, thinking specifically  

#### [0:08:00](https://www.youtube.com/watch?v=rO6wTSL6joE&t=480) |  about the anchor text here, I don't

think you need to do anything specific there. If you're already linking to those pages, if you're using a reasonable anchor text or for "cheese," in this case, that sounds perfectly fine. I don't think you need to change the anchor text to be, "Buy Your Cheese Online Here," and it's like "The Ultimate Guide To All Types Of Cheese" here. It's something you could do if you wanted to, if you think it makes sense for your users.  

#### [0:08:30](https://www.youtube.com/watch?v=rO6wTSL6joE&t=510) |  But it's not something where, I think,

you would see a visible effect in search. So I hope that helps in that regard. I think it's always kind of a tricky situation when you have multiple pages on the same topic or multiple pages for the same keyword, in that people often worry about cannibalization, which essentially means that you have multiple pages ranking for the same term, and maybe you would be ranking better if you had just had  

#### [0:09:00](https://www.youtube.com/watch?v=rO6wTSL6joE&t=540) |  one page ranking for that term. That's

definitely something legitimate to think about. And from my point of view, I generally prefer to have fewer pages rather than more pages. But these are completely different topics, completely different types of pages, so it feels perfectly fine from my point of view to have two pages that are different like this. And oftentimes, you will have this situation where  

#### [0:09:30](https://www.youtube.com/watch?v=rO6wTSL6joE&t=570) |  you have informational pages on a topic,

and maybe transactional pages on a topic, maybe something in between, maybe some category pages that are also on this topic, and that kind of start-up is completely normal. And that's something that our systems try to work with and where we try to show the relevant page in the search results. OK, "The best experts at a country level review our articles from the health section of our website.  

#### [0:10:00](https://www.youtube.com/watch?v=rO6wTSL6joE&t=600) |  We want to be sure that not

only users, but also Google appreciates it. What advice can you give us?" So essentially, well, when it comes to things like this, where you're saying, well, we do a lot of background work to make sure that the information that you get is really valid, it's correct, that's relevant, then that's something that you essentially need to show to users primarily, and our systems will be able to pick up on that over time. It's not that there is a specific structured data  

#### [0:10:30](https://www.youtube.com/watch?v=rO6wTSL6joE&t=630) |  element that you can put on a

page and say, well, my page is correct, or my information is correct. It's like, you should trust me; I did a lot of work. But really, you want to persuade is the users. And if we can tell that there's a lot of background information there, if our systems recognize that this is clear to users as well, then that's something that we will try to reflect in search.  

#### [0:11:00](https://www.youtube.com/watch?v=rO6wTSL6joE&t=660) |  So from that point of view, I

wouldn't focus so much on structured data, or meta tags, or anything like that. But really make sure that it's clear for users, and then we should be able to pick that up, too. I think the next question is kind of related. "We have a health section on our news website. We want to implement a review-by schema markup on the pages. It looks like this parameter is only for web page descendants-- Medical page, for example.  

#### [0:11:30](https://www.youtube.com/watch?v=rO6wTSL6joE&t=690) |  Should we implement reviewed-by in the news

article-- that works right now-- or should we change News Article to Medical Page for all articles in the Health rubric?" So I think this of goes into the same direction. Essentially, you need to make sure that these things are clear for users and not primarily focus on what search engines would see with regards to structured data. In a case like this, if you have news content,  

#### [0:12:00](https://www.youtube.com/watch?v=rO6wTSL6joE&t=720) |  then it would mark it up as

news content. That's the technically correct way to do that with the schema.org markup. I believe there are also some elements in Google search that specifically watch out for news article markup to recognize that actually, this is a news article-- which, from my point of view, would make sense. If there is no way to add reviewed-by schema markup to news article pages-- I don't know-- then there's no way to do that.  

#### [0:12:30](https://www.youtube.com/watch?v=rO6wTSL6joE&t=750) |  So that's something where, if you have

news articles and you can't add another kind of markup specifically for something else, then that's something you can't purely from the schema.org setup. It might be that there are alternate variations that you can do for this kind of site. I don't think, when it comes to search, that you would see any difference if you  

#### [0:13:00](https://www.youtube.com/watch?v=rO6wTSL6joE&t=780) |  implemented the markup in a hacky way

or didn't implement it at all. Most probably, our systems just watch out for those elements that we explicitly have documented in the developer documentation, where we have all of the different types documented that we use in search. That's specifically what we watch out for. And everything else is a little bit more like, well, you're providing a bit more context. So in a case like this, I wouldn't worry too much  

#### [0:13:30](https://www.youtube.com/watch?v=rO6wTSL6joE&t=810) |  about being able to add reviewed-by markup

if that's technically not something you could do when it comes to news article pages. Is it against Google guidelines if you cloak but show almost the same thing? Let's see. For context, due to a data contract, I can't show an exact results page due to scrapers-- so they have to be no-index.  

![](https://i.ytimg.com/vi/rO6wTSL6joE/maxres1.jpg)



#### [0:14:00](https://www.youtube.com/watch?v=rO6wTSL6joE&t=840) |  However, I can show cached results. So

if you're looking for a four bedroom house, as the user, you'll technically be served a different page and then a search engine. And so I think when talking with the engineers or the quality team about topics like this, they generally say, well, it should be exactly the same. From a practical point of view, there will almost always be differences with regards to what Google sees and what users see, especially when it comes  

#### [0:14:30](https://www.youtube.com/watch?v=rO6wTSL6joE&t=870) |  to content that's very dynamic. So for

example, it might be that you have a news page, and when Google crawls, it has one article on top. And then, an hour later, when a user goes to that page, there is a different article on top. Technically, it's slightly different content. From a practical point of view, the reason for the page is essentially just the same. So it's not something where I think our systems would watch out for that and say, oh, this is against the webmaster guidelines.  

#### [0:15:00](https://www.youtube.com/watch?v=rO6wTSL6joE&t=900) |  With regards to the Web Spam Team,

they would also look at this and say, well, it's essentially the same page. Maybe it's the data that's shown is slightly different with regards to what is cached and what is served live, but it's essentially the same page, so that generally would be fine. Usually, the place where we run into more problems with this kind of a setup is when you have a technical issue on the part of your site  

#### [0:15:30](https://www.youtube.com/watch?v=rO6wTSL6joE&t=930) |  that is only visible to Google Bot.

Then it happens every now and then that something severely goes wrong there. Maybe there's a server error showing, or maybe the cache is super stale and it's from last year and not from this week. Those are the kind of things where, as a site owner, you might not notice them immediately, because when you look at the page, when you use your monitoring tools to access those pages, you see the live version that a user would see.  

#### [0:16:00](https://www.youtube.com/watch?v=rO6wTSL6joE&t=960) |  So often, the issues that come up

here are more about, well, if you implement it in a bad way, or if something breaks along the way and you don't realize it, then you could be shooting yourself in the foot there. It's not so much that from the web spam guidelines, the web spam team, that they would look at this and say, oh, the text is slightly different on this version than on that version. Therefore, we have to take a manual action.  

#### [0:16:30](https://www.youtube.com/watch?v=rO6wTSL6joE&t=990) |  "I'm getting this error in Search Console--

referenced AMP URL is not an AMP. What's causing this error, and how can I fix it?" It's essentially impossible to say without knowing the URLs. This is one of those cases where I would recommend going to the Webmaster Health Forum and getting some help from other folks who have a little bit of experience in Search Console. Explicitly mention that URLs that you're seeing.  

#### [0:17:00](https://www.youtube.com/watch?v=rO6wTSL6joE&t=1020) |  Maybe take a screenshot as well so

that people can take a look and see, is there really an issue here, or is this something where, maybe, the search console has a weird error that's a bit confusing. Maybe it's also something where there's an error on our side. And the folks in the Webmaster Help Forum, they can escalate these issues to us. So that's the direction I would head there. My guess is that-- just purely from the text--  

#### [0:17:30](https://www.youtube.com/watch?v=rO6wTSL6joE&t=1050) |  that you have a page that looks

like an AMP page, but for whatever technical or theoretical reasons, it's not a valid AMP page. And that's something that happens every now and then. It could be that maybe there's a script tag that's lost on the page. Maybe something briefly went wrong with a plug-in that you're using. All of these things can happen. But the folks in the Webmaster Help Forum can generally help you to narrow things down.  

#### [0:18:00](https://www.youtube.com/watch?v=rO6wTSL6joE&t=1080) |  "Is there a concept in Google of

types of pages in a site? In other words, on an e-commerce store, for example, would a category listing page be identified, product detail type pages be identified as a concept of this, perhaps for understanding crawling or canonicalization?" I don't know if we'd have an explicit kind of concept for this. It's very likely that we would have different signals  

#### [0:18:30](https://www.youtube.com/watch?v=rO6wTSL6joE&t=1110) |  that we try to compile for different

types of pages to figure out how and when we should show this page appropriately. But I don't know if we would have something as explicit as this, where we'd say, oh, this is a category page on an e-commerce site, and it lists shoes in the category, or if it's more something that's more abstracted and more useful just for our algorithms.  

#### [0:19:00](https://www.youtube.com/watch?v=rO6wTSL6joE&t=1140) |  Part two is, "If there is such

a thing, does it pay to keep the basic template of common page types similar to help Google to understand? For instance, products in a div id=myproductlist, or whatever the structure is, common across category pages?" So sometimes that does help us to understand which pages belong together. So that is something that we try to do when we crawl and index a website, is to figure out what pages are kind of a part of the same group.  

#### [0:19:30](https://www.youtube.com/watch?v=rO6wTSL6joE&t=1170) |  And for the most part, we do

that with regards to crawling, to understand, well, these are all product pages. I mean not specifically that we'd say these are product pages, but this URL pattern looks like a kind of set of pages that are all very similar and based on that, we can prioritize our crawling a little bit. So that's the direction that we go there, it's less about of the ranking side  

#### [0:20:00](https://www.youtube.com/watch?v=rO6wTSL6joE&t=1200) |  and understanding exactly what page type it

is, but more understanding, well, this set of pages belongs together in one group, and maybe we've seen 90% of the pages in this group are no-index, for example. Then, if we see new pages that belong into the same group with a similar URL pattern, then, probably, we can say, well, it's very likely that these new pages will also be no-index, even without us calling them. So we could theoretically deprioritize  

#### [0:20:30](https://www.youtube.com/watch?v=rO6wTSL6joE&t=1230) |  those pages a little bit with regards

to crawling. And similarly, if we recognize that actually, this group of pages is really important for this website if we find new pages that fit into that group, then that's something we can say, well, maybe we should prioritize these a little bit with regards to crawling and pick them up a little bit faster. So that's the direction that we go there, it's less about the HTML exactly on the page and really more about the general bucket of pages.  

#### [0:21:00](https://www.youtube.com/watch?v=rO6wTSL6joE&t=1260) |  And I think for the most part,

we organize this by your URL patterns, where our systems automatically create a little bit of an understanding of the URL patterns within a website and understand which parameters are relevant where. Part of that you see in Search Console and the Parameter Handling Tool. "I started a blog last year, following all your tips on that blog. Within a few months, I was getting 800 daily visitors  

#### [0:21:30](https://www.youtube.com/watch?v=rO6wTSL6joE&t=1290) |  from Google, and that's huge for me.

But sadly to say, for some reasons, I was inconsistent on the blog for three months. After my inconsistency on the blog, I was getting zero visitors from Google. But after realizing my mistake, I started again in January and migrated to new hosting provider. And now I'm writing posts and building links daily. I'm still only getting 10 to 30 visitors from Google. What should I do?"  

#### [0:22:00](https://www.youtube.com/watch?v=rO6wTSL6joE&t=1320) |  So it's really hard to say what,

exactly, you've been seeing. My general sense is that the differences in the traffic that you're seeing from the search results is not due to your consistency on the blog or inconsistency on the blog, but rather that's something where our systems have tried to figure out how relevant this page is in the context of the overall. And that can change over time.  

#### [0:22:30](https://www.youtube.com/watch?v=rO6wTSL6joE&t=1350) |  And it can be such that you

might be getting 100 visitors a day at one point, and our algorithms update, and we understand, well, maybe this isn't as relevant as we thought it was, and you'd get fewer visitors afterwards. It can also happen that our algorithms get updated and say, well, this is a really fantastic page. Why are we only sending 800 people here? We should be sending thousands of people here. That can also happen. So that's kind of where-- my guess is this is more of an algorithm change thing  

#### [0:23:00](https://www.youtube.com/watch?v=rO6wTSL6joE&t=1380) |  and less a matter of you being

consistent or not. The other thing that I'm reading between the lines here is you're writing posts daily, and you're building links daily. And it makes me wonder what you consider to be building links, for example. It's very easy to get sucked up into the link-building world. And essentially, you're sending emails to everyone, or you're dropping comments on other people's blogs,  

#### [0:23:30](https://www.youtube.com/watch?v=rO6wTSL6joE&t=1410) |  or you're trying to find those sites

where you can drop your link and it's not a no-follow. And everyone goes there-- or automatically goes there-- and drops their links there. It's very easy to get sucked into that and to spend a lot of time building links, in a sense, but building a lot of links that, essentially, our systems ignore. And that could be time that you could be spending to improve your content overall, which is something that our systems will appreciate more over time.  

#### [0:24:00](https://www.youtube.com/watch?v=rO6wTSL6joE&t=1440) |  So that's something where I think it's

important that you find a balance between promoting your work and doing your work. But primarily, you should be doing your work really well and not spending that much time promoting it altogether. Let's see. "I think the Search Console Inspect URL Tool, we talked about that briefly.  

#### [0:24:30](https://www.youtube.com/watch?v=rO6wTSL6joE&t=1470) |  What makes posts eligible for Google Discover?

According to my Search Console reports, my posts were getting features for some time, but then it completely stopped." So Discover, I think, is pretty cool in that it shows your content to people who are not explicitly looking for it but who we think might have interest in that topic. So overall, I think that's pretty cool. On the other hand, that also means that our systems have to be a little bit more  

#### [0:25:00](https://www.youtube.com/watch?v=rO6wTSL6joE&t=1500) |  cautious with regards to the content that

we promote there, because we realize that people aren't explicitly looking for that content. So we should maybe be a little bit more cautious there than we otherwise would elsewhere in search. And with regards to eligibility in Discover I believe the Google News Publisher Guidelines apply to Discover. I'm not 100% sure. I think that's what we link from the Discover Help Center page.  

#### [0:25:30](https://www.youtube.com/watch?v=rO6wTSL6joE&t=1530) |  So that's the baseline eligibility. But as

I mentioned, we do try to make sure that the content that we provide through Google Discover or that we link to is something that we can really fully stand behind. So my guess is, if for a while your posts were being shown in Discover, maybe they're not being shown as much anymore, then our systems are a little bit more cautious with regards to whether or not this is really fantastic content that we  

#### [0:26:00](https://www.youtube.com/watch?v=rO6wTSL6joE&t=1560) |  should be promoting and discovering. That also

means that probably, you just need to step up a little bit more to reach that target again. It's really hard to say what, exactly, you should be doing differently, because there is no query assigned to Discover. But it is something where working with your audience, the people who are going to your site already, and figuring out, what is it that really interests them, and how can you  

#### [0:26:30](https://www.youtube.com/watch?v=rO6wTSL6joE&t=1590) |  provide that in a way that gives

a lot of value to everyone who looks at that content? That's something you can try to tweak over time. "Is using schema to link between other related schemas on the same page, between schemas on pages of the website, basically creating a network just like internally linking? Does that have any benefit for Google's understanding of a website or any benefit to SEO?"  

#### [0:27:00](https://www.youtube.com/watch?v=rO6wTSL6joE&t=1620) |  I don't think so. So primarily, when

it comes to structured data, we try to use the structured data that we can use for specific search features. We have that explicitly documented and the "Developer's Guide." So that's our primarily use case of structured data. Additionally, we do try to look at the structured data that's otherwise on the website to understand a little bit better, is there any context that we're, perhaps, missing here?  

#### [0:27:30](https://www.youtube.com/watch?v=rO6wTSL6joE&t=1650) |  Is there any additional information that helps

us to better understand how this particular page stands within the website? But at the point where you're kind of referring to-- referring from one type of not-directly-supported structure data to other pages with not-directly-supported structured data, at that point, I think you're probably in the area of, well, our systems see this, but we can't really do anything useful with it.  

#### [0:28:00](https://www.youtube.com/watch?v=rO6wTSL6joE&t=1680) |  Even if we can understand the relationships

between those specific items that are marked up with structured data, it's probably so vague that it's really not something that would have any visible effect on ranking at all. "Do you think that errors in a domain might affect the web positioning of subpages-- for instance, in relevance?"  

![](https://i.ytimg.com/vi/rO6wTSL6joE/maxres2.jpg)



#### [0:28:30](https://www.youtube.com/watch?v=rO6wTSL6joE&t=1710) |  It is really hard to say without

knowing what kind of errors you're looking at there. So when it comes to technical errors, for the most part, I don't think that would apply. If you have some pages that are accidentally 404, I don't think it would apply at all to anything else on the website. The one exception that I can think of is if it looks to us like this domain is not in use at all,  

#### [0:29:00](https://www.youtube.com/watch?v=rO6wTSL6joE&t=1740) |  then that might be something that would

apply to the other subdomains there. So for instance, if the WWW and the non-WWW version of the domain, if they both just don't resolve to a normal web page, then our systems might think, well, maybe this website went down. Maybe it's no longer accessible. And at that point, they might apply that to the other subdomains as well and say, well, it looks like the whole domain is gone. Maybe we don't need to index all of these subdomains either.  

#### [0:29:30](https://www.youtube.com/watch?v=rO6wTSL6joE&t=1770) |  But that's an extremely rare situation that

I ever see something like that. So that's usually not something that people worry about, because if it looks like your website is down, then that seems like a more general problem than is, how does it affect my relevance in the search results? Other types of errors-- like, for example, if you have structured data issues on a website, if you have issues with regards to speed  

#### [0:30:00](https://www.youtube.com/watch?v=rO6wTSL6joE&t=1800) |  or with regards to even simple things

like, I don't know, grammar or spelling on a website. Technically, those are errors, but that's not something that would affect the other pages or the other domains, subdomains on a website. So that's generally not something that I would see as being an issue. So if you have a setup with different subdomains, obviously, making sure that your website doesn't look like it's down is a good thing.  

#### [0:30:30](https://www.youtube.com/watch?v=rO6wTSL6joE&t=1830) |  But otherwise, I wouldn't worry too much

about how you manage the main domain versus the subdomains. What could be the cause behind Google activating a website's review snippet enhancement, followed by massive upwards and downwards fluctuations in clicks and impressions and a deactivation one month later? We've been experiencing such quick switches since last year after having your View Snippets activated constantly for years.  

#### [0:31:00](https://www.youtube.com/watch?v=rO6wTSL6joE&t=1860) |  SANJIT CHAKRABORTTY: I don't know. It's hard

to say from just this question. It sounds like there might be some kind of a technical issue involved here. It might also just be that our algorithms are a bit on the edge with regards to how to treat this website. But if you've been having this kind of on and off situation, on a weekly or a monthly level, then that feels kind of weird, like something that probably  

#### [0:31:30](https://www.youtube.com/watch?v=rO6wTSL6joE&t=1890) |  shouldn't be happening, where it might be

useful to have your domain or the queries where you're seeing this. What you could do is maybe post in the Webmaster Help forum to see if other people have anything obvious that they can spot there. Otherwise, you can also send me a note on Twitter, and I can take a look at that, too. I'm doing SEO on and off page for some packers and mover web sites, approximately two months.  

#### [0:32:00](https://www.youtube.com/watch?v=rO6wTSL6joE&t=1920) |  Backlinks and domain authority have creasing right

now. I don't know. Is that like-- "has been increasing," I'm guessing. But pages are not ranking. What should I do to rank all of my pages? So I think first of all, we don't use domain authority in search. I think that's a misconception that's out there that comes up every now and then. I think it's really cool to have these kind of tools out there  

#### [0:32:30](https://www.youtube.com/watch?v=rO6wTSL6joE&t=1950) |  that help you to understand how my

site fits in with regards to the rest of the web. But we don't use domain authority. So it's not something where I would focus on domain authority and say, this is what I need to do, but rather, think about your website on a whole, and think about what you should be doing overall to improve your website. The same thing applies to backlinks here. As I mentioned before, with the other case, someone who is just  

#### [0:33:00](https://www.youtube.com/watch?v=rO6wTSL6joE&t=1980) |  building backlinks, it's something where it is

very easy to get pulled down into this world of building backlinks, where you have to drop your links everywhere to increase the number of links to your website. And that's definitely not what our algorithms are looking for. If you just drop random links on other people's blogs, or drop links in forums or in other places where it might get picked up, that's not something that we would look at and say, oh, this  

#### [0:33:30](https://www.youtube.com/watch?v=rO6wTSL6joE&t=2010) |  is a sign of a high-quality website

that we should be showing more. That's not how it works. So that's something where, if you've been working on this website for approximately two months, then I would recommend maybe spending a bit more time on the website overall, especially if you're active in a very competitive area. So I don't know how packers and mover websites are where you are located, but I've seen that as one of the more competitive areas.  

#### [0:34:00](https://www.youtube.com/watch?v=rO6wTSL6joE&t=2040) |  And coming in for two months and

spending a bit of time to build up a website, and drop some links in various places, and focus on domain authority, I don't think that would be enough to actually make a dent there. So that seems more like something where you'd have to come up with a long-term strategy and figure out ways that you can differentiate yourself from other people, from all of the other competitors that are out there, and really show the additional value that you  

#### [0:34:30](https://www.youtube.com/watch?v=rO6wTSL6joE&t=2070) |  provide, and to make sure that Google

and other search engines are able to recognize that additional value. And we would recognize that not by random backlinks that are dropped or domain authority, but rather by looking at the whole picture. All right. "Can you share any more information about the possible bug with this Disqus comments not being indexed? I can see some pages are definitely having their comments indexed, while others aren't.  

#### [0:35:00](https://www.youtube.com/watch?v=rO6wTSL6joE&t=2100) |  I've seen this for a long time

with Disqus, and I thought Google was selectively indexing comments from certain pages based on quality. Martin explained the other day that there might be a bug. Since many sites use Disqus, it would be great to know if more Disqus comments are going to be index moving forward. Martin said this could happen." Well, I guess if Martin says it could happen, then that seems like a pretty strong case. I personally haven't looked into this.  

#### [0:35:30](https://www.youtube.com/watch?v=rO6wTSL6joE&t=2130) |  I don't know exactly what is happening

there. I know some sites use Disqus comments extensively. Some sites implement them in a way that they're cached within the static HTML that's served with the website. It makes it, I suspect, a bit hard to understand exactly what is happening there if there are so many different ways that you can embed these comments within a website. So that, I don't know.  

#### [0:36:00](https://www.youtube.com/watch?v=rO6wTSL6joE&t=2160) |  It sounds like from this comment and

from, I think, the brief exchange I saw on Twitter, that there is something that we could be doing to improve indexing of these comments. But I don't know how big of an effect that would be, if that's something where we can just index it a little bit more, or if it's a really big jump, that we can suddenly index a lot more. I don't know. We'll see.  

#### [0:36:30](https://www.youtube.com/watch?v=rO6wTSL6joE&t=2190) |  I don't know. Barry, you have Disqus

comments on your site, right? BARRY SCHWARTZ: Yes, I do. JOHN MUELLER: [INAUDIBLE] BARRY SCHWARTZ: BARRY But it seems to index fine, so I don't know. JOHN MUELLER: OK. BARRY SCHWARTZ: But Doug [? Glenn ?] did a blog post months and months ago saying how some sites, Google had no problem indexing these comments on, and some sites, they don't. And he has a real long story on that. I'm not sure. I haven't looked into it either. But maybe there's just the way that those publishers have implemented Disqus, that it's being blocked.  

#### [0:37:00](https://www.youtube.com/watch?v=rO6wTSL6joE&t=2220) |  I kind of want to block mine.

I'm not sure. I used to block it. Then you guys got better at indexing. So now I have to find another way to block it. So-- JOHN MUELLER: Yeah, that's always a struggle. It's like a bunch of people come to us, and it's like, how do I get my stuff indexed? And other people come to us, how do I get it un-indexed? BARRY SCHWARTZ: Yeah, well, you can't win, right? JOHN MUELLER: Always something to do. This is good.  

#### [0:37:30](https://www.youtube.com/watch?v=rO6wTSL6joE&t=2250) |  Yeah, I don't know. We'll see what

Martin comes up with. I know he's been in touch with the rendering and the indexing team on that. So it sounds like there is something, but I don't know how big of an issue it is. BARRY SCHWARTZ: It was just a weird response, because Martin is like, yeah, maybe there's an issue on our end. So he basically said, there is an issue on our end. So I mean, unless he just took a quick look and was like, maybe there is an issue, but wasn't sure.  

#### [0:38:00](https://www.youtube.com/watch?v=rO6wTSL6joE&t=2280) |  So if you could follow up with

Martin and have him tweet something out that would make for a good headline, that would be great. [LAUGHS] JOHN MUELLER: OK. Something that people can comment on, yeah. SANJIT CHAKRABORTTY: Yeah. JOHN MUELLER: I think that it's sometimes tricky with a lot of these JavaScript implementations, in that when you test them manually, it looks like things are working, or it can look like things are not working. But our indexing systems try to be a little bit more resilient and catch things that even the offhand testing  

#### [0:38:30](https://www.youtube.com/watch?v=rO6wTSL6joE&t=2310) |  tools don't notice. So it's sometimes a

bit tricky in that regard. But we'll see what comes out. BARRY SCHWARTZ: Yeah, I mean, I wrote about it, and then I put some weird long phrase in my comments area, waited 20 minutes, did a search for that weird long phrase, and you guys found it. So clearly, at least on my site, you seem to be indexing it well and fast. So if you could slow that down? [INAUDIBLE] slow me down.  

#### [0:39:00](https://www.youtube.com/watch?v=rO6wTSL6joE&t=2340) |  JOHN MUELLER: Yeah. I mean clearly, it's

a sign that your comments on your site are high-quality, and we need to take those up quickly, right? BARRY SCHWARTZ: Yes. [LAUGHING] JOHN MUELLER: OK. We'll see what happens there. Stay tuned. "Is it normal for the last crawl of a page to be the first time Google Bot has indexed it? I'm using React plus NextJS with server-side rendering, and I think there might be a problem for Google  

#### [0:39:30](https://www.youtube.com/watch?v=rO6wTSL6joE&t=2370) |  Bot in reaching my site. When I

request a recrawl, it gets a spike in impressions the first thing, and then it falls off. This happens for all pages. Am I missing something from a technical point of view?" I don't know if there's anything by default that's wrong in a case like this. It's something where just looking at the relevance or the visibility of a page in search,  

#### [0:40:00](https://www.youtube.com/watch?v=rO6wTSL6joE&t=2400) |  that can be kind of normal, in

that, when you publish something new, then suddenly, it's very relevant and new for everyone to be shown in search, and then, over time, that drops off. So that could be kind of normal. However, it sounds like you have some very specific technical kind of specifics that you're seeing there. And that feels like something where maybe it would be worthwhile to post some clear example URLs and maybe even some screenshots of what, exactly, you're seeing there with regards to the date  

#### [0:40:30](https://www.youtube.com/watch?v=rO6wTSL6joE&t=2430) |  of the crawling, or the last call,

or the first crawl of these pages. So just purely judging from the names that you're using there, with React, NextJS, server-side rendering, that seems totally unproblematic. But it's really hard to say what, exactly, we're seeing there. What I would recommend doing there is maybe posting in the Webmaster Help Forum if you think this is a general crawling, indexing  

#### [0:41:00](https://www.youtube.com/watch?v=rO6wTSL6joE&t=2460) |  type of confusion. If you think that

it's based on your JavaScript setup-- so maybe server-side rendering isn't working well, or we're doing client-side rendering for your pages for whatever reason-- then we have a special JavaScript Site and Search Working Group, which is a semi-private forum that you can just join, and you can ask your JavaScript sites-related questions there. That's something where we tend not to index that content from that.  

#### [0:41:30](https://www.youtube.com/watch?v=rO6wTSL6joE&t=2490) |  Well, I don't think we index it

at all from that forum. So it's a little bit more of a private area where you can discuss, things that are specific to JavaScript sites, just because we want to make sure that these kind of newer technologies are indexable reasonably well as well. "Posted in this Friday's Central Office Hours as well, but maybe we can get to it sooner. We're facing a strange issue with canonical selected by Google Bot. We have two pages that, from our point of view,  

#### [0:42:00](https://www.youtube.com/watch?v=rO6wTSL6joE&t=2520) |  have clearly distinct content, but Google Bot

sees one as a canonical for the other." And then the two URLs. "This affects all such similar pages, so weather for a specific location. We initially believe that this is because Google Bot was not reliably fetching the CSS and have since in-lined the critical CSS, but we're still facing the issue. Are we doing something clearly wrong that we've missed? Could this be because of a shared path  

#### [0:42:30](https://www.youtube.com/watch?v=rO6wTSL6joE&t=2550) |  in the URL structure?" I don't know.

I'd need to take a look at the specific setup. It's hard to say offhand. In general, I wouldn't assume that there is a CSS issue that would cause these pages to be as canonical. So I'm guessing, just from the URLs alone, that the content there is significantly different. So just purely not having access to the CSS  

![](https://i.ytimg.com/vi/rO6wTSL6joE/maxres3.jpg)



#### [0:43:00](https://www.youtube.com/watch?v=rO6wTSL6joE&t=2580) |  would not make us think that the

content is the same. And so just because of the CSS reasons, I don't think that would be a reason why we would think that these pages are the same. What I have seen in some situations, especially with sites, I'm guessing, like this, where you have a city name in the URL itself, is that sometimes, we see that you can specify any name as a city name, and we'll see essentially the same content. We won't get a 404 for cities that don't exist, for example.  

#### [0:43:30](https://www.youtube.com/watch?v=rO6wTSL6joE&t=2610) |  And in a case like that, we

might think that actually, this part of the path or the parameter that has a city name is irrelevant for this page, because we can enter random words there, and it leads us to the same content. And so that's something that we've sometimes seen there. Yeah? ANDREWS BLUMMEL: Just to add on that, basically, no, we do 404 [INAUDIBLE]  

#### [0:44:00](https://www.youtube.com/watch?v=rO6wTSL6joE&t=2640) |  that are not available. And what led

us to believe that this would be a CSS issue is when were doing live testing. In some instances, we saw a properly rendered page, and in some instances, we didn't. And when we were checking our logs on server side, we were actually not seeing any requests for the CSS from the Google Bot. And so this is what led us to believe that this might be a CSS issue. But anyhow, now, the critical CSS is delivered with the initial HTML, so it should load properly.  

#### [0:44:30](https://www.youtube.com/watch?v=rO6wTSL6joE&t=2670) |  And we still can't figure out how

to solve this. It's still-- the majority of our pages are marked as non-canonical. And so we've lost, basically, all of our traffic because of that. JOHN MUELLER: OK, and these are all city names, is it? ANDREWS BLUMMEL: Yeah, these are all-- basically, the idea of such a page is that we give you the weather for the specific location. So all of those are going to be city names. And basically, most of them are going to be in the region of Austria. JOHN MUELLER: OK. ANDREWS BLUMMEL: What I did find is a very similar challenge  

#### [0:45:00](https://www.youtube.com/watch?v=rO6wTSL6joE&t=2700) |  that Ikea posted here, where they are

also getting improperly selected canonicals. And they seem to have resolved the issue because you can still find things. But we've never seen any resolution, anything in the forums there. Some people have raised similar issues, but we couldn't figure out anything that solves it. JOHN MUELLER: OK. And you have the country or the language code in the URL  

#### [0:45:30](https://www.youtube.com/watch?v=rO6wTSL6joE&t=2730) |  as well, right? ANDREWS BLUMMEL: Yeah. JOHN

MUELLER: Do you have the same issue with other languages, or is it just German? ANDREWS BLUMMEL: It's actually just for German that we see this issues. And it's, weirdly enough, because we are differentiating between DE, which is our main language, and DE minus-- DE for German German. And this should be proper, actually, if you read the specifications. But it only affects the pages with the [? ULTE, ?] so far as we can tell.  

#### [0:46:00](https://www.youtube.com/watch?v=rO6wTSL6joE&t=2760) |  But it's a weird issue. JOHN MUELLER:

Do you have the same content in other languages, then? Or it's like, these are the only pages for Germany that you have there? ANDREWS BLUMMEL: But we've basically prepared ourselves to offer multi-language-- specifically in the Swiss region, for example. And that's why we also have this. But really, we are not utilizing it right now. So there's no different languages being offered for these pages. JOHN MUELLER: OK. I'll check with the team to see what might be happening there.  

#### [0:46:30](https://www.youtube.com/watch?v=rO6wTSL6joE&t=2790) |  It might be that our systems are

confused with regards to that URL path and somehow thought that maybe this path is irrelevant. But if that's the case, then that's usually something that we can resolve on our side. But I'll check. ANDREWS BLUMMEL: The weird thing is the canonical makes no sense. It's a news page, and the other one is a weather page. So it's very clearly distinct. JOHN MUELLER: Yeah. Usually, what happens in cases like that,  

#### [0:47:00](https://www.youtube.com/watch?v=rO6wTSL6joE&t=2820) |  where our systems get confused about this

kind of thing, is that we try to understand the URL structure. And it's not so much, at that point, any more what is actually shown on this URL, but rather it's like, our systems have determined this part of the path is irrelevant, so we don't even look at it. And then we say, to simplify things, we will fold it together as this canonical. So that's something where my guess is something like that is happening there.  

#### [0:47:30](https://www.youtube.com/watch?v=rO6wTSL6joE&t=2850) |  And maybe our systems picked that up

at some point when, maybe, it wasn't as clear within the website how these things were structured. But this is usually something that we can resolve on our side. So I'll check with the team. ANDREWS BLUMMEL: Thanks. JOHN MUELLER: Sure. All right, we're running low on time. Let me see. One last question in the list. And then we have it kind of complete, unless someone submitted something new.  

#### [0:48:00](https://www.youtube.com/watch?v=rO6wTSL6joE&t=2880) |  "What would you suggest as a better

solution for users and machines-- having a permanent redirect of all 404s via meta-refresh of five seconds to the home page so that users can find a search box and helpful links, such as popular stores and categories, or having a designated 404 page showing that the pages no longer exist, and helpful resources?" A real 404 page is always preferred. So if you remove content, serve us a 404 page, we can understand that the content is gone.  

#### [0:48:30](https://www.youtube.com/watch?v=rO6wTSL6joE&t=2910) |  We can reduce our crawling of those

URLs. It's completely fine. Redirecting people to the home page is confusing for users. It's confusing for us as well, because for us, we see that and say, oh, this looks like a soft 404. And so we will generally end up still crawling a little bit more, but still treating it as a 404. So you might as well just give us a clear 404 and make that 404 page user-friendly.  

#### [0:49:00](https://www.youtube.com/watch?v=rO6wTSL6joE&t=2940) |  All right, I'm sure there are some

more questions that got submitted along the way, but maybe we'll switch to live questions from you all. Is there anything that I can help with? RUCHIT PATEL: Hi, John. My name is Ruchit, and I posted on [INAUDIBLE] also, but I just joined later on. So we have an event website which has around 250 million events, and currently, we  

#### [0:49:30](https://www.youtube.com/watch?v=rO6wTSL6joE&t=2970) |  are facing a huge issue of [INAUDIBLE]

especially as we get around 250 million events. But most of the events are past, so it doesn't make sense for Google and for us, too. So we get most of the traffic on the 5% to 10% events which are upcoming events. So we want to re-index all these past events. But what we are seeing-- for that, we added no-index tag in the pages. But what is happening, every day, we  

#### [0:50:00](https://www.youtube.com/watch?v=rO6wTSL6joE&t=3000) |  are seeing that Google is crawling 3

to 4 million pages, and most of them are past event pages. So our upcoming events are taking a longer time to get indexed, it's like, how to index these pages faster, so we don't have to wait for Google to crawl all of these 200 million events pages and then the [INAUDIBLE]? JOHN MUELLER: OK, so I think there  

#### [0:50:30](https://www.youtube.com/watch?v=rO6wTSL6joE&t=3030) |  are two things you can do. On

the one hand, there is the unavailable_after meta tag that you can use, which tells us ahead of time when this page will no longer be available, or when it will be irrelevant. So that's something you can use going forward. If you have an event that takes place at some point, you can say unavailable_after maybe, I don't know, a month later, or whatever you decide. That helps us to understand that these pages are going to go away fairly soon and to help us focus  

#### [0:51:00](https://www.youtube.com/watch?v=rO6wTSL6joE&t=3060) |  our crawling on other ones. And the

other part is if you just relatively recently added the no-index to the old events, then that's something we just have to process. And that can take a bit of time. I wouldn't worry so much about it, because usually, this kind of refresh crawling that we do is something that is usually lower priority within our systems.  

#### [0:51:30](https://www.youtube.com/watch?v=rO6wTSL6joE&t=3090) |  So we do try to prioritize the

crawling of new pages that we discover on your website, and if we recognize we still have room to re-crawl old pages, we will re-crawl the old pages as well. From an absolute numbers point of view, it can look like we're crawling 10% of the new pages and we're crawling, like, 90% of the URLs are really old pages. But that's essentially just because the 10% crawls from the new pages, we think, are the important parts that we should  

#### [0:52:00](https://www.youtube.com/watch?v=rO6wTSL6joE&t=3120) |  be picking up for indexing. So I

would try to let this settle down over the course of maybe, I don't know, half a year or a year. And I assume that at that point, we will be able to focus a lot more on the newer pages, and we'll have recognized that the old ones are really gone in the meantime. But even when we've recognized that they're gone, because you have so many of these old pages, we will still occasionally try them. So if you look at the absolute numbers in your server logs  

#### [0:52:30](https://www.youtube.com/watch?v=rO6wTSL6joE&t=3150) |  later on, you will probably still see

that we crawled a lot of old pages. But again, that's not because we think these are important pages, but rather just because we know they exist, and we just want to double-check. Another thing you can do to make sure that it's clear to us which pages we should be crawling is to have a clear internal site structure in that regard, in that maybe you take the really old events and you move them into an archive section of your website that isn't linked so prominently within your website,  

#### [0:53:00](https://www.youtube.com/watch?v=rO6wTSL6joE&t=3180) |  and you really prominently focus your internal

linking on the new events that are upcoming. So make it as clear as possible when we crawl your website, this is what you want us to focus on, and, oh, I also have all of these other old ones here. It's like, you can find your way there, but it's not the most visible part of the website. RUCHIT PATEL: Thanks, John. That helps. JOHN MUELLER: Sure. BARRY SCHWARTZ: John, can talk about updates?  

#### [0:53:30](https://www.youtube.com/watch?v=rO6wTSL6joE&t=3210) |  Or I haven't [INAUDIBLE] in 2 and

1/2 years, since the [INAUDIBLE] update. JOHN MUELLER: I don't know. BARRY SCHWARTZ: Could you name what's going on this week, the past couple of weeks-- June 10, June 18, today? Lots of little fluctuations. JOHN MUELLER: I have no idea. BARRY SCHWARTZ: Can we call it something? JOHN MUELLER: I have no idea what you're referring to. I'm sorry-- I, um-- BARRY SCHWARTZ: [INAUDIBLE] JOHN MUELLER: I don't think we have a core update at the moment. BARRY SCHWARTZ: Right. Nothing was confirmed.  

#### [0:54:00](https://www.youtube.com/watch?v=rO6wTSL6joE&t=3240) |  Danny didn't tweet anything. You're not aware

of any tweaks. It seems to be a lot of fluctuation is going on. I know Google's always fluctuating, constant changes, yada, yada, yada, but no idea. JOHN MUELLER: I don't think it's-- I mean, I don't know. There are always things happening within Google, so it is really hard to say. But I'm not aware of anything specific where it's like, oh, we're doing something crazy here, and people might see this kind of thing. My guess is these are just the normal things that  

#### [0:54:30](https://www.youtube.com/watch?v=rO6wTSL6joE&t=3270) |  are happening. BARRY SCHWARTZ: OK, last chance.

No chance-- you don't want to name it? [LAUGHS] JOHN MUELLER: I don't even know what I'm naming. Is this a good thing or a bad thing? So it's not-- BARRY SCHWARTZ: No! JOHN MUELLER: I didn't see a lot of stuff on Twitter where people were saying changes. So OK. I guess I'll watch out for your blog and see what you say. [LAUGHS] I really don't know.  

#### [0:55:00](https://www.youtube.com/watch?v=rO6wTSL6joE&t=3300) |  BARRY SCHWARTZ: OK. DAVE SMART: Hey, John.

Can I ask bit of a follow-up question to what we were speaking about earlier? About you can look through URL structures and see [INAUDIBLE] go for there there. So would that mean that something that has quite a flat URL structure might be at a bit of a advantage in that respect?  

#### [0:55:30](https://www.youtube.com/watch?v=rO6wTSL6joE&t=3330) |  JOHN MUELLER: I think we would probably

still be able to figure out parts of a URL like that. But if you have an extreme case where you have no folders at all, then it does make it a little bit trickier for us to understand which parts are really relevant or not. So for example, compared to something where you clear URL parameters, where you have city name equals this and language equals that, then it's a lot easier for us to understand,  

#### [0:56:00](https://www.youtube.com/watch?v=rO6wTSL6joE&t=3360) |  oh, this parameter here varies and changes

the content. Whereas, if it's a really flat structure where you just have dashes in between all of the parts, then it's really hard for us to understand what happens when individual parts are different or don't exist. With parameters, we can drop them and see what happens, if they still serve content or not. DAVE SMART: Thank you.  

#### [0:56:30](https://www.youtube.com/watch?v=rO6wTSL6joE&t=3390) |  JOHN MUELLER: Cool. OK, so maybe we

can take a break here. And I have the next one in English lined up on Friday. So if there's anything still on your mind, feel free to drop your questions in there. I'll see if I can figure out something about updates that are happening. I don't know if there is anything explicit we'd be able to announce, but who knows? Always something new and surprising. And we'll see what happens with all of those Disqus comments, if suddenly there is a giant surge of indexing  

#### [0:57:00](https://www.youtube.com/watch?v=rO6wTSL6joE&t=3420) |  of comments on the web. We'll see.

All right. Thanks, everyone, for joining in, and I hope you found this useful. And hopefully, see you all again in one of the future Hangouts. Bye, everyone. RUCHIT PATEL: Thanks, John. Bye.  