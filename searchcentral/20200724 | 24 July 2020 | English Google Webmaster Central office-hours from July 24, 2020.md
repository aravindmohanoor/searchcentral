[![English Google Webmaster Central office-hours from July 24, 2020](https://i.ytimg.com/vi/_UGEeGlKQ2o/hqdefault.jpg)](https://www.youtube.com/watch?v=_UGEeGlKQ2o)

## English Google Webmaster Central office-hours from July 24, 2020

This is a recording of the Google Webmaster Central office-hours hangout from July 24, 2020. These sessions are open to anything webmaster related like crawling, indexing, mobile sites, internationalization, duplicate content, Sitemaps, Search Console, pagination, duplicate content, multi-lingual/multi-regional sites, etc. 



Watch out for new sessions, and add your questions at https://www.youtube.com/user/GoogleWebmasterHelp/community



Feel free to join us - we welcome webmasters of all levels!



#### [0:00:00](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=0) |  JOHN MUELLER: All right, welcome, everyone, to

today's Webmaster Central office-hours Hangouts. My name is John Mueller. I am a webmaster trends analyst at Google in Switzerland. And part of what we do are these office-hour Hangouts, where people can join in and ask their questions around their websites and web search. Bunch of stuff was submitted already. We'll try to go through as much as that as possible. But if any of you want to get started with a question, you're welcome to jump on in now.  

#### [0:00:30](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=30) |  AUDIENCE: Hi, John. JOHN MUELLER: Hi. AUDIENCE:

I have two questions today. So the first one is about the chart. So our client did run some sort of survey to get information from the user. And they write blog content based on the survey. Now, the question is, how we can add these-- how can add chart with a blog post? Should we add the image, or should we add some sort of code  

#### [0:01:00](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=60) |  to show the chart? Which one is

better? JOHN MUELLER: I think it depends a bit on what you want to achieve with the chart. Usually these kind of things, I would just add as an image and make sure that you have an understandable alt attribute for the image as well. So if there is any critical information in that chart that you need to get across, then put it in the alt attribute so that we can pick it up as text, so that people who can't see the image can also get that information.  

#### [0:01:30](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=90) |  But in general, I would just let

them get [INAUDIBLE] images. I think, usually, these kind of charts are not going to do something fantastic in image search because it's hard to imagine that someone is looking for that particular chart using Google images. But essentially, in images is probably the best approach there. I don't think you would get a lot of value out of making that chart into HTML  

#### [0:02:00](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=120) |  and putting the numbers and the labels

into text because that's something that you can just as easily put in in the body of the blog post, in the alt attribute as well. AUDIENCE: OK. And the next question is about infographics in image. Now, infographics will be different from the image. Now, how Google can understand, this one is just a simple image and this one is infographics? How can Google understand this thing? JOHN MUELLER: I don't think we need  

#### [0:02:30](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=150) |  to understand the difference, or why should

we need to understand the difference? Because it's-- for us, an image is an image. We can pull out some information from an image. If there is text in the image we can try to understand that. But essentially, if it's an image, if you're putting [INAUDIBLE] information into an image, then that's something that's primarily an image and not primarily text.  

#### [0:03:00](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=180) |  So if you're doing something like an

infographic, like a really long thing, I'd recommend making sure that you have the text or the bulk of the text in there in some kind of a blog post or in kind of other textual format as well. AUDIENCE: OK. Thanks, John. JOHN MUELLER: Sure. AUDIENCE: Oh, hello, John. JOHN MUELLER: Hi. AUDIENCE: Hi. My question is regarding content scrapping, which is also a quality guideline from Google.  

#### [0:03:30](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=210) |  So the thing is, we have a

website where we cover mobile games that go on Google Play Store. And we write about those games. We use-- we write original content about the game, like what is the storyline, gameplay, and all the characters about the game. But we have a competitor who just blatantly copies everything from Google Play Store, but [INAUDIBLE] better than us. So what can we do to improve our rankings  

#### [0:04:00](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=240) |  in this kind of situation? Like, we

are doing everything original, and they're just copying from Google Play Store. JOHN MUELLER: Oh. I think sometimes that's frustrating, but , essentially the important part to keep in mind is that we use a lot of factors when it comes to ranking. So what I've sometimes seen is that one side will do a lot of things really well and then some individual things really badly, and they'll still perform fairly well, because overall, we look at that and say, well, lots of good  

#### [0:04:30](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=270) |  signals here too. So as a competitor

in a situation like that, I would recommend making sure that you're focusing on all of those signals as well, then trying to find ways to improve your site overall, not just specifically with regards to the content. For example, what-- I don't know your site. So I'm just making up a situation. What could happen is you have really good textual content, but you embed it on [INAUDIBLE] So that's where--  

#### [0:05:00](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=300) |  take a step back, and instead of

just focusing on the text, try to really think about your whole website overall. AUDIENCE: Oh, well, we do consider all these points. And I think we have good visibility of the website. We have good number of backlinks compared to them. Site looks good and load fast. Everything is good.  

#### [0:05:30](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=330) |  It's just the content part that I

believe we are lagging behind because they just copy it, and they're just doing better. Still not able to figure out the exact reason why they're ahead of us. I don't know if it's [INAUDIBLE].. JOHN MUELLER: Yeah, usually, in these kind of situations, not that there's one thing that they're doing that is the reason they're ranking better, and you can just copy that and do that as well. It's really a combination of different things.  

#### [0:06:00](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=360) |  So that's something where I'd really be

cautious about just saying, well, on this page, we have better content than this other page. But really try to take a step back and look at your website overall. Maybe there are other parts of your website that are more problematic and try to find ways to improve all of that. And that's not something that happens-- like you fix the HTML code today, and then tomorrow, everything is perfect. That takes a long time, sometimes,  

#### [0:06:30](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=390) |  to really improve overall. AUDIENCE: Sure, sure,

thank you. JOHN MUELLER: Sure. All right. Let me run through some of the submitted questions because I think last time we barely got through any of them. Let's see. The first one, I don't know what I can say here. Would you confirm if Google is making any changes to the search results, because I'm seeing ranking loss and big fluctuations in existing rankings  

#### [0:07:00](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=420) |  for my Australia-based website? So we make

changes all the time. So from that point of view, I can pretty much confirm that we have made changes in the search results. So I don't think that's really useful in that sense because, like, if you're making changes all the time, why am I seeing changes now? But rather, that's something where I would generally recommend--  

#### [0:07:30](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=450) |  obviously, recognizing these kind of situations is

a good first step. But also letting it settle down, seeing what happens in the end, checking in with other webmasters of [INAUDIBLE] sites to see what kind of changes maybe they're seeing as well. And then think about, on the one hand, what you can do to improve your site's overall so that they're a little bit more stable and not reliant on this one particular factor that you  

#### [0:08:00](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=480) |  happen to be working on. And on

the other hand, maybe looking at the search results where you've been seeing changes and thinking about how all of that could fit together. So in that regard, I don't really have this one answer that's like, well, you're seeing changes in search, therefore you should pull the handbrake on your website and everything will stand still. That doesn't happen. These changes in search are things that we do to try to improve the search results.  

#### [0:08:30](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=510) |  So sometimes we do get it wrong,

but a lot of times, I think we head in the right direction. And it's worthwhile to find ways that you can improve your website and keep up with how the web is improving overall. Google has stated that deep linking to an app has positive ranking effects to the associated website it's being linked from. Is this accurate today? So I don't know if there's really  

#### [0:09:00](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=540) |  a positive ranking effect on the website

that you will get just from linking to an app. That feels like a stretch. I'm not sure where exactly that's coming from. And the question is, is this still accurate today, provided I'm doing all the right things to make my site indexable and providing authoritative content that users can trust? What sort of a lift should I expect? Yeah, like I said, I don't think this is something that we do today because essentially, you  

#### [0:09:30](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=570) |  can link to all kinds [INAUDIBLE] content.

And just because you're linking to that content doesn't mean that your website is better. This is-- for example, if you take it to web pages, something that people have been doing since the beginning, where they will publish something low quality or spammy, and they'll link to Wikipedia and CNN and Google and say, well, look at all of these authoritative web sites I'm linking to. You should trust my content. And just because you're linking to something good  

#### [0:10:00](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=600) |  doesn't mean that your content is good.

Obviously, sometimes links do provide extra value to your content, but there's no kind of magical effect from just linking to some things that are also good. Would you advise utilizing a reverse proxy server for moving from a subdomain to a subfolder structure? Any risk or considerations that shouldn't be overlooked?  

#### [0:10:30](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=630) |  So in general, if you're changing the

structure of your website, I would recommend just setting up redirects and doing it the normal way. Setting up some kind of a reverse proxy-- in my opinion, for something basic like this, seems like a lot of extra work with a lot of moving parts that can break. So I recommend setting up the redirect. Whenever you're changing the site structure, you will see some fluctuations in search for a while,  

#### [0:11:00](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=660) |  but that's something where it'll settle down.

And we have a lot of practice with redirects. So usually, that should work out well. I think, especially in the beginning, there is some situations where maybe setting up a reverse proxy makes sense, where if we really can't crawl your content properly, or if you have a really kind of complicated infrastructure that you need to hide from users and hide from search engines,  

#### [0:11:30](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=690) |  then maybe setting up a kind of

a reverse proxy to map your complicated URLs to cleaner URLs, maybe that could make sense. But for the most part, site moves like this, site structure changes, that's something where I wouldn't bother with all of this extra machinery to hide those changes. I've seen several WordPress sites get hacked, resulting in a warning being displayed in the search results. If a reverse proxy was used and this warning was present,  

#### [0:12:00](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=720) |  would the warning extend to the rest

of the domain, or would it only pertain to the pages that are hosted on the WordPress CMS? I don't know how broad that kind of setup would be. So I think what you're kind of saying is, you would have your WordPress site in a subdirectory or something like that on a main domain,  

#### [0:12:30](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=750) |  and would this warning affect the rest

of the domain? I don't know. It depends a bit on how easily we can recognize which part of the site is running WordPress. And I mean, the ideal situation is not so much to kind of mitigate the risk that when you get hacked, that Google only shows that for part of your website, but rather that you try not to get hacked or that if you do get hacked, that you fix this as quickly as possible.  

#### [0:13:00](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=780) |  So I think investing a lot of

time and energy into setting up a special configuration where that hack warning will only be visible to the small part of your site seems like time and energy that you could be spending to make sure that your website doesn't get hacked at all. In Search Console, the perform-- in Search Performance, when I filter a query, that report's giving me certain stats. Then when I add a country filter, plus the same query, I get totally different stat.  

#### [0:13:30](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=810) |  I get a higher number of clicks

than before. How can I get fewer clicks if I don't filter a specific country? I don't know. It'd be useful to look at some examples. If you could send me some examples, I'd be happy to take a look at that with the team. Sometimes what happens there is, depending on the way that the filtering happens in the back-end with regards to how much data we have for individual parts of the site  

![](https://i.ytimg.com/vi/_UGEeGlKQ2o/hq1.jpg)



#### [0:14:00](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=840) |  and how kind of the sampling of

that data happens overall. In practice, what you can usually rely on is that the higher number that we show in Search Console is the more correct one. So maybe that helps, maybe that makes things more confusing. If you have some specific examples, I'd be happy to take a look. One of the typical CEO suggestions is to avoid Google to index poor content pages.  

#### [0:14:30](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=870) |  Typically, user profile pages are like that.

Maybe just username and a couple information. The question is, is it better to put no index on profile pages to avoid Google seeing those less valuable pages? You can do that if you want to. In general, I wouldn't say that all profile pages are bad. But it's something that we do sometimes see that either spammers use profile pages  

#### [0:15:00](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=900) |  as a way of placing the links

or placing some specific content that they're trying to rank for. Other times, the profile pages are just with basic information and not very useful. If it's just a matter of basic information and not very useful, I generally don't think that's something you need to put a no-index on because what happens in practice is we will look at your website overall, and we'll try to determine which parts of your website are important for search. And those are the parts that we will focus on.  

#### [0:15:30](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=930) |  So even if you have parts of

your website that are less useful, l like maybe some of these profile pages, we will still try to focus on the things that we think are useful and relevant to show in search. So it's not that those less complete profile pages would be pulling your website down. The one time where it would probably make sense to do something here is if it's a really gigantic website, and you have tons and tons of these kind of emptier  

#### [0:16:00](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=960) |  pages on your website. And that makes

it really hard for us to crawl and index the website. So in particular, if you have several million pages, and of those, maybe 80% are these more empty profile pages, we would spend a lot of time focusing on these empty profile pages before we recognize that, actually, they're not so important for your website. We could be spending our time somewhere else. So from that point of view, I wouldn't blanketly  

#### [0:16:30](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=990) |  say you always need to put no-index

on your profile pages. I would look for things like spam. If people are abusing those profile pages, clean that up. If the number, absolute number of those profile pages is kind of in a reasonable range, and they're not showing visibly in search, then I wouldn't really worry about that. Do you think a 301 redirect chain of multiple redirects rules pileups can hurt a website--  

#### [0:17:00](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=1020) |  for example, http://example.com to www.example.com to https://example.com.

Is that something critical to look at, or is it just us who are noticing those paths, but search engines and users are experiencing the final URL? Yeah, for the most part, we focus on the final URL. So that's something where, depending on how you have your website set up, you commonly have this kind of chain redirect set up,  

#### [0:17:30](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=1050) |  where you redirect incrementally closer to the

URL that you actually want. And that's perfectly fine. The one thing that can sometimes happen is if we find kind of the ancient URL at some point, and that's the only thing we know about your website, then what Google bot will do is follow five redirect steps. And then in the next day, follow the next line. But once we've recognized where your final URLs are,  

#### [0:18:00](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=1080) |  then we'll focus on those final URLs.

It's not that we'll follow that redirect train every time we try to crawl. So that's something that I've seen tools sometimes flag and say, it's OK. If you look at this obscure URL, you'll find seven redirects in a chain, and your website will disappear in search if you have seven instead of five. And that's definitely not the case. So what I would do in a general situation like this  

#### [0:18:30](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=1110) |  is try to double check that when

users are using your website, they're using the final URLs, that you're not constantly redirecting between your URLs. And if you have multiple your URLs-- redirect setup like this, and this is just kind of legacy changes that have been happening over time, I wouldn't worry about it. If it's something that people see all the time-- if you look at your server logs, and you see that these redirect chains are being used regularly, then  

#### [0:19:00](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=1140) |  I would try to figure out how

you can link to the final URL, rather than to the initially redirecting URL. But the redirect chain itself, that's not something that I would really worry about. Our company is in the process of merging and rebranding two domains. Let's see-- site one and site two both have unique content. They cover similar topics. One is our flagship site with more value.  

#### [0:19:30](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=1170) |  The new domain, we required that for

the merge and rebrand just happens to be the .com version of site two. So we want to use that. But since site one is more important, we want to first redirect site one to site two and then redirect site two .org to site two .com at a later date. Would this be problematic for the search? Would Google penalize the site, since this could be confusing signal to users? So we definitely wouldn't penalize sites like that.  

#### [0:20:00](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=1200) |  That's something where, definitely from a webspam

point of view, this is a non-issue. This is kind of a technical issue that we need to figure out, but it's not something we would consider to be abuse. So make maybe kind of that worry off first. That doesn't mean that you won't see any fluctuations with changes like this. So that's a kind of a different question.  

#### [0:20:30](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=1230) |  In general, moving from one domain to

another is something that we have a lot of practice with. If you're just moving one-to-one, all of the URLs from one domain to another, I would expect that to just work out. Maybe you'll see some fluctuations for a couple of days, maybe a week or so. But usually, that should settle down fairly quickly. On the other hand, if you're merging things-- so in particular, if you move site one to site two, and site two already had some content,  

#### [0:21:00](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=1260) |  then you're merging things. In cases like

that, it does take significantly longer to kind of settle down. In this case, I don't know if the final site already has content or not, if you're merging things into that. But what I would generally do is try to separate out the individual steps so that you can easier recognize where things have gone wrong or where something might have happened that you need to double check.  

#### [0:21:30](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=1290) |  So a common scenario is you do

kind of this moving from one domain to another, and at the same time, you change your CNS, and you change your URL structure, or you change your-- the layout of your pages. And if you do all of that at the same time, and something goes wrong in search, then figuring out why that happened in search is going to be really hard, whereas if you do it incrementally, and you recognize, oh, when I changed my URL structure,  

#### [0:22:00](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=1320) |  things went wrong, therefore, as a next

step, I need to figure out what in my URL structure is different compared to before. And maybe I can improve things, maybe I need to roll the URL structure back, whatever. But by being able to separate out those individual parts, it makes it a lot easier to figure out what you need to change. So that would generally be my recommendation there. I wouldn't worry so much about the unique content  

#### [0:22:30](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=1350) |  part or similar topics or all of

those things. But from our point of view, it's really more a matter of, are you merging things, or are you just moving things? A question about pop-under ads. My site started ranking, and I have this pop-under ads on it. It only opens up once in 24 hours. Can this affect my ranking on Google? I don't want my rankings to drop. I don't think anyone wants their rankings to drop.  

#### [0:23:00](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=1380) |  I don't know what specifically you're showing

with the pop-under ads. In practice, we do take a variety of signals into account when it comes to understanding the quality of a page. And we look at things like if the top part of the page is visible or not. And pop-under ads feels like. I don't know how exactly you're implementing it. But if you're like, opening a window behind an existing  

#### [0:23:30](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=1410) |  window, that feels like a really old

technique that I don't know if browsers even support that that well anymore. So that's something where, from my point of view, I would look more into the usability side of that and figure out, like, why are you doing this? And what is your goal? Does it actually work for you? And then as a second step, figure out if this is really useful for your users  

#### [0:24:00](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=1440) |  and useful for your site, how might

that affect search? We have a question about mobile usability. It's data that we have clickable elements to close and content [? widen ?] on screen on some pages. We tried a lot of ways, like improving the font size, adding padding and margin for clickable elements to improve these issues, but none of the work. The actual problem is Google Search Console doesn't show us where exactly the problem occurred  

#### [0:24:30](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=1470) |  on which clickable elements. It's also interesting

that when we use a test live page on Google Search Console, we don't get any errors with the same pages. OK, so what I would suggest doing there is if the bulk of your pages don't have this message, and if the live test doesn't have this message, then I would just ignore that warning. What might be happening is that individual times  

#### [0:25:00](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=1500) |  when we tried to render those pages

to see how the text on those pages works, that maybe we're not able to process the CSS for those individual pages. And then we flag that, like this in Search Console. So that's something where, if the live test says it's OK then I would trust the live test. I have a question about nofollow versus no href  

#### [0:25:30](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=1530) |  on internal linking. OK, I don't want

Google to relate our menu links on all types of category pages. What would you suggest here? Remove the href from the menu links, add nofollow to the menu links, disallow the menu container. So generally speaking, you don't need to hide things that are-- I mean, I don't know your specific site set-up.  

#### [0:26:00](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=1560) |  But in general, you wouldn't need to

hide links on a site like that because if it's something that you don't want to have index, then I would put a no-index on the destination page. It's generally not something that you need to kind of prevent from being crawled. If you do kind of want to avoid forwarding signals internally, then using a nofollow there is fine. Using a disallow on a menu container,  

#### [0:26:30](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=1590) |  I don't think that would necessarily work

in most cases. So that would mean that you'd have to have your menu as a separate HTML file that is loaded in iframe on a page kind of thing. And that's a really complicated site structure setup. That's something that I haven't seen in a really long time. But if you really just don't want to forward any signals to those links, I would use nofollow.  

#### [0:27:00](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=1620) |  But for the most part, you probably

don't need to do anything special here. Question about PageSpeed Insights. Why does a Google AdSense script cause poor PageSpeed Insights' performance. It's loaded async, but Google marks the ads by Google as a problem with these errors. It's weird because Google suggests don't use Google AdSense. It's bad. It slows down your pages.  

#### [0:27:30](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=1650) |  So I don't know about that specific

snippet of text. But in general, our speed testing tools are agnostic to the kind of markup and scripts that you add to your pages. So it's not going to be the case that our speed testing tools will say, oh, this ad script is perfectly fine because it's made by us, even if it's really slow. So if our speed testing tools say that a particular element is slowing down your page,  

![](https://i.ytimg.com/vi/_UGEeGlKQ2o/hq2.jpg)



#### [0:28:00](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=1680) |  and that particular element happens to come

from Google at some point, then essentially you have a page is a bit slower. Users don't care where that ad is coming from or where the slowness is coming from, they just care that a page is slow. So that's something kind of off the side. With regards to why the Google ad script is making your pages slow, I don't-- that's something where I would check in with the AdSense folks  

#### [0:28:30](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=1710) |  to see what other options you have

where you might be able to implement those ads in a way that don't slow down your site. Or maybe there are ways that you can implement the ads on your site in a way that doesn't directly affect the page speed. For example, if you have those ads further down on the page, then maybe the largest [INAUDIBLE],, the first meaningful page, all of those metrics  

#### [0:29:00](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=1740) |  are actually OK because the slower part

is loaded after the first page view. So those are kind of a few elements there. The other thing to keep in mind is that, in particular, the PageSpeed Insight score is not like a magic number that you have to improve and get to 100%. It's a combination of different speed factors, and it's meant to help you to figure out where your weak points are with your website.  

#### [0:29:30](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=1770) |  So that's something where if you add

a script to your page, and it goes down from 98 to 95, then probably that's still OK. But it's worthwhile to figure out, especially if you see really big changes with regards to those speed scripts. In the future, we plan on using the Core Web rather than just the PageSpeed Insight score. The Core Web Vitals are also, I believe, shown in PageSpeed Insights now, but separately.  

#### [0:30:00](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=1800) |  So I would take a look at

that to see how maybe this particular script affects the Core Web Vitals. And also check in with the AdSense folks to see if there are ways that you can implement things that still work really fast for your site. I noticed my site ranking suddenly dropped around May 2020, and I noticed all my ranking post was not ranking anymore. I don't know what's wrong with my ranking. I don't know.  

#### [0:30:30](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=1830) |  Like, that's a very vague question and

a very broad timeline. So it's really hard to say. What I would recommend doing here is maybe posting in the Webmaster Help Forum and including your URL, including the queries, where you've been seeing changes, and the pages on your website that you think should be ranking a little bit better for those queries, and trying to kind of talk with other people who've run into similar problems to figure out what you could be  

#### [0:31:00](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=1860) |  doing to improve things there. What I

have sometimes seen is that sites will look at metrics like the total impressions or the total clicks through the site and not consider the individual queries and the conversion on those queries. If those queries were really-- like, queries where your site is particularly relevant for. So for example, I have seen situations where a site will write an article  

#### [0:31:30](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=1890) |  about how to log in to Gmail.

And if that article happens to rank for a query like Gmail, then you would get a lot of traffic there. And when our algorithms figure out, well, actually this is not really the best thing to show for this query, then you will see a big drop in traffic. And if you just look at the absolute numbers there, then it'll look like something really big is happening to your website. But it's actually just that one query. And if you step back, then you might notice, well, maybe my site isn't really the best one to rank  

#### [0:32:00](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=1920) |  for that particular query. I made several

tests to find out that my high CLS and LCP are coming from AdSense ads. Oh my gosh, more of these. So other than removing those ads, can you give [INAUDIBLE] how to solve the problem? Or to fix a guideline from Google AdSense would also be nice. So again, we're not going to change our guidelines just  

#### [0:32:30](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=1950) |  because products from Google are also sometimes

slow, but rather, we encourage the web to find ways to improve their speed overall. If you're seeing issues around specific Google products, then I would go in those Google product forums and really work with folks there to help improve that. And I'm happy to help out if there's anything I can do there. But in general, we don't know all the teams at Google.  

#### [0:33:00](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=1980) |  And we can't give them confidential information

on how to magically make things faster. They have to do the normal things, as any other provider would need to do. So that's something where I primarily try to work with the product teams that you're trying to integrate there. Is crowding Google search results with multiple domains from the same company, selling the same product, against the webmaster  

#### [0:33:30](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=2010) |  guidelines? Our business is being pushed down

page one results for thousands of keywords, and we want to know how to deal with it. It's something that I think our algorithms do sometimes struggle with. A lot of times, I think we get it right. And every now and then, something will pop up where suddenly there are lots of different TLDs from this one site that are showing up in the search results. And that's something we do try to work on.  

#### [0:34:00](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=2040) |  So it's not so much like, is

it against the webmaster guidelines or not? But rather, our algorithms sometimes struggle to get the right balance there. Showing multiple results from the same website is perfectly fine. We try to-- generally try to limit that to maybe one or two results per website. But for individual queries, it might make sense to show a lot more. And there is no magic number that we would say, this is the total number of results  

#### [0:34:30](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=2070) |  we would show from one website or

one business in the search results. So that's something also worth kind of keeping in mind there. The other thing is-- the one area where it does kind of touch up on the webmaster guidelines is if you're doing something like creating doorway sites or creating doorway pages. If you're creating significant duplication with all of the same content and just tweaking things  

#### [0:35:00](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=2100) |  by putting it on different domain names,

then that is something where the web spam team might take action if they find that. Using the web spam report form is a good way to kind of bring that up on our side. But also keep in mind that the web spam report form is something that we use to improve our algorithms. It's not something where the web team will take that input and one-to-one do a manual action on it. Two questions, does Google index image metadata?  

#### [0:35:30](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=2130) |  If yes, does it influence ranking? We

do pick up some image metadata. And I believe it's primarily used for things like understanding the image license and the copyright information. It's not really a ranking factor, but it's something that we do sometimes show in Google images. When people are seeing kind of this preview of an image, we can sometimes show the metadata from the image there. So not a ranking factor, but always a good thing to have,  

#### [0:36:00](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=2160) |  especially if you have information about the

licensing or kind of copyright information that you want to provide. There's Google-indexed metadata in MP3 and other audio formats. Does that influence ranking? I don't think so, but I don't know for sure. I think the tricky part there is I don't think we actually index MP3s at all. So we would-- we would probably be able to pick those up  

#### [0:36:30](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=2190) |  as videos sometimes, depending on how you're

embedding those on the page. But otherwise, I don't think we would individually index MP3s separately. So that's more a matter of providing information on the landing pages where you're linking to those MP3s. And obviously, information online is text, and we can use that for ranking. How many internal links should we use on a page?  

#### [0:37:00](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=2220) |  Let's say there's one in the menu

and one in text. What is the best approach? Will it lose link value if the same internal link is used multiple times? Use as many internal links as you want. So that's kind of the guideline. It's not that there is any magic number that you need to focus on or with regards to using the same link multiple times. That's all generally fine. The one thing I would watch out for  

#### [0:37:30](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=2250) |  is more that your site has kind

of a clear structure, in that when we crawl your website, that we can understand which pages are related to each other, which pages are kind of equally important, and which pages are kind of subpages of existing pages so that we can understand the context of your pages a little bit better. So one thing that SEOs sometimes like to do, especially when they first get a hold of a crawling tool, is to create a really flat structure, where  

#### [0:38:00](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=2280) |  all pages link to all pages. You

just have to know one URL, and then you know all URLs of the website, like if you crawl the site as just one long line, where all pages are equally important. And from our point of view, that's not really that useful because we don't understand how the relationship is between these pages. From kind of a pure crawler point of view, it looks like, oh, all the pages are on level one, or however you count that. But that's not necessarily good.  

#### [0:38:30](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=2310) |  It's usually better to have kind of

a balanced structure where you have some category pages, maybe some subcategory pages for the individual categories, the detail pages further down below so that we can understand what the relationship is between those pages. And with regards to internal links, that essentially maps back to that. So if you have links from your category page to your subcategories of that category, and from there, to the individual products,  

#### [0:39:00](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=2340) |  then that's a nice structure to have.

It's not that you need to put all of your sites links into all of your pages. OK, let's see. We still got some time. There's one longer question about a specific site. I'll just skip that one to now because it seems like something more complicated to look at. I notice these spammy sites are linking to my pages.  

#### [0:39:30](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=2370) |  I sent them an email to stop,

but they didn't. I disallow them. I don't want them to affect my ranking because I didn't put them. Some pages are linking to my pages around 20 times with some weird author. Is this about the only thing I can do here? Disavow's perfect. For these kind of situations, if you really want to make sure that Google's algorithms do not take this into account at all, disavow is perfectly fine. In practice, you probably don't need to disavow.  

#### [0:40:00](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=2400) |  If these are really spammy pages, if

these are just kind of like links on random pages of the web, then that's something we'd probably ignore already. It's not something that you would need to disavow. But if you're worried about this, worried enough to actually send them an email, and it's like you really don't want them to be taken into account, then the disavow tool will do that for you.  

#### [0:40:30](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=2430) |  Structured data questions on a new site.

FAQ page, structured data. Is it OK to markup main content landing page containing FAQs with FAQ schema, rather than create a separate FAQ page strictly for FAQs' link to each other. From a user point of view, we think it would be better on the site to have all the FAQs listed on the main content landing page. Our landing page will have an accordion-style index on top, with hashes to jump out to the FAQ content for ease of access.  

#### [0:41:00](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=2460) |  [INAUDIBLE] speaking, you can do that. I

don't know if it really makes sense for your users, but that's kind of a question between you and your users. It's less a matter of, like, can you do it or not? The important part with kind of FAQ content and structured data, [? reach ?] results in general is that we expect this content to be visible on the page. So if you're hiding the whole block of FAQs, that would be problematic.  

#### [0:41:30](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=2490) |  If you're showing the questions on the

page, and if you click on the questions, then it expands and shows the answer, that would be fine. Video structured data, same landing page as above. We have multiple videos listed in carousels. Better to have individual pages for these videos and add supporting content on the page-- if so, how to mark up the videos on the landing page in point Google, via markup, to authoritative best content page containing the best amount of useful metadata and schema  

![](https://i.ytimg.com/vi/_UGEeGlKQ2o/hq3.jpg)



#### [0:42:00](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=2520) |  data. So the best amount of metadata

and information on a page is not something that you can really quantify. You have to kind of use trial and error, test that with your users, and figure out how much information makes sense to have on one page, versus splitting that across multiple pages. When it comes to videos, the thing to keep in mind is that when we recognize there is a video on a page, we will show one video thumbnail for that page.  

#### [0:42:30](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=2550) |  So if you have multiple videos, and

these are essentially video landing pages for those individual videos, then I would tend to put those videos on separate pages, just so that you have one clear landing page for those individual videos. So that's kind of from my point of view, the way that I would look at it there. If you have all of the videos on the same page, then it's really hard for us to tell which of these videos is the important one that we should show as a thumbnail,  

#### [0:43:00](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=2580) |  for example. Some simple links are attached

under each result's description in the search results using a scrolling carousel. I can't find any guide pages on that. What's the difference with the exposure type and side links? How does Google select those links? Can you explain more about the purpose and the algorithm of additional attached links on the search results?  

#### [0:43:30](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=2610) |  Not so sure exactly which kind of

links you mean there because especially those pages have gotten a bit complicated with lots, lots of different things there. When it comes to things like side links that we would show under a page, that's something where we try to understand where it makes sense to show additional information to the user. And oftentimes, that's based on things  

#### [0:44:00](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=2640) |  like us recognizing that the users search

for one thing, but actually, they're not looking for the most important page on those keywords, but rather some general information around those pages. So maybe they'll search for [INAUDIBLE] name. But instead of clicking on your company home page, they'll click on blue running shoes because that's a side link because actually they were looking for running shoes from your company, and they just remembered your company name as a query to look for. So that's something-- kind of a reason we would show things  

#### [0:44:30](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=2670) |  like side links. And for side links,

in particular it helps to also have a clear site structure, kind of as I mentioned before. Rather than linking everything with everything else, if you have a clear structure on your site where we can tell that these are kind of subpages from this one primary page, then it's a lot easier for us to automatically generate side links for those pages, because we know that they kind of belong together.  

#### [0:45:00](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=2700) |  It would be interesting to get some

insights in recent major changes of the [INAUDIBLE] algorithm. Do you have any interesting-- anything interesting worth mentioning? Is seed site something that is implemented? So I have no information about any major changes of the PageRank algorithm. I think we've kind of worked with that for a really long time. So from that point of view, I don't really know what specifically you're looking at there.  

#### [0:45:30](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=2730) |  The thing to keep in mind also

with page rank is, we do use page rank in search, but we use lots and lots of other factors. So sometimes it's something that people tend to focus on a lot just because we publish information about it once. And links are this kind of thing that you can implement and kind of manipulate a little bit on the web. And you think, well, I can influence this PageRank  

#### [0:46:00](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=2760) |  algorithm. And probably you can influence the

PageRank algorithm, but there's so many other things involved with search that focusing on one specific, tiny element of all of the kind of ranking or general indexing algorithms is not going to really help your site. OK, we still have a few questions left. AUDIENCE: John, sorry, good morning again. It would be very good if I could ask a question because I have just a few minutes left.  

#### [0:46:30](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=2790) |  It's about [INAUDIBLE] and all the privacy

stuff. Because of that, we are implementing two click embeds on our website for social media and YouTube. It's like when you come as a user to our website, you see a placeholder, and there's a text like, here would be recommended content from YouTube. And then you have to click on a switch, and then you give your permission to see this kind of third party and that stuff.  

#### [0:47:00](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=2820) |  So we are wondering if this affects

our visibility and rankings on Google because Google bot can't see this YouTube video or social media on that because Google can't click buttons. JOHN MUELLER: Yeah. So I think that kind of embed has been around for a pretty long time. And generally speaking, I think that's a fine approach to take. The one place where I could imagine this playing a little bit of a role  

#### [0:47:30](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=2850) |  is in recognizing which videos are embedded

on a page when it comes to video search and kind of the video thumbnail. But what you can do in cases like that is use the video markup, rather than just the video embed. So our systems do recognize the common kinds of video embeds and try to figure out what is a thumbnail automatically. So if we recognize a YouTube embed or Vimeo embed  

#### [0:48:00](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=2880) |  or whatever all of these common formats

are, we can figure that out automatically. But you can also use the structured data to tell us about this. So instead of-- in a case like this, instead of relying on the embed code, I would use the structured data and tell us, hey, I have the video here, and this is a thumbnail image, this is the file, or the other information that you have for the video. And then we can still recognize the video is on this page.  

#### [0:48:30](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=2910) |  We can use this page as a

video landing page and show it appropriately in the search results. AUDIENCE: Our approach would be to just use the embed URL schema so that Google sees the URL of the embed. Is it enough, or should we use the video object schema for this-- for YouTube embeds? JOHN MUELLER: I would try to use the video object. Yeah. I'm not sure how we would use embed. But the object, you're really giving us that information.  

#### [0:49:00](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=2940) |  For the other kinds of embeds from

social media content, usually I'd find that less problematic, unless there is something in that embed that you need to have for indexing. Like if you have a series of [AUDIO OUT] you're embedding on a page, and if we can't see those tweets at all, then the text in those tweets, we can't really associate with the page. But the fact that this text comes from tweets, and here's a link to the tweets, that doesn't matter to us.  

#### [0:49:30](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=2970) |  So it's not that we need to

see-- kind of for the other kind of social embeds, it's less of an issue. I think even for Instagram, when it comes to images, I believe their images are embedded in a way that we can't actually index the images through the embed anyway. So for the non-video types of social media embeds, I don't think that would be a problem.  

#### [0:50:00](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=3000) |  AUDIENCE: OK, thank you. JOHN MUELLER: Sure.

OK. Maybe we'll just switch over to more questions for you all. I also have a little bit more time. So we can stay a little bit longer if any of you want. Feel free to jump in. AUDIENCE: Can I ask a question about intrusive interstitials? JOHN MUELLER: OK. AUDIENCE: So first of all, thanks for doing these Hangouts. I'm a big fan. JOHN MUELLER: Thanks. AUDIENCE: There is some clarification that I need around the interstitials, regarding  

#### [0:50:30](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=3030) |  serving it to organic visitors, bots, and

about full page. So let me ask, let's say there's been tests done, and we see that the conversion rate for an e-commerce website is the same for buying products. So from a user perspective, a full page or a lower third is the same from a conversion perspective for buying products, but signing up for the emails,  

#### [0:51:00](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=3060) |  it's turning the sign-up rate, the registration

rate. So from what I understand, Google devalues a full page interstitial, is that correct? On mobile, at least. JOHN MUELLER: On mobile. Yeah, yeah, yeah. AUDIENCE: So is it OK to serve-- let's say I can figure out how to improve the registration rate. Is it OK to serve a lower third to organic visitors,  

#### [0:51:30](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=3090) |  but visitors coming in direct or other

marketing channels to serve the full page? Is that OK? JOHN MUELLER: That's generally OK. The thing to watch out for there is that Google bots, when we crawl and index your page, we don't send a refer. So that's something where, if users coming in from search see kind of an improved you, that's fantastic. You just need to make sure that that improved  

#### [0:52:00](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=3120) |  you is also the one that Google

bot sees when it crawls and indexes the pages, otherwise we wouldn't be able to take that into account. AUDIENCE: Correct. So it's OK to essentially serve the lower third to Google bot and organic? [INAUDIBLE] JOHN MUELLER: Yeah, yeah. AUDIENCE: OK. So let's say now somebody is coming in from California, same Google bot. It's the full page, and we've got the privacy policy. And it's a full page. Is this OK?  

#### [0:52:30](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=3150) |  Will I get devalued for that? JOHN

MUELLER: We try to recognize legal interstitials and ignore those. So things like privacy policy, the-- what is it, the data protection interstitials, those kind of things, we try to recognize and skip over. The important part is that you're showing this on top of the HTML page, not that you're showing it instead of the HTML page. So things like redirecting to a separate interstitial URL  

#### [0:53:00](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=3180) |  or showing the interstitial instead of the

actual content, that would mean that we wouldn't be able to actually crawl and index the content. But if it's a div on top of the HTML, that's perfectly fine. AUDIENCE: OK. And last question regarding devaluing. So I understand, obviously organic is-- I mean, that's what I live by, and that's my job. So it's very important. But let's just say, from a registration standpoint, that full page, business-wise for the email,  

#### [0:53:30](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=3210) |  is more valuable. How can I measure

if I'm getting devalued? Is there a way? Can you suggest something? So for example, my main competitors they do not have a full page, except for one. Until now, I don't know exactly how to measure or prioritize this within the company. JOHN MUELLER: I don't think you can. I don't think that's possible. So it's one of those things that we  

#### [0:54:00](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=3240) |  use in the ranking algorithms, where we

will kind of try to take that into account and essentially rank the website a little bit lower if we recognize that it's doing things like the content above the fold on mobile is not there or filled with ads, filled with the interstitial, that kind of thing. But it's not that there is a flag in Search Console, or you see a warning, or anything like that. AUDIENCE: Last question, and I don't know if you can tell me the answer for this.  

#### [0:54:30](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=3270) |  But let's say the ranking drops three

or four positions consistently. So I get to that first, second position, and then it drops three, four positions. Is that somewhat of an indicator that this could be hurting me, or related to the devalue? JOHN MUELLER: I would intuitively say no, just because my understanding is that,  

#### [0:55:00](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=3300) |  especially something like the intrusive interstitial change,

that's something that is more, probably a software factor, and it's something that wouldn't be applying across the whole website. In particular, if people are still looking for your brand name, then I wouldn't expect to see any ranking change for that. Whereas if people are looking-- AUDIENCE: Thank you. I see it on specific pages and related to eyeglasses, to health. JOHN MUELLER: Yeah, yeah.  

#### [0:55:30](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=3330) |  So if people are searching for eyeglasses,

and you're one of the hundreds of competitors out there, then that's something where I could see kind of a change being visible in Search. But it shouldn't be across the whole site. It should be really kind to those more generic queries where there's more competition, then it's, like, slightly harder for your site. AUDIENCE: OK, thanks so much. I really appreciate it. JOHN MUELLER: All right. I think we're at time. So I'll stop the recording here.  

#### [0:56:00](https://www.youtube.com/watch?v=_UGEeGlKQ2o&t=3360) |  But if any of you want to

hang around and chat, ask more questions, you're welcome to do that as well. Thank you all for dropping in. Thanks for joining and asking all of the tough questions, submitting some really good questions. And hopefully, I'll see you all again next time. All right, have a great weekend. And let's stop the recording.  