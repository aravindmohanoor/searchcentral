[![English Google Webmaster Central office-hours from September 11, 2020](https://i.ytimg.com/vi/AK_lSVA6bcY/hqdefault.jpg)](https://www.youtube.com/watch?v=AK_lSVA6bcY)

## English Google Webmaster Central office-hours from September 11, 2020

This is a recording of the Google Webmaster Central office-hours hangout from September 11, 2020. These sessions are open to anything webmaster related like crawling, indexing, mobile sites, internationalization, duplicate content, Sitemaps, Search Console, pagination, duplicate content, multi-lingual/multi-regional sites, etc. 



Watch out for new sessions, and add your questions at https://www.youtube.com/user/GoogleWebmasterHelp/community



Feel free to join us - we welcome webmasters of all levels!



#### [0:00:00](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=0) |  JOHN MUELLER: All right, welcome, everyone, to

today's Webmaster Central office-hours hangout. My name is John Mueller. I am a Search Advocate at Google. And part of what we do on the Search Relations team is to reach out and talk with webmasters and site owners about any issues they might have with regards to their websites and Google Search. A bunch of things were submitted already on YouTube. But like always, if any of you want to get started,  

#### [0:00:30](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=30) |  just feel free to jump on in

with the first question. SAIDUL HOQUE: Hi, John. JOHN MUELLER: Hi. SAIDUL HOQUE: I have two questions, actually. So one of our clients, they have a commercial site. And they have a blog as well. And both their sites, they set up on WordPress. Now, what we did-- we have a lot of content on blog, which are really high quality content. And people are giving link to our blog as reference. Now, what we did-- we created interlinks  

#### [0:01:00](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=60) |  from blog post to product page and

product category page. Now, the backlinks we are getting to our blog post-- will that help to rank our product page or product category page organically? JOHN MUELLER: Yeah, that should work out. Yeah, that's essentially kind of-- I think that's kind of a best practice, almost. You write about something that's kind of related to those products, related to your industry,  

#### [0:01:30](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=90) |  to the type of work that you

do on your blog. That's a good place to put out regular content. That's content that's perhaps easier to attract links for. And from there, you can link out to the relevant parts of your-- of the rest of your business, essentially. So from that point of view, I think that's a perfect setup. SAIDUL HOQUE: OK, now, the next question is I have got this one of my clients, today morning, actually. So he wants to set up his e-commerce website on Shopify.  

#### [0:02:00](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=120) |  But he wants to use WordPress for

the blog. So he needs to create a subdomain for the blog section. So the question is if we do a subdomain and get the backlink for the blog post, will that still help the product page and product category page for the all-in ranking? JOHN MUELLER: Sure, sure. SAIDUL HOQUE: [INAUDIBLE] JOHN MUELLER: Yeah, I think that's perfectly fine. Some sites even have the blog on a separate domain for whatever technical reasons. That's essentially up to you.  

#### [0:02:30](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=150) |  I think in general having it as

close to your primary site as possible makes sense, because then also for users, it comes across as one big structure. And then it's kind of clear that, oh, this link from this one part of the site links to a different part of the site. And it doesn't come across as something-- I don't know-- unexpected. You click on a link. And suddenly, you land on a completely different site. If it looks the same-- if it's essentially hosted in a similar place--  

#### [0:03:00](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=180) |  then that's, from my point of view,

a good idea. SAIDUL HOQUE: OK, thank you. MIHAI APERGHIS: So, John, in terms of Google understanding that even if it's on a subdomain under a different domain-- I assume interlinking plays an important role for Google to understand that two properties are from the same entity, from the same website, from the same company. What other things are kind of Google looking at?  

#### [0:03:30](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=210) |  Is it design? Does design play a

role? Should design for the blog, for example, be very similar to the website, hosting, things like that? JOHN MUELLER: From my point of view, that's more a factor from the user side and less an SEO factor. So from our side, it is important that we can understand the links between these two pages.  

#### [0:04:00](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=240) |  Sometimes what helps us is to understand

that these are part of the same entity, which in general, having it on the same host name is a perfect way to do it. Having it on subdomain is something that could also work. But essentially being able to understand it's one bigger entity-- and the main reason for that is that we can kind of build up the trust for this site and understand, oh, this is actually a very good site.  

#### [0:04:30](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=270) |  It has a lot of information on

these topics. There's a lot of information here. And we can understand the overall structure a little bit better. And for that, it doesn't need to look the same. It doesn't need to be hosted on the same setup, on the same network, or anything like that. It's really, from our side I'd say, mostly a matter of the being it on the same domain so that it's clear for us that this belongs together.  

#### [0:05:00](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=300) |  MIHAI APERGHIS: The Shopify example is a

good one, since you cannot use a subfolder, for example, with Shopify. Especially if your blog is on WordPress, you cannot go to Shopify and host it there. It's not going to be hosted in the same place, because obviously, they host it on different servers, different IPs. So this is what I was mainly curious-- what kind of signals can one give to Google in order to make sure that Google  

#### [0:05:30](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=330) |  understands this is part of the same

entity, from a technical perspective. Obviously, from a user perspective is important as well. But I assume, as mentioned, interlinking and things like that play a good role in Google understanding these are not separate. These are part of the same entity. JOHN MUELLER: Yeah, exactly. Yeah. Cool. Any other questions before we get started?  

#### [0:06:00](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=360) |  Brittany. BRITTANY MCCULLOUGH: Yeah. JOHN MUELLER: Go

for it. You get-- BRITTANY MCCULLOUGH: So I submitted again on the YouTube channel-- so you might have had a chance to read that-- and chimed in last week. But yeah, I've got the domain migration with over a 90% traffic loss, going on a month with no major culprits that we've been able to identify. So I had another theory, potential culprit,  

#### [0:06:30](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=390) |  I could run by you. So one

of the things on our mind is our site relies on a lot of JavaScript. That's always been true. But we had our old domain on Prerender, using Prerender until June. I won't get into exactly why we stopped using it. But we did stop using Prerender in June. And so that was true all summer. We did the domain migration at the beginning of August, still off Prerender. Domain migration was at the beginning of August. And we had all of our traffic loss.  

#### [0:07:00](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=420) |  And we were wondering if maybe taking

the site off Prerender in June was not the right move, and there was maybe a bit of a lag in Google totally processing that. The domain migration made it worse-- not totally sure. But we did put our new domain back on Prerender as of basically the beginning of September. It hasn't helped with the traffic loss at all. Wondering if you could give your opinion on whether this is a potential culprit and if so, if--  

#### [0:07:30](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=450) |  when we might potentially see recovery, what

we could do to help it, or if we are once again pulling at a thread that is not actually going to help us. JOHN MUELLER: Yeah, I don't know. So from the timeline, you basically have a client side rendered site, in that case-- a JavaScript based website. And then-- BRITTANY MCCULLOUGH: Yeah. JOHN MUELLER: --until June, you had it running on Prerender, so serving kind of the Prerender version to Google.  

#### [0:08:00](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=480) |  And-- BRITTANY MCCULLOUGH: Correct. JOHN MUELLER: Then

you turned that off and let Google do the rendering, essentially. And then in August, you set up the redirect through the other domain, OK. BRITTANY MCCULLOUGH: Mm-hmm. JOHN MUELLER: I think that makes it more complicated. But I don't know what the actual effect there might be. So that's something where I'd probably  

#### [0:08:30](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=510) |  have to take a look to see

what all was kind of happening. And during that time from June until August, was it fairly stable? Or were you seeing changes there, too? BRITTANY MCCULLOUGH: Well, we definitely did see a bit of a dip, but nothing absolutely crazy. But we saw a traffic loss maybe at about 15% starting after May, which is when we started moving off Prerender. That's also, of course, right after the May algorithm update.  

#### [0:09:00](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=540) |  So we had originally attributed it to

that. And that's fine. And we were trying to learn from that and sort of normal, run-of-the-mill stuff. But then, of course, when we did the domain migration in August and ended up with a 90% traffic loss, that made us reflect on if maybe that change was more tied to Prerender than the core algorithm update and just tried to focus in on that area or any area we could. JOHN MUELLER: OK, and the domain migration--  

#### [0:09:30](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=570) |  how did you set that up? Because

if it's a JavaScript based website, did you just redirect all the URLS to the new one with server side redirects? Or was there something on the JavaScript side that you did as well? BRITTANY MCCULLOUGH: Yeah, we just did-- I'll speak to it as best as I can. But, yeah, we set up, from my perspective, standard 301 redirects. We validated the Webmaster Tools. We've had four different SEO agencies looking at everything.  

#### [0:10:00](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=600) |  And first thing they check is our

301 redirects and have said everything looks golden there. We-- our SEO agency has-- they've picked up on things that aren't perfect. But all of them are a little bit at a loss to say how any of those smaller things-- from their perspective and our perspective-- could lead to a 90% traffic loss. So I feel like that's a-- we did that part pretty solid. But I can't say that with full confidence.  

#### [0:10:30](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=630) |  JOHN MUELLER: Yeah, I think it makes

it a little bit more complicated. But it shouldn't be such that you would see such a big drop. So in particular, what could happen-- I don't know if this is something that happened in your case. But what could happen with a client side rendered website, if it's based on JavaScript and needs all of the JavaScript to function properly, then when you redirect it,  

#### [0:11:00](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=660) |  because of the way that we cache

all of the resources that are used for rendering, it might be that it's a little bit trickier to handle a site move situation, because then we might have the new URL. And we try to render that based on the previously cached old content. And depending on the way that the move is set up, it might be that that rendering failed of that kind of mixed set of information that we have.  

#### [0:11:30](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=690) |  So if you have a pure static

HTML page, when we move that over, we have the static HTML page with everything. But if it's based on JavaScript, we need to be able to process the JavaScript to see the full content. And we cache a lot of the content that is pulled in with JavaScript. So it's possible there is some kind of clash, perhaps, that happened there. But that would be something where you would see issues  

#### [0:12:00](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=720) |  with regards to indexing, where you would

see that really the number of index pages is going down. It's not something where I suspect you would see just the traffic drop, so. BRITTANY MCCULLOUGH: Yeah, I mean our number of index pages is also way down. I mean, we sort of dropped off the map entirely with the old domain. And the new domain didn't really pick up more than a very small amount of keywords compared to what we used to rank for.  

#### [0:12:30](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=750) |  So I guess, in this case, do

you have any specific suggestions for what we could do from here? So like I said, the site has been back on Prerender for about a week and a half now. And that hasn't impacted our rankings or traffic. JOHN MUELLER: Yeah. BRITTANY MCCULLOUGH: Yeah. JOHN MUELLER: OK, so I passed it on to the ranking team to double check what was happening there last week. I haven't heard back anything in particular yet. But I need to double check just purely from a technical point  

#### [0:13:00](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=780) |  of view that we were able to

even process all of these things, so to determine, is this more of a technical indexing thing that we can work out? Or is there something from ranking that's actually harder to solve? Because the technical issues are things that-- usually, you can fix them. You moving back to Prerender is something where-- personally, you probably don't need to do that.  

#### [0:13:30](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=810) |  But it reduces the number of risky

connections that you have there. It makes it a little bit more stable in that regard. So that's something where I'd say, that's probably a good move. But I don't know if it's really purely a technical thing that needs to be worked out or if there's actually some ranking or quality issue that we need to work out. BRITTANY MCCULLOUGH: OK. JOHN MUELLER: Yeah, but I was hoping  

#### [0:14:00](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=840) |  I'd get more information by now from

the team. But sometimes it's not that trivial. BRITTANY MCCULLOUGH: Sure. JOHN MUELLER: Cool. BRITTANY MCCULLOUGH: I appreciate that and an excuse for me to join you again at midnight my time. JOHN MUELLER: Sure, yeah. BRITTANY MCCULLOUGH: So thank you. JOHN MUELLER: OK, have a good night then. If you want to drop off, no problem. BRITTANY MCCULLOUGH: I'll stick around. JOHN MUELLER: OK, cool. All right, let me look at some of the other questions that were submitted. "We do a lot of testing on our site.  

![](https://i.ytimg.com/vi/AK_lSVA6bcY/hq1.jpg)



#### [0:14:30](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=870) |  And the bots are seeing all of

these tests. We're planning quite a big test, which involves drastically changing the menu. And this would have quite a big impact on SEO. But we need to have the test for UX purposes. We don't want to roll out this change if it's not permanent. What should we do? If we block Googlebot from seeing the test, will it be considered cloaking? If we roll out the test for everyone, users and bots, what would be the maximum period of time we would run it without impacting SEO?"  

#### [0:15:00](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=900) |  So first off, I think doing tests

like this for usability, even for SEO sometimes, is really important. And I think it's something that everyone should consider doing and try to find ways that they can do that, because sometimes you can only make so many assumptions about your website. And you really need to test to see what is actually the case. Do users respond to this type of menu or that menu better?  

#### [0:15:30](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=930) |  Can we bring our information better to

users if we present it-- I don't know-- in a different color or in a different font or in different layout. All of these are things that you can't really know ahead of time. You almost have to test them. So doing this kind of A/B testing is really important. And understanding how you can do that is hard, figuring those details out. We have, I think, a help page on A/B testing, which has a little bit of information there.  

#### [0:16:00](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=960) |  But in general, if you're doing something

that you would consider a temporary A/B test, it's fine to include Googlebot in that. It's also fine to say, well, Googlebot is a special category, which might be a category that you base on-- I don't know-- geographic location, or on language settings, or on capabilities that this device has. And then do the A/B testing that way so that you have a more stable version  

#### [0:16:30](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=990) |  that you show Googlebot for crawling, indexing,

and ranking. So that's kind of the direction I would head there. If you do end up using a separate version for A/B testing, make sure you have the rel canonical set to your preferred version that you want to use for indexing. If you use the same URLS, then that's less of an issue. Also keep in mind that Googlebot doesn't use cookies. So if you use cookies to set an A or B version, then Googlebot won't keep that and won't  

#### [0:17:00](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=1020) |  return that cookie, which means that if

you're not watching out, you could end up in a situation that you serve Googlebot a different version every time Googlebot crawls, which is probably a bad thing when it comes to SEO, especially when you're changing things like the internal linking, the menu within a website. So those are the things that I would look at there. It's something that's definitely not trivial to do.  

#### [0:17:30](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=1050) |  But I know there are some frameworks

out there that make it a little bit easier. But it's worthwhile to think through all of the different variations and keeping in mind some of the restrictions from crawlers in general with regards to how they handle cookies, how they deal with redirects and different URLS, all of those things. "My old Hindi blog was getting huge traffic. But after I created some forum and dofollow comments,  

#### [0:18:00](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=1080) |  backlinks from high DA, PA-- foreign websites--

to my Hindi blog, after that my ranking is going down day by day. And a Google core update also decreased my ranking by 50%. In one year, three core updates hit my blog. I disavowed some of those links, but still no improvement is showing. Do I need to disavow all of those links?" So I'm kind of skeptical about the links  

#### [0:18:30](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=1110) |  that you placed there, because it sounds

like these are random links that you're placing on other people's websites just with regards to SEO. So if you're looking for high DA, which is Domain Authority-- it's a metric that Google doesn't use. It comes from a third party. If you're using sites like that, then probably other people  

#### [0:19:00](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=1140) |  are dropping links there, too. And then

probably we're going to be ignoring those links completely. So my feeling is those links are not going to be the problem. But they're also not doing any good at all for your website. So that's a lot of work that you're doing, which essentially has no effect. So I would recommend stopping just dropping links on other people's sites. With regards to the de-ranking in general,  

#### [0:19:30](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=1170) |  my guess here is that it's mostly

based on the content of the website itself and on the way that we see that website with regards to the rest of the Search world. So that's something where I wouldn't assume that those links are necessarily causing problems or that the core algorithm update is somehow magically changing things for your website. But really, it's more a matter of your website itself,  

#### [0:20:00](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=1200) |  the content that you provide, and the

overall value that you bring to the rest of the web. And the question goes on. "I'm hosting my blog on Blogger with a custom domain. Do I need to migrate it to WordPress or is Blogger still OK?" Blogger is perfectly fine. So there's no advantage that you would see in a case like this from moving to any other CMS. One of the really big advantages of using Blogger  

#### [0:20:30](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=1230) |  is that you don't have to worry

about the infrastructure. Things essentially just work for you. There's a team of engineers who work to handle any outage that comes up, who make sure that all updates are installed, all of that. So that's something that, if you can save yourself that work, that's always worthwhile. But again, I would really focus much stronger on the content. I don't know your website here.  

#### [0:21:00](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=1260) |  So it's hard to say. But it's

something that we regularly see. When a blog where people are just publishing content all the time, trying to get traffic-- when that drops significantly in ranking or in visibility in Search, then often that's due to the content not being as fantastic as we would have expected. "I was wondering about when these big announced core updates happen, are there some parts of the linking algorithm updated as well?  

#### [0:21:30](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=1290) |  Like, you discovered that this site received

great links from great sites. Would you say that this is a better site now because it got such recommendations, so that the big core updates will reward it and show it more to users?" So in general, a core algorithm update-- the way that we have it defined is somewhat vague, because it's not that we have this one piece of machinery that is the core algorithm, and when we change one screw there,  

#### [0:22:00](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=1320) |  then that's a core algorithm update. But

rather, we have so many different algorithms that work in Search. And when we make significant changes across a number of them or significant changes in the way that we interpret them, then that's something that we would call a core algorithm update. So from that point of view, it's not that we would say, oh, the way that we handle links never changes, or the way that we handle links always changes when we make a core algorithm update.  

#### [0:22:30](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=1350) |  These changes can happen essentially at any

time. And they can also coincide with core algorithm updates. The way that we process links is something that is continuous. So it's not that we have to wait for a specific time frame to see the new effect of the links. But rather, when we see links on the web, we can take them into account essentially immediately. "In the HTML spec, P is a logical element.  

#### [0:23:00](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=1380) |  Is that the same for Googlebot? I

mean, a situation where one paragraph contains one theme is much better for a robot's understanding than a stream of thoughts in one big P element." So this is an interesting question, because I never really thought about this. But from my understanding, we don't do anything special with these kind of paragraph delineators.  

#### [0:23:30](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=1410) |  Or a div, for example, is something

that people sometimes use for this as well. But rather, we kind of see it as chunk of text. So it's not that we would say, a paragraph separation, it means something unique. But rather, we have-- when we render the page, when we pull out the HTML, when we look at how things are semantically structured, when we see that this is one collection of thoughts, essentially a number of sentences that are all  

#### [0:24:00](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=1440) |  together, then that's something that we can

kind of assume belongs together with regards to understanding that page. So I wouldn't say that we go out of our way to semantically understand that this is a paragraph. But we do try to figure out what a paragraph is. So I guess in a way, you could say, we do figure it out. I don't know. It's weird. But I don't think it's the case that we try to turn a P tag into something more than kind  

#### [0:24:30](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=1470) |  of a separation of paragraph. One place

where this sometimes goes a little bit weird is-- I haven't seen this in the past recently. But previously, when people were using things like table-based layouts, then the table cells themselves are also kind of a paragraph.  

#### [0:25:00](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=1500) |  And sometimes what we saw is that

people were using a table-based layout to actually structure something that belongs together. So you could imagine a situation where you have a table setup, and a sentence is across a number of different table cells, which you're using for whatever design purposes. And for us when we look at that, we see a collection of individual cells. We don't realize that actually these cells belong together and make up one big text piece.  

#### [0:25:30](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=1530) |  Or similarly, you could imagine a whole

paragraph being split up into individual table cells. And that's something where, at least when people were doing this more often-- this kind of table-based layout-- it's something that we did run into every now and then, that we couldn't work out that these things are actually next to each other, and they belong together for understanding of a page. But with all of the modern CSS solutions out there,  

#### [0:26:00](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=1560) |  I think that's a lot less of

an issue. "It seems Google recently launched an update for Search in News tab, something that many were complaining about for the past nine months. Likewise, I also notice that Search Console is now showing performance of links for a News section. Has that always been there, or is that also a new thing? I am unable to see any performance insights there." So I don't know what-all was happening on the News site.  

#### [0:26:30](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=1590) |  I do know that they're working on

some things to kind of catch up with whatever they've been struggling with there. So hopefully, for those of you who are waiting for this, hopefully that will be a little bit better in the future. But I don't really have any details there to share. My understanding is that they'll probably also post something in the News help forum at some point  

#### [0:27:00](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=1620) |  with more details. With regards to Search

Console, we did start including the News information in Search Console. But that's, I believe, News mode in Search, not Google News. So it's slightly different from just pure Google News. And the data that we pulled in there I think only goes back to July or something like that from when we started collecting this data for sites.  

#### [0:27:30](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=1650) |  So sites that have been around for

longer that have the usual 18 month of data in Search Console, they still have a limited set there for that News section. Over time, as we collect more data for these sites, then we'll have that full time period again. "I wanted to ask if linking from the main part of-- main content part of the old, but still relevant, articles on my domain to the new,  

#### [0:28:00](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=1680) |  recently published articles on the same domain

increases relevance for specific internal anchor texts and topics used in the link or if it otherwise helps that new article?" So the question is kind of complicated. But I think essentially what you mean is, does it make sense to link from content on one page within your website to new pages on your website  

#### [0:28:30](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=1710) |  or to other pages on your website?

And from my point of view, that's an obvious yes. Of course linking between different parts of your website, creating a good internal linking structure-- that always makes sense. So that's something that I would always recommend. It's good for users. It's really helpful for search engines, because if we have multiple paths to crawl your website, it's a lot easier for us to crawl your website. If we can better understand which parts of your website  

![](https://i.ytimg.com/vi/AK_lSVA6bcY/hq2.jpg)



#### [0:29:00](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=1740) |  are important to you, which is usually

the parts that you link to more often within your website, then that helps us to better focus our efforts on those parts as well. So any kind of improvement that you can do for internal linking is a good thing. Two questions-- let's see. "When is the next Google core update coming? The last one, from May, was hard."  

#### [0:29:30](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=1770) |  I don't have any dates for core

algorithm updates. I know everyone kind of wants one. But it's something that, from our side, we try to minimize the amount of big disruptions like these as much as possible. And when we do work on bigger changes with regards to understanding relevance of Search, it is something that we try to significantly test to make sure  

#### [0:30:00](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=1800) |  that it's working well. We run a

number of evaluations on our side to determine where the different search results will be, if that matches what we want. We do a number of tests with external raters to figure out if we're missing anything or if we're accidentally not recognizing that this negatively affects some things that we were worried about. And from our point of view, it's not  

#### [0:30:30](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=1830) |  that we would wait for a specific

date and then just launch whatever we have then. But rather, we want to make sure that this is working as well as possible. And then when it's working well, then we will launch it. So it's not like a release date that we have to hit. But rather, we will launch it when things are ready. "My Search Console is showing nothing. But I suspect my site may have a ranking penalty for some reason. So is the only way to check in Search Console manual actions,  

#### [0:31:00](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=1860) |  or is there another way to check

this?" Yes, if there is a manual action on your website-- so if the Web Spam team has manually needed to step in and take some action with regards to your website, then that will be visible in Search Console. I think there is an extremely small number of cases where that wouldn't be visible. But those are really kind of tricky edge cases. And it's not something that an average site would run into.  

#### [0:31:30](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=1890) |  So in general, if you're not seeing

anything in Search Console in the manual action section, then I would assume that your website is ranking algorithmically the way that we think it makes sense. And it's not the case that there is anything manual playing a role in that. "Finally, I want to point out that a cache plugin named WP Rocket released yesterday-- a JavaScript delay function  

#### [0:32:00](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=1920) |  that solves all of the problems that

AdSense generates in PageSpeed Insights." So that sounds pretty promising. I haven't taken a look. I also don't have AdSense on my blog. So I can't really test it. But I know lots-- or some people have been complaining about the AdSense and some of the other things that-- services and products that we have that you can embed on your site that make a page slower.  

#### [0:32:30](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=1950) |  And if there are ways to improve

the speed for that, then I think that's a good idea. So it might be something to try out. "I found a snag in the Google workflow to recover account access." So I took a quick look at this question ahead of time. And I don't know exactly what it's referring to. I suspect it's tied into the Google Ads side of things and not with a Google Search Console kind of scenario.  

#### [0:33:00](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=1980) |  So I really don't have any insight

on what can be done there. I know that in general, the Account Recovery team works really hard to make sure that things work as much as possible. But if you're finding that the normal account recovery flow isn't working, then I would definitely post in the help forum. I don't know if there is now a separate Google Account help forum.  

#### [0:33:30](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=2010) |  Otherwise, probably the Gmail forum is a

good proxy for that. "I want to ask, what is the best to write in the alt text of an image that has quotes written on it. Do quotes work best or the keywords from the article? How should a person go with such images?" So the alt attribute for images should be a description essentially of the image itself. And from that point of view, if your image is a quote,  

#### [0:34:00](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=2040) |  then you can describe that quote. Or

you can just copy that quote into the alt attribute. That's a perfect setup. So that's kind of how I would go there. I wouldn't use the alt attribute just to stuff keywords from the site in there, because that's not useful for users. It's not useful for us as a search engine either, because we already see those keywords from the rest of your page. For Search, what happens with the alt attribute  

#### [0:34:30](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=2070) |  is we use that to better understand

the images themselves, in particular for Image Search. So if you don't care about Image Search, then from a Search point of view, you don't really need to worry too much about the alt attributes. But if you do want these images to be shown in Image Search, which sometimes it makes sense to show fancy quotes in Image Search as well, then using the alt attribute is a good way to tell us,  

#### [0:35:00](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=2100) |  this is on that image. And we'll

get extra information from around your page with regards to how we can rank that landing page. "I'm seeing a constant influx of spam and malicious domains appearing in the search results for a website I manage. We're finding about 30 to 50 new ones per day ranking in the top 10 pages for our brand search. Most of them redirect to phishing scams and virus warnings. What's the best way of dealing with these and then,  

#### [0:35:30](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=2130) |  most importantly, preventing them? It's quite strange

that these domains are ranking in the top 10 pages for Google for our brand when we have hundreds of popular articles that Google should be shown ahead of these. Is this just a loophole that affects all brand searches?" So I don't think this is something that affects all brand searches. That would be something where probably we'd hear a lot more complaints about. But it is something where depending on the kind of query  

#### [0:36:00](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=2160) |  that your brand search essentially is, it

can happen that we don't have a ton of really good content. And even if we have more good content from one website, it might be that we just show a handful of results from one website. And then the rest, we kind of take whatever else we can find on the web, which if we don't find a lot of good things, then we kind of have to scrape the bottom of the barrel. And we come up with things that aren't that great.  

#### [0:36:30](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=2190) |  Especially if you're talking about the first

10 pages of the search results for something like a brand query, probably users, when they're searching for your brand, they find your brand on the first page. And they go to your site directly. They wouldn't go through the top 10 pages to see what else is there. However, if this is something where it looks like these kind of hacked, phishing, kind of virusy sites are in a particular pattern,  

#### [0:37:00](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=2220) |  and it feels like Google is missing

this pattern completely for whatever reason, then I would strongly recommend posting more about this in the Webmaster Help forum so that the folks there can also pass that on to us if they recognize that there is something more general and broader that Google would need to do. So that's kind of the direction I would go there. Of course, with virus content, you  

#### [0:37:30](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=2250) |  can also report that through a special

forum on Google site, which we use quite a lot also for phishing content. You can do the same thing. So that can help there. But essentially, if there is nothing good that we can show for some of these queries, and you're going to page 10 in the search results, then we end up with all kinds of weird things that happen to be indexed for some reason. "We have a News site, and we use advertising.  

#### [0:38:00](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=2280) |  When I look at the HTML code

inside Search Console URL Inspection, I see there is a lot of CSS code injected by the Ads JavaScript in the dom. Does this affect the page ranking in any way?" Usually not-- so various JavaScript snippets do inject CSS. They do inject some HTML into the page depending on what they're meant to do. That's something that, from our point of view,  

#### [0:38:30](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=2310) |  doesn't affect ranking. There are two things

to watch out for when it comes to third party JavaScript that you use on your website. One is that some kinds of JavaScript inject code HTML into the head of the page, which can result in us not being able to understand which elements of your content are actually in the head. So one example is that JavaScript  

#### [0:39:00](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=2340) |  might inject something like an iframe to

the top of the head of your page. And when we parse that HTML page, we'll see the iframe tag. And we'll say, oh, the head of this page is closed. We can skip all of the rest of the metatags and things like that, that are there. And then it can happen that a robot's metatag is missed, that a rel canonical is missed, that hreflang links are missed, because we think that they're no longer in the head of the page. So that's one thing to watch out for.  

#### [0:39:30](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=2370) |  In URL Inspection, you should be able

to see that. It's really tricky to spot. And the first time you see it, you'll be really surprised and big aha moment. But it is something that can happen. And to fix it, you essentially have to work with the provider of that third party JavaScript to let them know that injecting things into the head of the page can be problematic. The other element that can play a role with third party  

#### [0:40:00](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=2400) |  JavaScript and content injected into a page

is essentially everything around speed, where if a JavaScript element injects a lot of content into a page, and that makes that page really, really slow, then when we evaluate the speed of the page for ranking, then that's something where we might see that, oh, this page is very, very slow. And we would not differentiate between it is you, the site  

#### [0:40:30](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=2430) |  owner, that is making this page slow,

or it is some third party that you're embedding with JavaScript that is making the page very slow. But rather, when we load your page, it is very, very slow. So that's the other aspect to kind of keep in mind. "Does Googlebot ignore the container tag while crawling?" So I don't know what the container tag is. So I didn't have a chance to double check before the hangout. I feel I'm missing something totally obvious.  

#### [0:41:00](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=2460) |  But in general, if the container tag--

lets say, the container tag is some new HTML element that somehow I missed. If that's a new HTML element, for example in HTML5 or something even newer than that, then from Google's bot point of view, we would essentially process that as any other tag that we don't know about. So that's something where we would try to render the page.  

#### [0:41:30](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=2490) |  If we can render the page and

get the content-- we render the page using a fairly modern Chrome version. So if we can render the page and get the content, then that's essentially fine. If the container tag is something that just provides extra functionality and doesn't change the content that is shown for rendering, then we would essentially ignore that. MIHAI APERGHIS: Perhaps they're referring to the Google Tag Manager container?  

#### [0:42:00](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=2520) |  JOHN MUELLER: Oh, OK. MIHAI APERGHIS: Whether

that's-- JOHN MUELLER: Google Tag Manager, yeah-- good point. Yeah, that's also a container. Always awkward when you don't know what it is. And it's like, am I missing something totally obvious, or did they confuse something? Yeah, so if it's Google Tag Manager, then that's something that could be tied in when it comes to rendering. You can test that with the URL Inspection tool  

#### [0:42:30](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=2550) |  to see what happens there. And I

haven't played around with Google Tag Manager for a while. But I-- you can do things like include JavaScript, which means you could update some of the content on the page as well. So if you're using that to update the content, to add content, to remove content, then when we render the page, we'll be able to take that into account. "Do you know about any update coming to Google My Business regarding keywords as a business plan?"  

#### [0:43:00](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=2580) |  I don't know anything about Google My

Business, essentially. So I don't really know there. I have seen, kind of anecdotally on Twitter, various people both complaining and asking for features around that. But I really don't have any insight on Google My Business. "If you see a URL as a 200 which was previously a 404,  

![](https://i.ytimg.com/vi/AK_lSVA6bcY/hq3.jpg)



#### [0:43:30](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=2610) |  then Google will treat this as a

fresh new URL and not impact performance on the big picture. My question is if URLS were performing well previously, does that mean it might have some kind of a score or page authority which would influence Google ranking? If Google sees those URLS as fresh URLS, that means all score authority will be zero. Wouldn't this indirectly impact performance?"  

#### [0:44:00](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=2640) |  So at least from as far as

I know, we don't have any kind of score that we would maintain after we drop a URL from the index. So it's possible that there are some elements that remain kind of in our indexed-- I don't know-- metadata for a URL when a page just temporarily drops into a 404 state and doesn't really get removed from our index.  

#### [0:44:30](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=2670) |  But as soon as we remove that

page from our index, we essentially don't have that metadata anymore. So if something is longer a 404, if it's longer in no index, then we don't have that information anymore. However, there might be a lot of signals that we pick up from the rest of the web. So if that page comes back, we wouldn't know about that page anymore. But we might have lots of signals from the rest of the web that tells us this is actually  

#### [0:45:00](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=2700) |  a good page. So in particular, if

you have a lot of internal links pointing to that page, if the rest of your site is something that we would consider very important or very high quality, then that gives us a lot of information, more about that new page or that page that has come back. So it's not so much that we would keep those signals, and we return them when that page comes back after some time. But rather, the information where those signals  

#### [0:45:30](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=2730) |  are coming from, that still exists somewhere

perhaps. And when that page comes back, then we can rebuild those signals based on the information that we have otherwise. So that's probably what you'd be seeing there if you test around with this kind of functionality. OK, we're running low on time. This looks like we still have a bunch of questions left. But I thought I'd just open things up for you all as well.  

#### [0:46:00](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=2760) |  If there is anything else on your

mind that you'd like to talk about, feel free to jump in. I will also be around a little bit longer if there is anything you want to chat about after the recording as well. [INTERPOSING VOICES] SIVAPRATAP NELLIPUDI: This is Siva again. Last week, we spoke about News. Just wanted to update you something that we have seen an update last night in the Search Console.  

#### [0:46:30](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=2790) |  And previously, it was listing only our

site operator's default. But now it is listing all of her articles in the Search Console. And we are also seeing a static clicks number as well in the Search Console. But it is not increasing, though, for some reason. We don't know why the clicks doesn't increase if the incoming is there. And one thing we have noticed is that a couple of her articles  

#### [0:47:00](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=2820) |  did surface on the News tab in

the regular Search. But when we go into the Google News app or news.google.com, we don't find the same articles there. So if you could please, sir, throw some light on the difference between these two and probably if there is something coming in future, maybe in a couple of weeks, as an improvement to this, because we have come a bit far from where we had been last week. So that is good.  

#### [0:47:30](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=2850) |  Thank you so much for [INAUDIBLE].. JOHN

MUELLER: Yeah, I don't work directly with the News team. So I don't have a lot of direct insights there. But I'm really glad to hear that things are looking up a little bit. If you're seeing these changes just from yesterday, then I would give it a little bit more time to settle down, because in general, indexing changes-- I assume it's the same when it comes to News-- indexing changes do take a little bit of time  

#### [0:48:00](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=2880) |  to settle down and to rebuild the

signals that we need for that. So that's something where I'd say, it's cool to see the initial jump. But you need to give it a couple of days to see where it settles down and where you start seeing data being collected. Also the data in Search Console, depending on the element that you're looking at, has a little bit of a delay. So it might be that after a couple of days, that data actually starts showing up there.  

#### [0:48:30](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=2910) |  But let me know if you still

end up seeing issues like this after a couple of days, maybe next week. Then we can see if there's something unique with the News site that we need to push. SIVAPRATAP NELLIPUDI: Sure, John. I mean, there is a difference between the News tab on Search Console and the News app? Or they are both the same? There is a difference, right? JOHN MUELLER: Yeah, so the News in Search Console is the News tab in Search or the News mode in Search.  

#### [0:49:00](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=2940) |  SIVAPRATAP NELLIPUDI: OK. JOHN MUELLER: And it's

not Google News. So it's very confusing because they're all called News. But we treat them as something different. SIVAPRATAP NELLIPUDI: OK, OK, thank you, John. We'll come back to you next week. Thank you so much, though. JOHN MUELLER: Cool. JEMMY K: Hey, John. JOHN MUELLER: Hi. JEMMY K: Got a question-- yeah, hi. Got a question regarding guest postings. So I know you've covered that previously. But my question is for a very high quality guest post,  

#### [0:49:30](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=2970) |  for SEO purposes and generating lots of

traffic, having original helpful content, and even ranking high on Google, should the links be nofollow as well? And are those links being devalued? And the next one would be what's your take on websites with large amount of articles from industry experts or professional writers that contribute great content? Thank you.  

#### [0:50:00](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=3000) |  JOHN MUELLER: I think it's hard to

have kind of a general guidance there. But from our point of view, if these guest posts are really purely there for those links, then that would be something that the Web Spam team would be worried about. Would there-- there are lots of ways to do guest posts where you're essentially just driving publicity to your content or driving awareness of your content. And that's something where, from my point of view,  

#### [0:50:30](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=3030) |  I don't see that as being problematic.

There are two-- or the one way I look at it is if you, as the person writing this guest post, don't really care if that link is follow or nofollow, then that's a good sign that you're writing this with the intent of bringing awareness, reaching a broader audience, reaching other people. Whereas if you're saying that the only reason I would ever  

#### [0:51:00](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=3060) |  publish this guest post is to get

a link that does not have a nofollow attached to it, then that's kind of a sign that you're really just trading that post for a link. And that would be a problem. And focusing it on great content and really great people, smart people writing these posts-- that's something that I sometimes see as more of a distraction rather than the actual issue at hand there.  

#### [0:51:30](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=3090) |  But I do know there are some

sites that have guest authors that are posting. And they write fantastic content. But it's essentially someone who's writing on that website where there is an editor involved. And essentially, they're working to create normal content for that website. It's not some random guest post that they get submitted that they just publish one to one. JEMMY K: Thanks. JOHN MUELLER: So I don't think that really  

#### [0:52:00](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=3120) |  answers your question. But that's kind of

the way that we would look at it. Also, the other thing that is sometimes also worth keeping in mind is that when the Web Spam team takes a look at your website-- think about what they would see. It's something where sometimes the Web Spam team will take a look at a website and say, well, these links are all over the place. There's all kinds of linking happening here. And it's like, if there is something bad in between,  

#### [0:52:30](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=3150) |  then it happens. That's not the end

of the world. But if they look at a website, and they say, well, all of the important links to this website are guest posts-- and they're high quality guest posts on high quality sites. But all of the links to the site are guest posts-- then that's kind of a sign that maybe we need to be a bit more careful here with regards to the links to the site. JEMMY K: So I assume it's more of a spectrum instead of a black or white.  

#### [0:53:00](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=3180) |  JOHN MUELLER: Yeah, yeah. JEMMY K: OK,

thank you. MIHAI APERGHIS: John, in the infinite scrolling documentation, that old blog post, one of the best practices mentioned there is the fact that each separate pagination page, when accessed directly, should only have products for that specific page, so products from 20 to 40  

#### [0:53:30](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=3210) |  or something like that. And you shouldn't

really mix products together. So the reason why I'm asking this is I have a case where, if you go to page 2 of a certain category, you also have the products loaded from page 1. So you have page 1 plus page 2. If you go on page 3, you have page 1 and page 2 and page 3. And it kind of scrolls you down to page 3.  

#### [0:54:00](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=3240) |  So how much of a negative impact

does that have, having those previous pages also loaded on those pagination URLS? JOHN MUELLER: It really depends on what you're using the pagination for. So in a case like this, it looks like the primary objective is to find links to the product pages. And if we find those links on multiple pages, that's fine.  

#### [0:54:30](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=3270) |  It doesn't matter. In cases where you

have one really long article, or you have multiple articles that you're loading with infinite scroll, then it's more a matter of the content itself being indexed, not the links. And if by indexing the content, we have this mix of different articles on the same URL, then that's a problem. So that's kind of the differentiator. Is the reason for this infinite scrolling page  

#### [0:55:00](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=3300) |  finding links to other pages, in which

case duplicates are fine? Or is the infinite scroll the matter of finding indexable content on that page itself? And in that case, differentiating between the different pages is really important. MIHAI APERGHIS: But is the risk that if, for example, you have a category with 10 pages, and the last 10th page has all of the products for that category, because it loads all of the previous pages-- well, would Google kind of think,  

#### [0:55:30](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=3330) |  well, this seems to have everything that

I need. So I'll index that one and show that one in the search results. Is there a danger that might happen? JOHN MUELLER: No, I don't think so. I don't think that would be a problem, no. So I guess the main place where we saw this as actually causing problems is more on News websites. MIHAI APERGHIS: Content-based websites. JOHN MUELLER: Yeah, content-based websites and really in particular on News websites, where  

#### [0:56:00](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=3360) |  if you load multiple articles using infinite

scroll, and they end up being on the same page, then you can end up in a situation where you have two completely disconnected articles loading on the first page. And then the title is something like, this politician said X. And then in the bottom, there is an article about a car crash. And then suddenly for queries like politician plus car crash, oh, it's like this politician had a car crash. But--  

#### [0:56:30](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=3390) |  MIHAI APERGHIS: Right. JOHN MUELLER: It's essentially

completely disconnected articles on the same page. And that's something where we have ended up contacting sites and letting them know, hey, this is really a problem. And it almost causes news cycles of its own, because you go to Google and search politician name plus car crash. And all these articles-- and it's like, there's a conspiracy. Something is-- MIHAI APERGHIS: Yeah. JOHN MUELLER: --trying to be hidden. MIHAI APERGHIS: But so from an e-commerce point of view,  

#### [0:57:00](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=3420) |  given that the documentation features that specific

example for e-commerces, should websites try to not have that kind of issue, try to solve it? Or doesn't really matter? JOHN MUELLER: I think it is always a good practice, because then you don't accidentally run into this. But it's definitely not critical for e-commerce. MIHAI APERGHIS: OK. JOHN MUELLER: Especially, I mean, for e-commerce, we really need to find those links to the product pages and the category  

#### [0:57:30](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=3450) |  pages. The first paginated version of the

category page will almost always be the most important one, because-- MIHAI APERGHIS: Sure. JOHN MUELLER: --that's the one that's linked from the rest of your site. So that's something where I don't see this as being a problem for e-commerce. I think it's a good practice just to make sure you don't avoid that. But it's not going to change anything for e-commerce. MIHAI APERGHIS: OK, cool. JOHN MUELLER: Cool, OK.  

#### [0:58:00](https://www.youtube.com/watch?v=AK_lSVA6bcY&t=3480) |  Let's take a break here with the

recording. I'll pause here. As always, if any of you want to hang around a little bit longer, perfectly fine. Thank you all for joining. I hope you found this recording useful. And hopefully, I'll see some of you all again in one of the future hangouts. Bye, everyone. MIHAI APERGHIS: Bye, John.  