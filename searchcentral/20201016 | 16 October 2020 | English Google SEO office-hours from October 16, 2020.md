[![English Google SEO office-hours from October 16, 2020](https://i.ytimg.com/vi/JV7egfF29pI/hqdefault.jpg)](https://www.youtube.com/watch?v=JV7egfF29pI)

## English Google SEO office-hours from October 16, 2020

This is a recording of the Google SEO office-hours hangout from October 16, 2020. These sessions are open to anything webmaster related like crawling, indexing, mobile sites, internationalization, duplicate content, Sitemaps, Search Console, pagination, duplicate content, multi-lingual/multi-regional sites, etc. 



Watch out for new sessions, and add your questions at https://www.youtube.com/user/GoogleWebmasterHelp/community



Feel free to join us - we welcome webmasters of all levels!



Subscribe to the Google Search Central Channel â†’ https://goo.gle/SearchCentral



#### [0:00:00](https://www.youtube.com/watch?v=JV7egfF29pI&t=0) |  JOHN MUELLER: Hi, everyone, and welcome to

today's Google SEO Office Hours Hangout. My name is John Mueller-- I am a Search Advocate at Google in Switzerland. And part of what we do are these Office Hour Hangouts where people can join in and ask their question around their website and web search. A bunch of stuff was submitted already on YouTube. We can go through some of that. But if any of you want to get started with the first question, you're welcome to jump in now.  

#### [0:00:30](https://www.youtube.com/watch?v=JV7egfF29pI&t=30) |  ANDREJ KOCAK: Hey, John. JOHN MUELLER: Hi.

ANDREJ KOCAK: Hey. So we have a competitor who, on his website, has a great number of product reviews. And after a mutual agreement, we'd like to use some of his product reviews on our website, alongside our reviews, for the benefit of visitors who would be interested in them-- and they would help them to decide on the product. So we exchange-- we, like, naturally give him credit for the reviews by providing the full backlink from each of our product details pages,  

#### [0:01:00](https://www.youtube.com/watch?v=JV7egfF29pI&t=60) |  which will be used for other reviews

from this website. And in the end, we would end up with around 2000 backlinks linking to his site from our site that has around 12,000 pages. So both our and his websites are well-established and belong to the top 10 in the niche. And would Google see this as something that's OK? Or could this harm ours or his rankings? In order to avoid duplicate content and Google seeing the reviews on our website-- because we don't really want  

#### [0:01:30](https://www.youtube.com/watch?v=JV7egfF29pI&t=90) |  Google to see them because they're there

only for our users-- we are thinking about lazy-loading loading them. Would this be OK? JOHN MUELLER: So, I guess, starting with the last part-- lazy-loading is fine. It's fine, also, to have parts of your pages where you say, these should be excluded from the snippet. So using the data no-snippet, for example. If you're using reviews that are not sourced yourself, then you shouldn't use them in structure data--  

#### [0:02:00](https://www.youtube.com/watch?v=JV7egfF29pI&t=120) |  that's kind of the other thing. I

think that the trickier part is really with regards to the link there. And it sounds like you're kind of exchanging things of value there. And from my point of view, that kind of falls into the bucket of link exchange. And that could be something where the Web Spam Team would say this would be problematic. My general recommendation there would be, if this is on a larger scale, then I  

#### [0:02:30](https://www.youtube.com/watch?v=JV7egfF29pI&t=150) |  would definitely work to make these links

no-follow so that users can click through if they want and there is some value in that, at least. But that you're sure that it doesn't come across as, we're buying the reviews from them in exchange for backlinks. ANDREJ KOCAK: OK. So, basically, if we are going to give him credit, it should be no full credit? And maybe one link on the general web page  

#### [0:03:00](https://www.youtube.com/watch?v=JV7egfF29pI&t=180) |  saying that we are using reviews from

his website that could be a do-follow link? JOHN MUELLER: Yeah. I think that would be fine, yeah. ANDREJ KOCAK: OK. Yeah, great. Thank you very much. JOHN MUELLER: Sure. SAIDUL HOQUE: Hi, John. JOHN MUELLER: Hi. HOQUE: I had actually a few questions. Also [INAUDIBLE] actually [INAUDIBLE] question for the main question. So my first question is the main question. If we move a domain to another domain entirely,  

#### [0:03:30](https://www.youtube.com/watch?v=JV7egfF29pI&t=210) |  does that mean that the ranking, the

orders I have, they you have said we'll get all the ranking? JOHN MUELLER: It should transfer all of the signals. Yeah. If everything is otherwise fine, then all of that should transfer normally. And we've worked for a really long time to make these domain moves as smooth as possible. I think, for the most part, they work really well. Sometimes we do run into weird edge cases  

#### [0:04:00](https://www.youtube.com/watch?v=JV7egfF29pI&t=240) |  but it should, essentially, transfer everything. It's

trickier if you have one domain that already has existing content and you move something there, because then you're kind of merging two websites. But if you're really just moving from one domain to another one to one and it's just changing the domain name, essentially, then that's something we should be able to pick up very easily. SAIDUL HOQUE: Here's my next question. We have a client who provide big swimming pool  

#### [0:04:30](https://www.youtube.com/watch?v=JV7egfF29pI&t=270) |  and also build a spa. Now, what

they did before, they had one outside for swimming [INAUDIBLE] and other side for a spa. Now, they want to meld the spa side with the swimming pool side, so all the [INAUDIBLE] they had for the spa side, they want to relate to the swimming pool side. Because they create a category for spa and all the products [INAUDIBLE] there. But if we do this, the spa side, it has some [INAUDIBLE] ranking.  

#### [0:05:00](https://www.youtube.com/watch?v=JV7egfF29pI&t=300) |  Does this ranking will move to the--

the spa category, new product category [INAUDIBLE] on swimming pool side? JOHN MUELLER: Yeah. So that sounds like you're merging sites, right? SAIDUL HOQUE: Yes. JOHN MUELLER: In general, we do try to figure out what the right approach is with merging sites, but it's harder than when you're moving from one domain to another because you don't really know what the final outcome should be. So essentially, what happens is, on a page by page basis,  

#### [0:05:30](https://www.youtube.com/watch?v=JV7egfF29pI&t=330) |  we try to move things over. And

then on a whole across the whole website, we obviously have to kind of recalculate and rethink things. How the internal linking is, which of these pages are relevant, and how they're connected with the rest of the web as well. So that's something where I would expect some of these pages, on a page by page basis, if you're just moving them to essentially just transfer over, and for a lot of the rest, it will probably take  

#### [0:06:00](https://www.youtube.com/watch?v=JV7egfF29pI&t=360) |  a bit of time to settle down.

And I imagine you'll see a positive effect of merging these two sites together but it's something where it's hard to say what the final outcome will be because it's not like all of the traffic from site A plus all of the traffic from site B but some kind of mixture in the end. SAIDUL HOQUE: And the last question. This is [INAUDIBLE] opposite of the [INAUDIBLE].. The one point will be garden [INAUDIBLE] and will be playground for the kids.  

#### [0:06:30](https://www.youtube.com/watch?v=JV7egfF29pI&t=390) |  Now, the playground for the kids, they

want you to separate domain for the playground section, and all the product they have on the website, they want to [INAUDIBLE] those products to the new domain. The question is, the old website, the ranking they have for the playground with the keywords, will the new website [INAUDIBLE] have those ranking? JOHN MUELLER: Maybe. I think splitting sites up is almost harder than merging them.  

#### [0:07:00](https://www.youtube.com/watch?v=JV7egfF29pI&t=420) |  But it's a similar situation where you

can't do it purely on a page by page basis because of all of the things like internal linking will be very different if you take things out of one website. I think sometimes it makes sense to separate things out. For the most part, I generally recommend concentrating things more rather than separating them out. But sometimes there are really good reasons  

#### [0:07:30](https://www.youtube.com/watch?v=JV7egfF29pI&t=450) |  to split things out across separate domains.

SAIDUL HOQUE: Thank you. OLIVER AZIMI: John, can I ask a question regarding side [INAUDIBLE]? JOHN MUELLER: Sure. OLIVER AZIMI: Could it be the case, if you're moving to a domain that previously had those associated selling illegal drugs or pornography, could it affect the transfer of page rank and signals over? Or do some-- you have some sort of algorithmic demotion  

#### [0:08:00](https://www.youtube.com/watch?v=JV7egfF29pI&t=480) |  that affecting the new site? JOHN MUELLER:

Yeah. That can happen. So for example, if there is-- if the old domain, or the domain that you're moving to, was an adult content domain, then that's something where it can happen that our safe search algorithms stick to that classification and say, well, this is adult content.  

#### [0:08:30](https://www.youtube.com/watch?v=JV7egfF29pI&t=510) |  And it can take quite a bit

of time for that to settle down and get dropped. With regards to, I don't know, other kinds of spam, it really depends a bit-- I mean, other kinds of spam. It's not necessarily spam if it's just adult content. But with regard to other kinds of, like, problematic or tricky content, it is something where, for a large part, we try to replace it with the new version.  

#### [0:09:00](https://www.youtube.com/watch?v=JV7egfF29pI&t=540) |  But sometimes there are effects that are

also outside of the website as well, such as maybe there are lots of external links pointing to the site with problematic anchors. That might be something where, on the one hand, we might be ignoring these already, or it could be even that they're causing problems for the website. So if you're moving to a site that has a longer history, then that is something to consider. That it might be harder to get it into a neutral state again.  

#### [0:09:30](https://www.youtube.com/watch?v=JV7egfF29pI&t=570) |  OLIVER AZIMI: Yeah. I've seen one case

that we moved the spammy domain, initial traffic dropped like I don't know 75% at the time. But after broad core updates, around six months later, we actually recovered most of the traffic. I don't know what-- JOHN MUELLER: OK. OLIVER AZIMI: That's very weird I think. JOHN MUELLER: I think that can happen. Yeah.  

#### [0:10:00](https://www.youtube.com/watch?v=JV7egfF29pI&t=600) |  In general, with our algorithms, we try

to make it so that they adapt over time to things like that. If we move things over and we have these residual signals for the new domain that you're moving to, then that should settle down over time. And sometimes that takes a couple of months, sometimes that takes a year. Depending on what the domain was doing beforehand, it's easier  

#### [0:10:30](https://www.youtube.com/watch?v=JV7egfF29pI&t=630) |  or it's harder. BRITTANY MCCULLOUGH: John, that's

very related to my question. So when we migrated our domain, we checked for any links to the-- before we even decided to do the migration, we checked for any links to the new domain, we checked for content history. There are only two links, no content for 10 years, at least according to the Wayback Machine. What other things should we have looked for? What's within our control to check for a new domain SO  

#### [0:11:00](https://www.youtube.com/watch?v=JV7egfF29pI&t=660) |  that we don't run this risk? Because

that seems to be the indication we're getting is that that's what's going on with us. So we don't want to run into this in the future and also still don't really know what to do right now. JOHN MUELLER: Yeah. I don't know. I saw your question this morning. One of the things on our side is we're still looking into some of the other signals that were missing there. And at the moment, I'm mostly trying  

#### [0:11:30](https://www.youtube.com/watch?v=JV7egfF29pI&t=690) |  to push the team into just getting

it resolved as quickly as possible. I think that first step was good but it does turn out that there are other things that are stuck there as well. I don't know what exactly else you should be watching out for. So I think the obvious ones are, really, the things that you looked at. Like, the links to the site, the previous content. Sometimes it's a bit tricky in that really spammy domains  

#### [0:12:00](https://www.youtube.com/watch?v=JV7egfF29pI&t=720) |  try to hide their history in the

Wayback Machine. But I don't think that's the case with the site that you moved to. So I don't really know what you could have done differently there. No. BRITTANY MCCULLOUGH: OK. Thanks. JOHN MUELLER: It's a bit frustrating. I wish we could get this resolved a little bit faster. BRITTANY MCCULLOUGH: OK. Thank you. JOHN MUELLER: Sure. KUBA SERAFINOWSKI: Hi, John. I wanted to ask about your thoughts on Carousel in Europe  

#### [0:12:30](https://www.youtube.com/watch?v=JV7egfF29pI&t=750) |  and the eligibility criteria for that. Could

you explain how to get featured there? Because our domains are market leaders in some of the countries in Europe and we feel that we should be eligible for that but there is no documentation whatsoever. JOHN MUELLER: Which Carousel did you mean? KUBA SERAFINOWSKI: The C results one.  

#### [0:13:00](https://www.youtube.com/watch?v=JV7egfF29pI&t=780) |  Like, C related results. For example, if

you're looking for a mechanic, you would see [INAUDIBLE] like Gumtree or OLX. JOHN MUELLER: OK. I don't know. If you want-- let me just drop my email address here. If you want to maybe send me an email with what exactly you're seeing and what your site is,  

#### [0:13:30](https://www.youtube.com/watch?v=JV7egfF29pI&t=810) |  I can try to find someone and

pass that on. KUBA SERAFINOWSKI: All right. That's awesome. Thank you. JOHN MUELLER: In general, a lot of these, I don't know, extra links. I don't even know what they're called, where you link to other sites for more information, is something that happens algorithmically. But I don't know how things are handled in that particular case on your side. KUBA SERAFINOWSKI: OK. I'll send an email. Thank you. JOHN MUELLER: Sure. OK.  

![](https://i.ytimg.com/vi/JV7egfF29pI/hq1.jpg)



#### [0:14:00](https://www.youtube.com/watch?v=JV7egfF29pI&t=840) |  Let me go through some of the

submitted questions. We have Brittany's question on top. I think we looked into that already. Let's take a look at the next one. We have a large site and a section on the site we have a forum. This forum is in old CMS and it's difficult to optimize for speed. We're looking to make sure that we have good Core Web Vitals score before 2021. If we're unable to improve the speed of this forum, will this only effect the keywords that rank on the forum pages, or could it affect the ranks of the pages  

#### [0:14:30](https://www.youtube.com/watch?v=JV7egfF29pI&t=870) |  that aren't on the forum and that

are faster? Basically, is speed looked at on a page by page basis or could slow speed on some pages of your site affect how Google sees your site as a whole? Good question. In general, with our algorithms, we try to be as fine grained as possible. So if we can get granular information for your site and recognize the individual parts of your website properly, then we will try to do that. However, it depends a little bit on your site and how much data  

#### [0:15:00](https://www.youtube.com/watch?v=JV7egfF29pI&t=900) |  we have for your site, especially when

it comes to speed. Where it's based, or it will be based, because it's not live yet, it'll be based on the Core Web Vitals on the Chrome User Experience Report data, which is just a very small sample of the people that visit your site aggregated. That's something that doesn't have data for every URL of a website. So depending on how much data is available there  

#### [0:15:30](https://www.youtube.com/watch?v=JV7egfF29pI&t=930) |  and how easily it is for us

to figure out which parts of your site are separate, then that's something that we can do easier or that is a little bit harder. We have similar things, I guess similar mechanisms, across various other signals that we use in search. One of them, for example, is with adult content where if you have a part of your website with adult content  

#### [0:16:00](https://www.youtube.com/watch?v=JV7egfF29pI&t=960) |  and a part of your website that

has normal content or other content on it, then the easier we can recognize that these are separate parts and separate them out individually, the more likely it is that we can just treat that one part slightly differently. You can do that with things like making sure you have a clean subdirectory structure on your site or using subdomains if that makes sense for your website. The easier, in your case, it would be, for example, to split out the forum from our site where we can tell,  

#### [0:16:30](https://www.youtube.com/watch?v=JV7egfF29pI&t=990) |  oh, slash forum is everything forum and

it's kind of slow, and everything else that's not in slash forum is really fast. If we can recognize that fairly easily, that's a lot easier. Then we can really say, everything here in slash forum is kind of slow, everything here is kind of OK. On the other hand, if we have to do this on a per URL basis where the URL structure is really-- we can't tell based on the URL if this is a part of the forum or part of the rest of your site, then we can't really  

#### [0:17:00](https://www.youtube.com/watch?v=JV7egfF29pI&t=1020) |  group that into parts of your website.

And then we'll be forced to take an aggregate score across your whole site and apply that appropriately. I suspect we'll have a little bit more information on this as we get closer to announcing or closer to the date when we start using Core Web Vitals in search, but it is something you can look at already a little bit in Search Console.  

#### [0:17:30](https://www.youtube.com/watch?v=JV7egfF29pI&t=1050) |  There is a Core Web Vitals report

there, and if you drill down to Individual Issues, you'll also see this your URL affects so many similar URLs. And based on that, you can already kind of tell, oh, is Google able to figure out that my forum is grouped together or is it not able to figure out that these belong together? OK. And now a really long question from David who doesn't like Pinterest. Is the indexing API going to open up to general URLs?  

#### [0:18:00](https://www.youtube.com/watch?v=JV7egfF29pI&t=1080) |  I don't know. My guess is it'll

be tricky. Because we see a lot of abuse with all of these submit to indexing features that we have. I don't know if it would make sense to open up yet another channel that we have to figure out how to deal with more abuse on. Is this ever going to be in the API? I hope so.  

#### [0:18:30](https://www.youtube.com/watch?v=JV7egfF29pI&t=1110) |  I will take this question as a

nudge and ask the team again. Can we have fetch and render API that has a static IP or a unique user agent? I don't think so. Mostly because the fetch and render feature or the inspect URL feature in Search Console is meant to reflect what Googlebot would actually see and is not meant to be used as a single request fine tuning  

#### [0:19:00](https://www.youtube.com/watch?v=JV7egfF29pI&t=1140) |  for Googlebot in the sense that you

have a specific IP address or a specific user agent there. I don't think that's something we'd be able to do. A suggested feature, a Google parser or breaker. Is there something in the code you can fetch that can break your parser? For example, a few years ago, an image tag in the head would break parsing and, therefore, terminate the head prematurely. We want to make sure that our terrible HTML isn't causing issues.  

#### [0:19:30](https://www.youtube.com/watch?v=JV7egfF29pI&t=1170) |  I guess the easy solution is not

to make terrible HTML. It sounds like you're pretty advanced so you can figure that out. But the part with individual elements in the head, that still applies in the sense that when we render a page, similar to a browser, if there are elements in the head of the page that belong to the body, then we will open up the body and treat the rest of that section, essentially, as part of the body.  

#### [0:20:00](https://www.youtube.com/watch?v=JV7egfF29pI&t=1200) |  And there are specific elements that we

really need to be able to find in the head of the page so that we can take them seriously. That includes things like the rel canonical, the robot's meta tags, and HR flang links, for example. So if you have elements on top of the head of the page that, essentially, break the head in the dom, that's something that could cause problems for those elements.  

#### [0:20:30](https://www.youtube.com/watch?v=JV7egfF29pI&t=1230) |  I don't think you explicitly see that

in infection render or inspect URL in Search Console because we just say, well, oh, it looks like-- it looks like the webmaster wanted to start the head of the page here. We will just treat the rest like it is. Or treat the rest like it is, a part of the body. We wouldn't necessarily see that as a bug or something that the site is doing wrong, but rather we're just trying to deal with a broken HTML that  

#### [0:21:00](https://www.youtube.com/watch?v=JV7egfF29pI&t=1260) |  is out on the web. Extend the

API. Some of us are using screen scraping techniques to extract a lot of data that isn't available on the API. Why not make it available and monetize it? So I don't think we'd want to monetize the API. That's the first step there in the sense that everything around money is really hard at Google, especially when dealing with customers and all of that. So I don't think that would be something that we'd monetize.  

#### [0:21:30](https://www.youtube.com/watch?v=JV7egfF29pI&t=1290) |  I do think it would be really

nice to extend the API, but it's really hard to encourage the product leadership to start doing more on the API side. So if you have any arguments that you think would be really useful in terms of, this is how we can make search better if we were able to pull data through the API, that  

#### [0:22:00](https://www.youtube.com/watch?v=JV7egfF29pI&t=1320) |  would be really useful for us. So

feel free to send that our way and we'll pass that on to the team. Bring back advanced search operators. I don't really see this happening because it's so-- it's something that, really, most sites, or most users, don't actually use and that they're really a lot of work to maintain, especially across the ever changing infrastructure in Google search. Maintaining some of these features that not a lot of people use is really expensive.  

#### [0:22:30](https://www.youtube.com/watch?v=JV7egfF29pI&t=1350) |  Bring back site removals. Pinterest is a

parking meter of the internet. No one likes to see them. I don't know. Bring back site removal. This sounds like you want to remove other people's sites. I'm sure the SEO of Pinterest would be against that. I don't know. I don't use Pinterest personally but I do see a lot of people getting value out of that. There is a lot of good content there so I don't know.  

#### [0:23:00](https://www.youtube.com/watch?v=JV7egfF29pI&t=1380) |  I think, in general, with regards to

site removals, especially on a personal level where you could say, I don't want to see this site anymore, I think that's an interesting idea. I think implementation is just really, really hard with all of the different ways that sites can be visible in search nowadays. Is there any preferred time zone for the last modification date? Yes.  

#### [0:23:30](https://www.youtube.com/watch?v=JV7egfF29pI&t=1410) |  Well, in the last modification date you

should be specifying a time zone. It doesn't matter which time zone you use, but it should have a time zone. I think that's part of the daytime standard that's used in the XML file. How sensitive is Google when it is about to ignore the last modification date? In general, we use it as a guide to understand when pages have changed. It's not so much that it has to be exact,  

#### [0:24:00](https://www.youtube.com/watch?v=JV7egfF29pI&t=1440) |  but rather we have to be able

to understand, oh, this page has changed since the last time we looked at it so we should look at it again. From that point of view, it's important for us to be able to roughly trust the last modification date. In particular, the thing that we sometimes see is that people generate site map files and they just use the current date for the last modification date for all URLs, and that's something that's obviously wrong.  

#### [0:24:30](https://www.youtube.com/watch?v=JV7egfF29pI&t=1470) |  When we look at the site mod

file and there are 10,000 URLs in there and they were all updated in the last minute, that's probably you're calculating the last modification date wrong. And from our point of view, it's not so much that we want to penalize the website for doing that, it's just, well, there isn't a lot of signal, a lot of useful information in that site mod might file for us to work on other than perhaps there's some new URLs that we haven't seen at all there before. So in a case like that, if you just  

#### [0:25:00](https://www.youtube.com/watch?v=JV7egfF29pI&t=1500) |  need to always have the same last

modification date or if you can't specify it at all, we can at least pick up the new URLs, but we wouldn't be able to know when the old URLs actually changed. Let's see. Question goes on in-- oops-- I think a slightly different direction. We update our meta robots frequently, index and no index, and two months ago we implemented last modification on product pages which are back in stock in the last seven days  

#### [0:25:30](https://www.youtube.com/watch?v=JV7egfF29pI&t=1530) |  and marked them as indexed but we

didn't see any impact and submitted URL marked no index. I manually checked some of the last modification URLs, Google never seems to follow them. In general, I think this fluctuation between indexed and non indexed is something that can throw us off a little bit. Because if we see a page that there is no index for a longer period of time, we will assume that this is kind of like a 404 page and we don't have to crawl at that frequently. So that's something where probably what  

#### [0:26:00](https://www.youtube.com/watch?v=JV7egfF29pI&t=1560) |  is happening there is that we see

these pages as no index and we decide not to crawl them as frequently anymore regardless of what you submit in the site mod file. So that's something where fluctuating with the meta no index is probably counterproductive here if you really want those pages to be indexed every now and then. SANJAY SANWAL: So, John-- hello.  

#### [0:26:30](https://www.youtube.com/watch?v=JV7egfF29pI&t=1590) |  JOHN MUELLER: Yeah? SANJAY SANWAL: So large--

more data is not useful in that case where we've [INAUDIBLE] our [INAUDIBLE]?? JOHN MUELLER: What I would try to do in a case like that is maybe set up a page that you can persistently maintain and link from there to the individual products that you want to have listed or not listed. And then maybe focus more on that persistent page  

#### [0:27:00](https://www.youtube.com/watch?v=JV7egfF29pI&t=1620) |  rather than on the individual products that

come in and go out. SANJAY SANWAL: OK. And you mentioned that [INAUDIBLE].. Where do we have to mention that what types we are using? JOHN MUELLER: So I assume you're talking about the site mod file, right? SANJAY SANWAL: Yes. Yes. Yes. JOHN MUELLER: Yes. OK. So in the site mod file for the last modification date, the date time uses a specific standard.  

#### [0:27:30](https://www.youtube.com/watch?v=JV7egfF29pI&t=1650) |  In that standard, it has the time

zone attached to the end. If you have a z at the end of the day time, then that means it's, I think, UTC time. But you can also specify different time zones there. SANJAY SANWAL: OK. [INAUDIBLE] end of every last word tag we have to mention [INAUDIBLE]. JOHN MUELLER: Yes. Well, I would make sure that you're doing it in the right standard. I would check the site mod file documentation and look up  

#### [0:28:00](https://www.youtube.com/watch?v=JV7egfF29pI&t=1680) |  the daytime standard that we use there.

It's, like, RFC and some number. Usually there is a Wikipedia page with a lot of examples where you see with time zone, without, with the UTC or the z at the end so that you can compare that. SANJAY SANWAL: Thank you. JOHN MUELLER: Sure.  

![](https://i.ytimg.com/vi/JV7egfF29pI/hq2.jpg)



#### [0:28:30](https://www.youtube.com/watch?v=JV7egfF29pI&t=1710) |  OK. In light of the recent indexing

issues, any update on the last 45% affected canonical URLs that still hasn't been restored? Is it OK to submit affected URLs manually in Search Console? Can you shed some light on what happened here? What is Google to present-- doing to prevent this in the future? I don't have any big updates on this at the moment. I haven't been following up on that. I think Dani has mostly been keeping track of that  

#### [0:29:00](https://www.youtube.com/watch?v=JV7egfF29pI&t=1740) |  and pushing things along. One thing I

can mention here is you can't use the site-- inspect URL and submit to indexing feature in Search Console because, at the moment, that's in maintenance. So that's kind of tricky there. I don't know for individual sites how strongly you would still see this because my understanding is usually these kinds of issues  

#### [0:29:30](https://www.youtube.com/watch?v=JV7egfF29pI&t=1770) |  are resolved for the visible URLs of

pretty much all sites fairly quickly within a day or so. But if you're still seeing a really strong effect from this, maybe drop me a note on Twitter and I can take a look with the team to see if maybe there is something else that's happening with your site in particular. I was wondering how Google search was evaluating the ad experience as a ranking factor? It's easy to estimate the readability of a font size, but I have trouble wrapping my mind  

#### [0:30:00](https://www.youtube.com/watch?v=JV7egfF29pI&t=1800) |  around how much a huge sticky video

on mobile would impact ranking. Let's say, 30% to comply better ad standard but still highly deceptive disruptive experience. I had to double check but as far as I know, we don't use the Ad Experience Report as a ranking factor in Search. But rather, this is something that is specifically in Chrome where if we see that a site does not comply with the standard  

#### [0:30:30](https://www.youtube.com/watch?v=JV7egfF29pI&t=1830) |  and we can confirm that, ; then

Chrome will automatically not display those ads. So it's not something that we would, essentially, really need to use in Search because Chrome would handle that anyway, but it is something where probably the effects that you would see in Search would be based on things like the above the fold content or the--  

#### [0:31:00](https://www.youtube.com/watch?v=JV7egfF29pI&t=1860) |  I forgot what we use-- not the

intrusive interstitials but the if you have a lot of ads on top part of your page. That's probably where you would see an effect from Search. I forgot what the name was we had for that. It is one of the-- I don't know, maybe two, three years old-- things where we launched something around making sure that the top part of the page is actually content.  

#### [0:31:30](https://www.youtube.com/watch?v=JV7egfF29pI&t=1890) |  I don't know how the font readability

would fit into that. My feeling is the font size would be more something that would affect whether or not we would see a page as being mobile friendly. And that's something that would apply for the mobile search results but not for the general search results. So I don't think I really answered your question there but I'm not 100% sure what direction I should go there.  

#### [0:32:00](https://www.youtube.com/watch?v=JV7egfF29pI&t=1920) |  I wanted to know how we can

stop paginated pages from ranking. I want them to index but not to rank, as I always want the first page rank and not page two or page three. But I can't even add no index as the listings mentioned in those second and third are important. If anyone searches for a specific name, I want to listings mentioned on page two and three also to rank. But I don't want other pages other than page one to rank. That's, I think, a tricky situation in terms of you  

#### [0:32:30](https://www.youtube.com/watch?v=JV7egfF29pI&t=1950) |  can't really specify where you want your

pages to rank or whether or not they should be shown in the search results if you want them to be indexed. So if they're indexed, then our systems will try to figure out how to rank them appropriately. So that's-- you're in that situation where you want both things, both have an index but not have it counted kind of thing, and--  

#### [0:33:00](https://www.youtube.com/watch?v=JV7egfF29pI&t=1980) |  well, not have it indexed and have

it counted-- but that's not really something that's fully supported there. What we generally recommend when it comes to pagination is to allow your paginated pages to be indexed, block your filtered pages from being indexed because these are essentially links to the same products as you had before, unless there are individual filtered versions that you would consider something more like a category page.  

#### [0:33:30](https://www.youtube.com/watch?v=JV7egfF29pI&t=2010) |  With regards to paginated pages, one way

you can make sure that we focus more on the first page is to link incrementally between the pages of your paginated set. So instead of linking from page one to page two, three, four, five, six, seven, and all of the other ones, link from page one to page two and from page two page three, page three to page four, so that when we look at that, we see that the first page is highly  

#### [0:34:00](https://www.youtube.com/watch?v=JV7egfF29pI&t=2040) |  mentioned within your website. So clearly this

must be a very important page. And the other ones are incrementally less important because they're further and further away from your home page. By doing it like that, you can have those pages be indexed, but we will understand that these are not really that relevant for your site. And usually that does end up with us focusing on the first page. Especially if someone is searching for a category, then we can focus on that first page and say, this is clearly the best page for that category.  

#### [0:34:30](https://www.youtube.com/watch?v=JV7egfF29pI&t=2070) |  The site map we submitted from years

ago keeps updating the Submit a Date in Search Console. It looks like it's getting resubmitted but no one on the account has resubmitted it. This happened a couple times a month. What might be happening there? So it's hard to say without knowing which site you're looking at. But one of the things that does happen is that, or can happen,  

#### [0:35:00](https://www.youtube.com/watch?v=JV7egfF29pI&t=2100) |  is that there is the anonymous submission

feature for site map files where you can just ping a specific URL and Google will see that as a resubmission of the the site map file and try to reprocess it. And usually that is used by CMS's or site maps plug-in, those kinds of things where when you update something it automatically pings that URL and let's Google and the other search engines know,  

#### [0:35:30](https://www.youtube.com/watch?v=JV7egfF29pI&t=2130) |  something changed in the site map file.

And that would be treated as a resubmission from our side and we would probably track that or show that in Search Console as well. So it's not so much that someone is manually going in there and clicking that button, but it could very well be that your CMS is doing that for you and taking some of that work out of your hands and saying, well, we can deal with this automatically. Theoretically, it could also be that someone else is resubmitting your site map file because it  

#### [0:36:00](https://www.youtube.com/watch?v=JV7egfF29pI&t=2160) |  doesn't need to be tied to your

account to ping that update URL. I imagine it's very unlikely that someone else is randomly submitting-- resubmitting your site map like this because there's really no reason to do that. It doesn't help them, it doesn't really change anything from your side, so from that point of view, my guess is it's probably just your CMS that is doing this for you.  

#### [0:36:30](https://www.youtube.com/watch?v=JV7egfF29pI&t=2190) |  Rendering check question. We have a website

single page application where when we check the index URL and the URL inspection tool it looks fine. Rendering a mobile friendly test looks good as well. But when we test the live URL, the HTML is minimal and the screenshot is blank. What might be the reason for this discrepancy? My guess, just based on this question without looking at the URLs, is that we have trouble rendering the page at a high speed.  

#### [0:37:00](https://www.youtube.com/watch?v=JV7egfF29pI&t=2220) |  When it comes to Google Search, we're

very patient and we render pages, essentially, if they take a little bit longer that's fine, if some of the embedded content isn't available yet, we will fetch that individually and then use that for rendering. But with the testing tools, we want to give you an answer as quickly as possible. And when we see someone is using one of these testing tools, we set the time outs a little bit more aggressively just so that we can give people an answer.  

#### [0:37:30](https://www.youtube.com/watch?v=JV7egfF29pI&t=2250) |  That means that if you're using these

tools to look at the screenshot or look at how things are rendered, it's very possible that some of the embedded content, especially if you're pulling things from an API or from your back end, that they're timing out for that specific test. On the one hand, if it works in Search then you're probably fine because Search, like I mentioned, is a little bit more patient. On the other hand, it makes it a little bit harder  

#### [0:38:00](https://www.youtube.com/watch?v=JV7egfF29pI&t=2280) |  to debug so I would try to

look into how much embedded content is actually needed for your pages to load. You can look at a waterfall diagram and things like webpagetests.org or in Chrome Developer Tools directly and make a rough estimation of, is this something that I can improve? Can I maybe fold some of these files together so instead of 300, 400 requests  

#### [0:38:30](https://www.youtube.com/watch?v=JV7egfF29pI&t=2310) |  it just takes 100 requests to render

this page. And if so, then that can make it easier for you to debug. And it does make it more likely that we won't accidentally run into issues when we render for Search as well. Of course, usually it makes things faster for users too which is a nice side effect. My recommendation there would be not to panic if it's working in Search but still to look into ways that you can improve that over time.  

#### [0:39:00](https://www.youtube.com/watch?v=JV7egfF29pI&t=2340) |  Is it recommended to use keywords as

it is in the content to get the best results in Google? Does the crawler use the fundamentals of AI to make a combination of keywords that are closely related with the content and then rank them? We want to know how a crawler picks up and makes combinations of keywords so you're ranked on Google. We don't make up the keywords and say this page will rank for these keywords. But rather, we take the queries and we  

#### [0:39:30](https://www.youtube.com/watch?v=JV7egfF29pI&t=2370) |  try to find the best matching pages

for that. So one-- the simplest approach that we take is we split a page into words and we store all of the words in an inverted index so that when we know that someone is looking for this combination of words then we can find all of the documents that have those words in them. And then based on that list of documents, we can reorder that list and say, well, this is the right order that we should be showing these  

#### [0:40:00](https://www.youtube.com/watch?v=JV7egfF29pI&t=2400) |  to people. So it's not so much

a matter of Google reading the content and then deciding which keywords to use, but rather, we getting the keywords and then deciding which document to actually show in the search results. I think the fundamentals of AI is something that always comes up because we talk about this all the time as well, especially in the more marketing and user side of Search where we use things  

#### [0:40:30](https://www.youtube.com/watch?v=JV7egfF29pI&t=2430) |  like Burt to improve the quality of

our search results. Which is, ultimately, machine learning, artificial intelligence algorithm. For a large part, these algorithms are there to try to help deal with cases where we don't really understand what the user is searching for. We still see about 15% of all searches are completely new every day. These aren't things that we can prepare for and we have to estimate what is the user actually searching  

#### [0:41:00](https://www.youtube.com/watch?v=JV7egfF29pI&t=2460) |  for? Are there any acronyms in there?

Are there synonyms that we can use? Is there singular or plural that we can figure out? That's something we, for the longest time, we used to do more algorithmically and make hard rules where we say, oh, if there's an s maybe it's a plural. But that doesn't apply to all languages and all kinds of words. So for that we use a lot of machine learning now to really understand better what is it that people are actually  

#### [0:41:30](https://www.youtube.com/watch?v=JV7egfF29pI&t=2490) |  looking for instead of just matching individually

the individual words in a query. GRANT DOSHLAKU: Hey, John? JOHN MUELLER: Hi. GRANT DOSHLAKU: Sorry for interrupting. JOHN MUELLER: Go for it. GRANT DOSHLAKU: Quick question. Did you have the chance-- just following up on our last discussion two weeks ago. Did you have the chance to look into the site that they shared on the chat? The site that had the the jump of about 40% and that  

#### [0:42:00](https://www.youtube.com/watch?v=JV7egfF29pI&t=2520) |  went recently through a light redesign? I'm

not sure if you know what I'm referring to. JOHN MUELLER: I don't remember which one. GRANT DOSHLAKU: It was a digital trends website. JOHN MUELLER: Yeah. Oh, I think I passed it on to the team. Yeah. I don't know if I heard anything back there, though. GRANT DOSHLAKU: So, basically, because we are still working into that and one question that we had,  

![](https://i.ytimg.com/vi/JV7egfF29pI/hq3.jpg)



#### [0:42:30](https://www.youtube.com/watch?v=JV7egfF29pI&t=2550) |  because we are still-- and I think

that ad experience question that you had on the chat and the-- I think you were trying to mention the Page Layout algorithm. JOHN MUELLER: Oh, yeah. GRANT DOSHLAKU: Yeah. JOHN MUELLER: [INAUDIBLE]. GRANT DOSHLAKU: So-- JOHN MUELLER: You should answer these questions. GRANT DOSHLAKU: Yep. So how long does it take to recover from a Page Layout algorithm if you've been impacted by it?  

#### [0:43:00](https://www.youtube.com/watch?v=JV7egfF29pI&t=2580) |  JOHN MUELLER: For a lot of these

quality algorithms, I don't know if we have a specific time where we can say that it's been resolved now. It depends a little bit on-- I don't know specifically with or with Page Layout algorithm-- but with a lot of these we do look at it more on a broader level for a website where we say, well, we can't test every page individually for this but we've seen a large part of the pages  

#### [0:43:30](https://www.youtube.com/watch?v=JV7egfF29pI&t=2610) |  for this site have this issue. In

cases like that, it is something where we have to, first, understand, well, a large part of this site doesn't have this issue anymore. And that means we have to reprocess the larger part of the site. Which is something that can easily take a couple of months. So if you're making changes like that and you're essentially affecting the quality of your pages overall, then that is something that I would expect  

#### [0:44:00](https://www.youtube.com/watch?v=JV7egfF29pI&t=2640) |  is not going to happen overnight. It's

not going to happen within a week. It's more a matter of, I don't know, two, three, four, five months maybe where we really understand, well, the site has significantly changed. GRANT DOSHLAKU: Yep. So could it be related to having an ad that is about, let's say, 30% and it appears above [INAUDIBLE].. Could that trigger the Page Layout algorithm? JOHN MUELLER: We don't have any specific percentages  

#### [0:44:30](https://www.youtube.com/watch?v=JV7egfF29pI&t=2670) |  that we would talk about there with

the Page Layout algorithm. I could imagine that if you're talking about something that is really a bigger part of a page, that could be affecting there. But we don't have specific numbers where we tell you, oh, the ad has to be maximum this many pixels or this many percent of the viewport. That's not something we have. GRANT DOSHLAKU: One other question.  

#### [0:45:00](https://www.youtube.com/watch?v=JV7egfF29pI&t=2700) |  And this is just trying to find

if we missed something. What could be some reasons that would cause the drop of traffic 35% to 40% across subdomains, not just the main domain, but across subdomains as well? Like, that could be-- that could cause this? JOHN MUELLER: I don't know. Lots of things. It's really hard to say because, on the one hand,  

#### [0:45:30](https://www.youtube.com/watch?v=JV7egfF29pI&t=2730) |  there are things like our understanding of

the quality, which can change. And that is something that could affect the larger part of the website. But it's really hard to say, in general. Because on the one hand, we make algorithm changes, the rest of the web changes all the time, and all of that plays in together. Even if you don't make any changes on your website then  

#### [0:46:00](https://www.youtube.com/watch?v=JV7egfF29pI&t=2760) |  that can, at some point, cause either

a [INAUDIBLE] decline or a really strong drop. GRANT DOSHLAKU: Yeah. When you're talking about quality issues, would it cause quality issues if, let's say, for example, we are updating the content frequently but not significantly? Would that be an issue? Would Google take some issues into us doing that?  

#### [0:46:30](https://www.youtube.com/watch?v=JV7egfF29pI&t=2790) |  JOHN MUELLER: I think that's perfectly fine.

I don't think that that would be generally a problem. Usually what I see with regards to quality issues is really when-- I don't know-- when you look at the website overall and you can tell that users aren't trusting the content as much anymore or they're just not sure about the content anymore. Then that's something where I'd say there are more clear cut  

#### [0:47:00](https://www.youtube.com/watch?v=JV7egfF29pI&t=2820) |  quality issues. Just individual updates of a

site or making a lot of changes on a site or making few changes on a site, that's usually more the usual noise that is out there on the web. And that's something that some sites make a lot of changes, some sites don't make a lot of changes. That's all fine. GRANT DOSHLAKU: And last question. Yahoo syndicates a lot of our content. In the majority of cases, our content  

#### [0:47:30](https://www.youtube.com/watch?v=JV7egfF29pI&t=2850) |  ranks first because Google recognizes us as

the source of the content. But Yahoo doesn't canonicalize its content that it's syndicating from us. And in some rare cases, they manage to rank above us for some content that is created by us. Could that be a cause for a job like this? JOHN MUELLER: No. I don't think so. I think that's something where, ultimately, the issue that you'll see is that these syndication  

#### [0:48:00](https://www.youtube.com/watch?v=JV7egfF29pI&t=2880) |  sites essentially rank as well in the

search results and sometimes they rank above your content because just, like, for whatever reasons. But it's not a sign that we would say your site is lower quality because it's syndicating content to other sites. I think, in general, that would almost be the opposite. That if other sites are wanting to syndicate your content, then that's a good side. GRANT DOSHLAKU: Yeah. We are circling back always to the--  

#### [0:48:30](https://www.youtube.com/watch?v=JV7egfF29pI&t=2910) |  to us being affected by the Page

Layout algorithm. And we made changes and we now understand that it will take some months for those changes to be recognized. But how can we make sure that those are the necessary changes? Like, what else are we missing or how can we check to make sure that after two three months we don't realize that, oh, we missed this thing and we should have changed this as well? JOHN MUELLER: I don't think you can, unfortunately. I don't think there is a--  

#### [0:49:00](https://www.youtube.com/watch?v=JV7egfF29pI&t=2940) |  I mean, there definitely isn't a testing

tool that will tell you what specifically you need to change with regards to your website's quality. The best I would recommend is to get a lot of people's opinions on it. So that could be something where you could go to the Webmaster Health forum and say, from a quality point of view, what else should we be taking into account? And sometimes you get a lot of feedback that is less relevant,  

#### [0:49:30](https://www.youtube.com/watch?v=JV7egfF29pI&t=2970) |  maybe small details, but sometimes you also

get some feedback on issues that you've been trying to push out of your mind for a while and that you actually should focus on a bit more. GRANT DOSHLAKU: Thanks a lot. JOHN MUELLER: Sure. All right. Maybe I'll just open it up to more questions from any of you. LENE HEGLAND: Hi, John. I have a question related to the merging of the websites that we talked about earlier.  

#### [0:50:00](https://www.youtube.com/watch?v=JV7egfF29pI&t=3000) |  We're merging two pretty big websites, not

for SEO reasons, for branding purposes, and there are some checklists out there. But I wanted to ask you, what is the most common error that people do when they're merging big websites? What do they forget? What would you recommend me to really focus on? JOHN MUELLER: Yeah. I don't know if we really have a list of the common errors  

#### [0:50:30](https://www.youtube.com/watch?v=JV7egfF29pI&t=3030) |  that people make. The one thing I

would recommend doing is really tracking all of the things that you're doing. Really making sure you have a clear list of all of the URLs ahead beforehand and where they should be going so that you can check this afterwards as well, that all of the redirects are in place, that all of the internal links are working appropriately, and just making sure that you have all of these technical details really nailed down. It is something that, especially if you're doing it all in one  

#### [0:51:00](https://www.youtube.com/watch?v=JV7egfF29pI&t=3060) |  at one time, it's kind of nerve

racking but it's-- I think the best you can do is really just make sure that all of those small details are all covered properly. LENE HEGLAND: OK. Thank you. And then last question. The developer seems to not want to do a full 301, just a 302. How big of a difference will it make to only do a 302 not a full permanent redirect?  

#### [0:51:30](https://www.youtube.com/watch?v=JV7egfF29pI&t=3090) |  JOHN MUELLER: So my guess is it

will take a little bit longer for the canonicalization to kick in and to focus on that new URL that you have there. But ultimately, I think in the long run it won't play a big difference. But if you're moving permanently, then it feels like a 301 would be the right thing to do in any case. LENE HEGLAND: I was hoping that you would give him more of a,  

#### [0:52:00](https://www.youtube.com/watch?v=JV7egfF29pI&t=3120) |  yes, you should do that, so I

can tell the developers that that was the-- JOHN MUELLER: Yeah. I mean, it's-- it is what we recommend. It's something, like, if you don't do it, and a lot of sites get it wrong, then we have to deal with that as well. But if you really want to make sure that everything is perfect, then a 301 is the right way to go. LENE HEGLAND: Thank you. That was all.  

#### [0:52:30](https://www.youtube.com/watch?v=JV7egfF29pI&t=3150) |  PRAVEEN SHARMA: Hey, John? Can I ask

a question? JOHN MUELLER: Sure. PRAVEEN SHARMA: OK. We have a software application website and basically it's a product website. Recently we decided that we should create a news portal kind of section so that we can [INAUDIBLE] industry news. We will be writing four to five articles every day. Now, the situation is something like that, because our is a product website, and the team is confused whether we should create a separate section for news on the existing website  

#### [0:53:00](https://www.youtube.com/watch?v=JV7egfF29pI&t=3180) |  or should we just create a new

domain for the news section? Because what's confusing is that if we go with the existing website, what are the chances that Google might consider our product website as a news portal only after a certain period of time? Or vise versa. It's a product website so Google might consider that it's not a new website so might rank the news in the news column. What do you say that we should do there? JOHN MUELLER: I would recommend keeping it  

#### [0:53:30](https://www.youtube.com/watch?v=JV7egfF29pI&t=3210) |  within your existing website. By keeping it

within your existing website, you're automatically making sure that it has all of the weight that it can get from the rest of your website. That's something where if you split it out into a separate domain then, essentially, you're starting with a new website and you have to work to get that well known out on the web. Whereas, if you start with your existing site, then you already have something to work with.  

#### [0:54:00](https://www.youtube.com/watch?v=JV7egfF29pI&t=3240) |  With regards to Google seeing it as

a new site or a product site, in general, that's not something I would worry about, especially if you can structure the URLs in a way that is clear this is news and this is the rest of your site, for example. So if you have a clear URL structure there, I definitely don't see any problem there. PRAVEEN SHARMA: Yeah. The existing approach we decided to create a separate category for the news section and it would be like using [INAUDIBLE] of Schema  

#### [0:54:30](https://www.youtube.com/watch?v=JV7egfF29pI&t=3270) |  so that Google has no note [INAUDIBLE]

like but we should not be confused it's a news website or it's a product website. So that was confusing. Yeah. Thank you for clearing. JOHN MUELLER: Cool. Now, any other questions? What can I help with? Nothing.  

#### [0:55:00](https://www.youtube.com/watch?v=JV7egfF29pI&t=3300) |  Wow. OK. I think we're pretty much

on time so that's also fine. If everything, otherwise, is [INAUDIBLE]---- MAHEM: Can you hear me now? JOHN MUELLER: OK. MAHEM: We have news from the [INAUDIBLE] for four years and every week we do our [INAUDIBLE] news coverage, which is linked back by other publishers. But we never appear in the top stories.  

#### [0:55:30](https://www.youtube.com/watch?v=JV7egfF29pI&t=3330) |  But they appear. What is it-- what

should we do? JOHN MUELLER: It's hard to say because for the top stories it's not so much that there is a specific meta tag or something technical that you need to do there. Rather, it's an organic search feature. And depending on how our search algorithms look at that for your site, that can go one way or it can go the other way.  

#### [0:56:00](https://www.youtube.com/watch?v=JV7egfF29pI&t=3360) |  So that's really tricky to say. One

thing you could do is maybe start a thread in the Webmaster Help forum so that someone can take a look at your details and see if there's something specific that they can point out. But in many cases, there is nothing specific technical to point out and say you need to do this specifically to be visible in the top stories section. MAHEM: Thank you.  

#### [0:56:30](https://www.youtube.com/watch?v=JV7egfF29pI&t=3390) |  JOHN MUELLER: Cool. OK. Maybe we can

take a break here. I need to jump off and do some other things at this time. Thank you all for joining. It's been great having you all here and thanks for all of your questions. And like I mentioned, if there is something that's still stuck or that you need some help on, feel free to ping me on Twitter and let me know about that. Otherwise, thanks for all your questions  

#### [0:57:00](https://www.youtube.com/watch?v=JV7egfF29pI&t=3420) |  and have a great weekend everyone. MICHAEL

CHIDZEY: Thanks, John. Cheers. JOHN MUELLER: Bye, everyone. SAIDUL HOQUE: Thank you. Bye. GRANT DOSHLAKU: Bye. MARIA AMELIE: Thank you. Bye bye. Thank you. JOHN MUELLER: Bye.  